{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0418 13:27:02.650438 139727724291904 file_utils.py:38] PyTorch version 1.4.0 available.\n",
      "I0418 13:27:02.651617 139727724291904 file_utils.py:54] TensorFlow version 2.1.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setGPU: Setting GPU to: 1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import setGPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0418 13:27:04.594387 139727724291904 tokenization_utils.py:418] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-vocab.txt from cache at /home/CompanyAI/.cache/torch/transformers/bb773818882b0524dc53a1b31a2cc95bc489f000e7e19773ba07846011a6c711.535306b226c42cebebbc0dabc83b92ab11260e9919e21e2ab0beb301f267b4c7\n",
      "I0418 13:27:05.647269 139727724291904 configuration_utils.py:254] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json from cache at /home/CompanyAI/.cache/torch/transformers/33b56ce0f312e47e4d77a57791a4fc6233ae4a560dd2bdd186107058294e58ab.c7892120c5a9b21e515abc904e398dbabddf9510b122f659063cbf361fe16868\n",
      "I0418 13:27:05.649232 139727724291904 configuration_utils.py:290] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"do_sample\": false,\n",
      "  \"eos_token_ids\": 0,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 105879\n",
      "}\n",
      "\n",
      "I0418 13:27:06.573167 139727724291904 modeling_tf_utils.py:338] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-tf_model.h5 from cache at /home/CompanyAI/.cache/torch/transformers/7efc9507bca9e880aea7a38a849d8e16fcd54f2071f8f8143afa5815d00a16f4.25728a4fd7ddaafee2965f5821a206f237b83c672e0bb092881f9b1f5eea2b2f.h5\n",
      "I0418 13:27:26.073199 139727724291904 modeling_tf_utils.py:376] Layers of TFBertForSequenceClassification not initialized from pretrained model: ['dropout_37', 'classifier']\n",
      "I0418 13:27:26.074909 139727724291904 modeling_tf_utils.py:380] Layers from pretrained model not used in TFBertForSequenceClassification: ['mlm___cls', 'nsp___cls']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "model = TFBertForSequenceClassification.from_pretrained(\"bert-base-multilingual-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "VALID_SPLIT = 0.2\n",
    "MAX_LEN = 128\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = \"data_out/KOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[MASK]', '[CLS]', '[PAD]', '[UNK]', '[SEP]'] \n",
      " [103, 101, 0, 100, 102]\n",
      "[101, 1174, 26646, 49345, 13045, 35132, 25169, 47024, 117, 1170, 26646, 11376, 17360, 13212, 79427, 102]\n",
      "[101, 29155, 10228, 102]\n",
      "[CLS] 안녕하세요, 반갑습니다 [SEP]\n",
      "[CLS] hello world [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Special Tokens\n",
    "print(tokenizer.all_special_tokens, \"\\n\", tokenizer.all_special_ids)\n",
    "\n",
    "# Test Tokenizers\n",
    "kor_encode = tokenizer.encode(\"안녕하세요, 반갑습니다\")\n",
    "eng_encode = tokenizer.encode(\"Hello world\")\n",
    "\n",
    "kor_decode = tokenizer.decode(kor_encode)\n",
    "eng_decode = tokenizer.decode(eng_encode)\n",
    "\n",
    "print(kor_encode)\n",
    "print(eng_encode)\n",
    "print(kor_decode)\n",
    "print(eng_decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean Movie Review Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, \"naver_movie\", \"ratings_train.txt\")\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, \"naver_movie\", \"ratings_test.txt\")\n",
    "\n",
    "train_data = pd.read_csv(DATA_TRAIN_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리\n",
    "\n",
    "def clean_text(sent):\n",
    "    sent_clean = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", sent)\n",
    "    return sent_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error message: expected string or bytes-like object\n",
      "sentence: nan\n",
      "Error message: expected string or bytes-like object\n",
      "sentence: nan\n",
      "Error message: expected string or bytes-like object\n",
      "sentence: nan\n",
      "Error message: expected string or bytes-like object\n",
      "sentence: nan\n",
      "Error message: expected string or bytes-like object\n",
      "sentence: nan\n",
      "num sents, labels 149995, 149995\n"
     ]
    }
   ],
   "source": [
    "# train_data = train_data[:1000] # for test\n",
    "\n",
    "train_data_sents = []\n",
    "train_data_labels = []\n",
    "\n",
    "for train_sent, train_label in zip(train_data[\"document\"], train_data[\"label\"]):\n",
    "    try:\n",
    "        token_sent = tokenizer.encode(clean_text(train_sent))\n",
    "    except Exception as e:\n",
    "        print(\"Error message: {}\".format(e))\n",
    "        print(\"sentence: {}\".format(train_sent))\n",
    "        continue\n",
    "        \n",
    "    train_data_sents.append(token_sent) #append는 빼 놓고 한다.\n",
    "    train_data_labels.append(train_label)\n",
    "\n",
    "train_data_sent_pads = pad_sequences(train_data_sents, maxlen=MAX_LEN, padding='post')\n",
    "train_data_labels = np.asarray(train_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"num sents, labels {}, {}\".format(len(train_data_sent_pads), len(train_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  101  1174 25539 23236 29234 13045 87550 97082 25539  1176 25539 24937\n",
      " 13045 16801 72197 47024  1169 70724 22585 13926   102     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_sent_pads[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비하기\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/KORtf2_bert_naver_movie -- Folder create complete \n",
      "\n",
      "Train on 119996 samples, validate on 29999 samples\n",
      "Epoch 1/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.4657 - accuracy: 0.7509\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.82812, saving model to data_out/KORtf2_bert_naver_movie/weights.01-0.83.h5\n",
      "119996/119996 [==============================] - 1060s 9ms/sample - loss: 0.4656 - accuracy: 0.7509 - val_loss: 0.0033 - val_accuracy: 0.8281\n",
      "Epoch 2/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.3245 - accuracy: 0.8553\n",
      "Epoch 00002: val_accuracy improved from 0.82812 to 0.84766, saving model to data_out/KORtf2_bert_naver_movie/weights.02-0.85.h5\n",
      "119996/119996 [==============================] - 1034s 9ms/sample - loss: 0.3244 - accuracy: 0.8553 - val_loss: 0.0030 - val_accuracy: 0.8477\n",
      "Epoch 3/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.2764 - accuracy: 0.8814\n",
      "Epoch 00003: val_accuracy did not improve from 0.84766\n",
      "119996/119996 [==============================] - 1031s 9ms/sample - loss: 0.2764 - accuracy: 0.8814 - val_loss: 0.0034 - val_accuracy: 0.8477\n",
      "Epoch 4/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.2348 - accuracy: 0.9008\n",
      "Epoch 00004: val_accuracy did not improve from 0.84766\n",
      "119996/119996 [==============================] - 1031s 9ms/sample - loss: 0.2347 - accuracy: 0.9008 - val_loss: 0.0039 - val_accuracy: 0.8438\n",
      "Epoch 5/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.1982 - accuracy: 0.9178\n",
      "Epoch 00005: val_accuracy improved from 0.84766 to 0.85156, saving model to data_out/KORtf2_bert_naver_movie/weights.05-0.85.h5\n",
      "119996/119996 [==============================] - 1033s 9ms/sample - loss: 0.1982 - accuracy: 0.9178 - val_loss: 0.0035 - val_accuracy: 0.8516\n",
      "Epoch 6/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.1646 - accuracy: 0.9340\n",
      "Epoch 00006: val_accuracy improved from 0.85156 to 0.85938, saving model to data_out/KORtf2_bert_naver_movie/weights.06-0.86.h5\n",
      "119996/119996 [==============================] - 1033s 9ms/sample - loss: 0.1647 - accuracy: 0.9340 - val_loss: 0.0040 - val_accuracy: 0.8594\n",
      "Epoch 7/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9449\n",
      "Epoch 00007: val_accuracy improved from 0.85938 to 0.86719, saving model to data_out/KORtf2_bert_naver_movie/weights.07-0.87.h5\n",
      "119996/119996 [==============================] - 1033s 9ms/sample - loss: 0.1383 - accuracy: 0.9449 - val_loss: 0.0033 - val_accuracy: 0.8672\n",
      "Epoch 8/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.1155 - accuracy: 0.9540\n",
      "Epoch 00008: val_accuracy did not improve from 0.86719\n",
      "119996/119996 [==============================] - 1031s 9ms/sample - loss: 0.1156 - accuracy: 0.9540 - val_loss: 0.0043 - val_accuracy: 0.8477\n",
      "Epoch 9/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.1014 - accuracy: 0.9598\n",
      "Epoch 00009: val_accuracy did not improve from 0.86719\n",
      "119996/119996 [==============================] - 1031s 9ms/sample - loss: 0.1014 - accuracy: 0.9598 - val_loss: 0.0047 - val_accuracy: 0.8477\n",
      "Epoch 10/20\n",
      "119936/119996 [============================>.] - ETA: 0s - loss: 0.0870 - accuracy: 0.9657\n",
      "Epoch 00010: val_accuracy did not improve from 0.86719\n",
      "119996/119996 [==============================] - 1031s 9ms/sample - loss: 0.0870 - accuracy: 0.9657 - val_loss: 0.0046 - val_accuracy: 0.8477\n",
      "{'loss': [0.46564872008692626, 0.32442472837317715, 0.27640139790665186, 0.2347456508730645, 0.1982337214687736, 0.16467060378449866, 0.13829249476751862, 0.11555234743047188, 0.10141412524866014, 0.08703642496521574], 'accuracy': [0.75088334, 0.8553119, 0.8814044, 0.9007717, 0.91779727, 0.93401444, 0.9448982, 0.95401514, 0.9598153, 0.9656655], 'val_loss': [0.0032524483502477425, 0.0029924791285767466, 0.0033675866181216456, 0.0038975209187474217, 0.003458759141662144, 0.0039538283630857355, 0.0032573305625486996, 0.004276643129518705, 0.00473512564147646, 0.004589420202760014], 'val_accuracy': [0.828125, 0.84765625, 0.84765625, 0.84375, 0.8515625, 0.859375, 0.8671875, 0.84765625, 0.84765625, 0.84765625]}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_naver_movie\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=3)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 학습과 eval 시작\n",
    "history = model.fit(train_data_sent_pads, train_data_labels, epochs=NUM_EPOCHS, batch_size=BATCH_SIZE,\n",
    "                    validation_split = VALID_SPLIT, callbacks=[earlystop_callback, cp_callback], validation_steps=2)\n",
    "\n",
    "#steps_for_epoch\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korean Movie Review Test 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6270596</td>\n",
       "      <td>굳 ㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9274899</td>\n",
       "      <td>GDNTOPCLASSINTHECLUB</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8544678</td>\n",
       "      <td>뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6825595</td>\n",
       "      <td>지루하지는 않은데 완전 막장임... 돈주고 보기에는....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6723715</td>\n",
       "      <td>3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                           document  label\n",
       "0  6270596                                                굳 ㅋ      1\n",
       "1  9274899                               GDNTOPCLASSINTHECLUB      0\n",
       "2  8544678             뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아      0\n",
       "3  6825595                   지루하지는 않은데 완전 막장임... 돈주고 보기에는....      0\n",
       "4  6723715  3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심기를 불편하게 하죠??      0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = pd.read_csv(DATA_TEST_PATH, header = 0, delimiter = '\\t', quoting = 3)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expected string or bytes-like object\n",
      "nan\n",
      "expected string or bytes-like object\n",
      "nan\n",
      "expected string or bytes-like object\n",
      "nan\n",
      "num sents, labels 49997, 49997\n"
     ]
    }
   ],
   "source": [
    "test_data_sents = []\n",
    "test_data_labels = []\n",
    "\n",
    "for test_sent, test_label in zip(test_data[\"document\"], test_data[\"label\"]):\n",
    "    try:\n",
    "        token_sent = tokenizer.encode(clean_text(test_sent))\n",
    "        test_data_sents.append(token_sent)\n",
    "        test_data_labels.append(test_label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(test_sent)\n",
    "        pass\n",
    "\n",
    "test_data_sent_pad = pad_sequences(test_data_sents, maxlen=MAX_LEN, padding='post') # convert into numpy\n",
    "test_data_labels = np.asarray(test_data_labels, dtype=np.int32) #레이블 토크나이징 리스트\n",
    "\n",
    "print(\"num sents, labels {}, {}\".format(len(test_data_sent_pad), len(test_data_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49997/49997 [==============================] - 213s 4ms/sample - loss: 0.4673 - accuracy: 0.8568\n",
      "test loss, test acc:  [0.4673143170114865, 0.85679144]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data_sent_pad, test_data_labels)\n",
    "print(\"test loss, test acc: \", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KorNLI Dataset\n",
    "\n",
    "Data from Kakaobrain:  https://github.com/kakaobrain/KorNLUDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE PARAM\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20\n",
    "VALID_SPLIT = 0.2\n",
    "# MAX_LEN = 14 * 2 # Average total * 2\n",
    "MAX_LEN = 65 # Average total * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Train dataset\n",
    "TRAIN_SNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'snli_1.0_train.kor')\n",
    "TRAIN_XNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'multinli.train.ko.tsv')\n",
    "DEV_XNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'xnli.dev.ko.tsv')\n",
    "\n",
    "train_data_snli = pd.read_csv(TRAIN_SNLI_DF, header=0, delimiter = '\\t', quoting = 3)\n",
    "train_data_xnli = pd.read_csv(TRAIN_XNLI_DF, header=0, delimiter = '\\t', quoting = 3)\n",
    "dev_data_xnli = pd.read_csv(DEV_XNLI_DF, header=0, delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 경쟁을 위해 말을 훈련시키고 있다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>한 사람이 식당에서 오믈렛을 주문하고 있다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>말을 탄 사람이 고장난 비행기 위로 뛰어오른다.</td>\n",
       "      <td>사람은 야외에서 말을 타고 있다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>그들은 부모님을 보고 웃고 있다</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>카메라에 웃고 손을 흔드는 아이들</td>\n",
       "      <td>아이들이 있다</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    sentence1                  sentence2     gold_label\n",
       "0  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.  한 사람이 경쟁을 위해 말을 훈련시키고 있다.        neutral\n",
       "1  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.   한 사람이 식당에서 오믈렛을 주문하고 있다.  contradiction\n",
       "2  말을 탄 사람이 고장난 비행기 위로 뛰어오른다.         사람은 야외에서 말을 타고 있다.     entailment\n",
       "3          카메라에 웃고 손을 흔드는 아이들          그들은 부모님을 보고 웃고 있다        neutral\n",
       "4          카메라에 웃고 손을 흔드는 아이들                    아이들이 있다     entailment"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SNLI Train Dataset\n",
    "train_data_snli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>개념적으로 크림 스키밍은 제품과 지리라는 두 가지 기본 차원을 가지고 있다.</td>\n",
       "      <td>제품과 지리학은 크림 스키밍을 작동시키는 것이다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>시즌 중에 알고 있는 거 알아? 네 레벨에서 다음 레벨로 잃어버리는 거야 브레이브스...</td>\n",
       "      <td>사람들이 기억하면 다음 수준으로 물건을 잃는다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>우리 번호 중 하나가 당신의 지시를 세밀하게 수행할 것이다.</td>\n",
       "      <td>우리 팀의 일원이 당신의 명령을 엄청나게 정확하게 실행할 것이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>어떻게 아세요? 이 모든 것이 다시 그들의 정보다.</td>\n",
       "      <td>이 정보는 그들의 것이다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>그래, 만약 네가 테니스화 몇 개를 사러 간다면, 나는 왜 그들이 100달러대에서 ...</td>\n",
       "      <td>테니스화의 가격은 다양하다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0         개념적으로 크림 스키밍은 제품과 지리라는 두 가지 기본 차원을 가지고 있다.   \n",
       "1  시즌 중에 알고 있는 거 알아? 네 레벨에서 다음 레벨로 잃어버리는 거야 브레이브스...   \n",
       "2                  우리 번호 중 하나가 당신의 지시를 세밀하게 수행할 것이다.   \n",
       "3                       어떻게 아세요? 이 모든 것이 다시 그들의 정보다.   \n",
       "4  그래, 만약 네가 테니스화 몇 개를 사러 간다면, 나는 왜 그들이 100달러대에서 ...   \n",
       "\n",
       "                              sentence2  gold_label  \n",
       "0           제품과 지리학은 크림 스키밍을 작동시키는 것이다.     neutral  \n",
       "1            사람들이 기억하면 다음 수준으로 물건을 잃는다.  entailment  \n",
       "2  우리 팀의 일원이 당신의 명령을 엄청나게 정확하게 실행할 것이다.  entailment  \n",
       "3                        이 정보는 그들의 것이다.  entailment  \n",
       "4                       테니스화의 가격은 다양하다.     neutral  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XNLI Train Dataset\n",
    "train_data_xnli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>그리고 그가 말했다, \"엄마, 저 왔어요.\"</td>\n",
       "      <td>그는 학교 버스가 그를 내려주자마자 엄마에게 전화를 걸었다.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>그리고 그가 말했다, \"엄마, 저 왔어요.\"</td>\n",
       "      <td>그는 한마디도 하지 않았다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그리고 그가 말했다, \"엄마, 저 왔어요.\"</td>\n",
       "      <td>그는 엄마에게 집에 갔다고 말했다.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...</td>\n",
       "      <td>나는 워싱턴에 가본 적이 없어서 거기 배정을 받았을 때 그 장소를 찾으려다가 길을 ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...</td>\n",
       "      <td>워싱턴으로 진군하면서 해야 할 일이 무엇인지 정확히 알고 있었다.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0                           그리고 그가 말했다, \"엄마, 저 왔어요.\"   \n",
       "1                           그리고 그가 말했다, \"엄마, 저 왔어요.\"   \n",
       "2                           그리고 그가 말했다, \"엄마, 저 왔어요.\"   \n",
       "3  내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...   \n",
       "4  내가 무엇을 위해 가고 있는지 또는 어떤 것을 위해 있는지 몰랐기 때문에 워싱턴의 ...   \n",
       "\n",
       "                                           sentence2     gold_label  \n",
       "0                  그는 학교 버스가 그를 내려주자마자 엄마에게 전화를 걸었다.        neutral  \n",
       "1                                    그는 한마디도 하지 않았다.  contradiction  \n",
       "2                                그는 엄마에게 집에 갔다고 말했다.     entailment  \n",
       "3  나는 워싱턴에 가본 적이 없어서 거기 배정을 받았을 때 그 장소를 찾으려다가 길을 ...        neutral  \n",
       "4               워싱턴으로 진군하면서 해야 할 일이 무엇인지 정확히 알고 있었다.  contradiction  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XNLI DEV Dataset\n",
    "dev_data_xnli.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # dataset: 942854\n"
     ]
    }
   ],
   "source": [
    "# 학습을 위하여 SNLI와 XNLI 데이터셋을 합친다.\n",
    "\n",
    "train_data_snli_xnli = train_data_snli.append(train_data_xnli)\n",
    "train_data_snli_xnli = train_data_snli_xnli.reset_index()\n",
    "\n",
    "print(\"Total # dataset: {}\".format(len(train_data_snli_xnli)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simliarty tokenizer\n",
    "\n",
    "# 참조: https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus\n",
    "\n",
    "def sim_tokenizer(sent1, sent2, MAX_LEN):\n",
    "    \n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent1,                      # Sentence to encode.\n",
    "        text_pair = sent2,\n",
    "        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "        max_length = MAX_LEN,           # Pad & truncate all sentences.\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # Construct attn. masks.\n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids'] # Add the encoded sentence to the list.\n",
    "    attention_mask = encoded_dict['attention_mask'] # And its attention mask (simply differentiates padding from non-padding).\n",
    "    token_type_id = encoded_dict['token_type_ids'] # diffenciate two sentences\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저를 제외하고는 5장에서 처리한 방식과 유사하게 접근\n",
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "\n",
    "change_filter = re.compile(FILTERS)\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "\n",
    "for sent1, sent2 in zip(train_data_snli_xnli['sentence1'], train_data_snli_xnli['sentence2']):\n",
    "    \n",
    "    sent1 = re.sub(change_filter, \"\", str(sent1))\n",
    "    sent2 = re.sub(change_filter, \"\", str(sent2))\n",
    "    \n",
    "    input_id, attention_mask, token_type_id = sim_tokenizer(sent1, sent2, MAX_LEN)\n",
    "    \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "    token_type_ids.append(token_type_id)\n",
    "    \n",
    "train_snli_xnli_input_ids = np.array(input_ids, dtype=int)\n",
    "train_snli_xnli_attention_masks = np.array(attention_masks, dtype=int)\n",
    "train_snli_xnli_type_ids = np.array(token_type_ids, dtype=int)\n",
    "train_snli_xnli_inputs = (train_snli_xnli_input_ids, train_snli_xnli_attention_masks, train_snli_xnli_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 942854, # labels: 942854\n"
     ]
    }
   ],
   "source": [
    "# Label을 Netural, Contradiction, Entailment 에서 숫자 형으로 변경한다.\n",
    "label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2}\n",
    "def convert_int(label):\n",
    "    num_label = label_dict[label]    \n",
    "    return num_label\n",
    "\n",
    "train_data_snli_xnli[\"gold_label_int\"] = train_data_snli_xnli[\"gold_label\"].apply(convert_int)\n",
    "train_snli_xnli_labels = np.array(train_data_snli_xnli['gold_label_int'], dtype=int)\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(train_snli_xnli_input_ids), len(train_snli_xnli_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dev set도 똑같은 방법으로 구성한다.\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "\n",
    "for sent1, sent2 in zip(dev_data_xnli['sentence1'], dev_data_xnli['sentence2']):\n",
    "    \n",
    "    sent1 = re.sub(change_filter, \"\", str(sent1))\n",
    "    sent2 = re.sub(change_filter, \"\", str(sent2))\n",
    "    \n",
    "    input_id, attention_mask, token_type_id = sim_tokenizer(sent1, sent2, MAX_LEN)\n",
    "    \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "    token_type_ids.append(token_type_id)\n",
    "    \n",
    "dev_xnli_input_ids = np.array(input_ids, dtype=int)\n",
    "dev_xnli_attention_masks = np.array(attention_masks, dtype=int)\n",
    "dev_xnli_type_ids = np.array(token_type_ids, dtype=int)\n",
    "dev_xnli_inputs = (dev_xnli_input_ids, dev_xnli_attention_masks, dev_xnli_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# sents: 2490, # labels: 2490\n"
     ]
    }
   ],
   "source": [
    "# Label을 Netural, Contradiction, Entailment 에서 숫자 형으로 변경한다.\n",
    "label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2}\n",
    "def convert_int(label):\n",
    "    num_label = label_dict[label]    \n",
    "    return num_label\n",
    "\n",
    "dev_data_xnli[\"gold_label_int\"] = dev_data_xnli[\"gold_label\"].apply(convert_int)\n",
    "dev_data_xnli_labels = np.array(dev_data_xnli['gold_label_int'], dtype=int)\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(dev_xnli_input_ids), len(dev_data_xnli_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 준비하기\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/KORtf2_KorNLI -- Folder already exists \n",
      "\n",
      "Train on 848568 samples, validate on 94286 samples\n",
      "Epoch 1/20\n",
      " 81408/848568 [=>............................] - ETA: 30:43 - loss: nan - accuracy: 0.3372"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0419 02:50:35.940788 139727724291904 callbacks.py:1286] Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "W0419 02:50:35.942330 139727724291904 callbacks.py:1018] Can save best model only with val_accuracy available, skipping.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-c847815789a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m                     \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#             validation_data = (dev_xnli_inputs, dev_data_xnli_labels),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             batch_size=BATCH_SIZE, callbacks=[earlystop_callback, cp_callback])\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#steps_for_epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#학습 진행하기\n",
    "model_name = \"tf2_KorNLI\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=5)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "# 학습과 eval 시작\n",
    "history = model.fit(train_snli_xnli_input_ids, train_snli_xnli_labels, epochs=NUM_EPOCHS,\n",
    "                    validation_split = 0.1,\n",
    "#             validation_data = (dev_xnli_inputs, dev_data_xnli_labels),\n",
    "            batch_size=BATCH_SIZE, callbacks=[earlystop_callback, cp_callback])\n",
    "\n",
    "#steps_for_epoch\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KorNLI Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test dataset\n",
    "TEST_XNLI_DF = os.path.join(DATA_IN_PATH, 'KorNLI', 'xnli.test.ko.tsv')\n",
    "\n",
    "test_data_xnli = pd.read_csv(TEST_XNLI_DF, header=0, delimiter = '\\t', quoting = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set도 똑같은 방법으로 구성한다.\n",
    "\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "token_type_ids = []\n",
    "\n",
    "for sent1, sent2 in zip(test_data_xnli['sentence1'], test_data_xnli['sentence2']):\n",
    "    \n",
    "    sent1 = re.sub(change_filter, \"\", str(sent1))\n",
    "    sent2 = re.sub(change_filter, \"\", str(sent2))\n",
    "    \n",
    "    input_id, attention_mask, token_type_id = sim_tokenizer(sent1, sent2, MAX_LEN)\n",
    "    \n",
    "    input_ids.append(input_id)\n",
    "    attention_masks.append(attention_mask)\n",
    "    token_type_ids.append(token_type_id)\n",
    "    \n",
    "test_xnli_input_ids = np.array(input_ids, dtype=int)\n",
    "test_xnli_attention_masks = np.array(attention_masks, dtype=int)\n",
    "test_xnli_type_ids = np.array(token_type_ids, dtype=int)\n",
    "test_xnli_inputs = (test_xnli_input_ids, test_xnli_attention_masks, test_xnli_type_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label을 Netural, Contradiction, Entailment 에서 숫자 형으로 변경한다.\n",
    "label_dict = {\"entailment\": 0, \"contradiction\": 1, \"neutral\": 2}\n",
    "def convert_int(label):\n",
    "    num_label = label_dict[label]    \n",
    "    return num_label\n",
    "\n",
    "test_data_xnli[\"gold_label_int\"] = test_data_xnli[\"gold_label\"].apply(convert_int)\n",
    "test_data_xnli_labels = np.array(test_data_xnli['gold_label_int'], dtype=int)\n",
    "\n",
    "print(\"# sents: {}, # labels: {}\".format(len(test_xnli_input_ids), len(test_data_xnli_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_xnli_inputs, test_data_xnli_labels)\n",
    "print(\"test loss, test acc: \", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
