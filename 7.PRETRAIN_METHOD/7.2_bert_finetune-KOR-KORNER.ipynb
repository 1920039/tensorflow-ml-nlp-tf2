{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "#     os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "    import setGPU\n",
    "except:\n",
    "    print('no setGPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 3\n",
    "MAX_LEN = 111 # EDA에서 추출된 Max Length\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = \"data_out/KOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 학습 데이터 개수: 81000\n",
      "개체명 인식 테스트 데이터 개수: 9000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"train.tsv\")\n",
    "DATA_LABEL_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"label.txt\")\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"test.tsv\")\n",
    "\n",
    "def read_file(input_path):\n",
    "    \"\"\"Read tsv file, and return words and label as list\"\"\"\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            split_line = line.strip().split(\"\\t\")\n",
    "            sentences.append(split_line[0])\n",
    "            labels.append(split_line[1])\n",
    "        return sentences, labels\n",
    "\n",
    "train_sentences, train_labels = read_file(DATA_TRAIN_PATH)\n",
    "\n",
    "train_ner_dict = {\"sentence\": train_sentences, \"label\": train_labels}\n",
    "train_ner_df = pd.DataFrame(train_ner_dict)\n",
    "\n",
    "test_sentences, test_labels = read_file(DATA_TEST_PATH)\n",
    "test_ner_dict = {\"sentence\": test_sentences, \"label\": test_labels}\n",
    "test_ner_df = pd.DataFrame(test_ner_dict)\n",
    "\n",
    "print(\"개체명 인식 학습 데이터 개수: {}\".format(len(train_ner_df)))\n",
    "print(\"개체명 인식 테스트 데이터 개수: {}\".format(len(test_ner_df)))\n",
    "\n",
    "# 개체명 인식 학습 데이터 개수: 81000\n",
    "# 개체명 인식 테스트 데이터 개수: 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 레이블 개수: 30\n"
     ]
    }
   ],
   "source": [
    "# Label 불러오기\n",
    "\n",
    "def get_labels(label_path):\n",
    "    return [label.strip() for label in open(os.path.join(label_path), 'r', encoding='utf-8')]\n",
    "\n",
    "ner_labels = get_labels(DATA_LABEL_PATH)\n",
    "\n",
    "print(\"개체명 인식 레이블 개수: {}\".format(len(ner_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0822 08:36:53.351701 140526050977600 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at bert_ckpt/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n"
     ]
    }
   ],
   "source": [
    "# 버트 토크나이저 설정\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt')\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id # 0\n",
    "pad_token_label_id = 0\n",
    "cls_token_label_id = 0\n",
    "sep_token_label_id = 0\n",
    "# cls_token_label_id = 1\n",
    "# sep_token_label_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        truncation=True,\n",
    "        add_special_tokens = True, #'[CLS]'와 '[SEP]' 추가\n",
    "        max_length = MAX_LEN,           # 문장 패딩 및 자르기 진행\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # 어탠션 마스크 생성\n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] \n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "def convert_label(words, labels_idx, ner_begin_label, max_seq_len):\n",
    "            \n",
    "    tokens = []\n",
    "    label_ids = []\n",
    "\n",
    "    for word, slot_label in zip(words, labels_idx):\n",
    "\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        if not word_tokens:\n",
    "            word_tokens = [unk_token]\n",
    "        tokens.extend(word_tokens)\n",
    "        \n",
    "        # 슬롯 레이블 값이 Begin이면 I로 추가\n",
    "        if int(slot_label) in ner_begin_label:\n",
    "            label_ids.extend([int(slot_label)] + [int(slot_label) + 1] * (len(word_tokens) - 1))\n",
    "        else:\n",
    "            label_ids.extend([int(slot_label)] * len(word_tokens))\n",
    "  \n",
    "    # [CLS] and [SEP] 설정\n",
    "    special_tokens_count = 2\n",
    "    if len(label_ids) > max_seq_len - special_tokens_count:\n",
    "        label_ids = label_ids[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "    # [SEP] 토큰 추가\n",
    "    label_ids += [sep_token_label_id]\n",
    "\n",
    "    # [CLS] 토큰 추가\n",
    "    label_ids = [cls_token_label_id] + label_ids\n",
    "    \n",
    "    padding_length = max_seq_len - len(label_ids)\n",
    "    label_ids = label_ids + ([pad_token_label_id] * padding_length)\n",
    "    \n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs_targets(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    label_list = []\n",
    "\n",
    "    for i, data in enumerate(df[['sentence', 'label']].values):\n",
    "        sentence, labels = data\n",
    "        words = sentence.split()\n",
    "        labels = labels.split()\n",
    "        labels_idx = []\n",
    "        \n",
    "        for label in labels:\n",
    "            labels_idx.append(ner_labels.index(label) if label in ner_labels else ner_labels.index(\"UNK\"))\n",
    "\n",
    "        ner_begin_label = [ner_labels.index(begin_label) for begin_label in ner_labels if \"B\" in begin_label]\n",
    "        assert len(words) == len(labels_idx)\n",
    "\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(sentence, MAX_LEN)\n",
    "\n",
    "        convert_label_id = convert_label(words, labels_idx, ner_begin_label, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        label_list.append(convert_label_id)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    label_list = np.asarray(label_list, dtype=int) #레이블 토크나이징 리스트\n",
    "    inputs = (input_ids, attention_masks, token_type_ids)\n",
    "    \n",
    "    return inputs, label_list\n",
    "\n",
    "train_ner_df = train_ner_df[:100]\n",
    "test_ner_df = test_ner_df[:10]\n",
    "\n",
    "train_inputs, train_labels = create_inputs_targets(train_ner_df)\n",
    "test_inputs, test_labels = create_inputs_targets(test_ner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertNERClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertNERClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "                                                name=\"ner_classifier\")\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "\n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "        \n",
    "        print(sequence_output.size())\n",
    "        \n",
    "        sequence_output = self.dropout(sequence_output, training=training)\n",
    "        logits = self.classifier(sequence_output)\n",
    "        \n",
    "        print(logits.size())\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0822 08:37:35.585758 140526050977600 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at bert_ckpt/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "I0822 08:37:35.587702 140526050977600 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I0822 08:37:36.810427 140526050977600 modeling_tf_utils.py:473] loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-tf_model.h5 from cache at bert_ckpt/273ed844d60ef1d5a4ea8f7857e3c3869d05d7b22296f4ae9bc56026ed40eeb7.1b4841f14bf42137fc7ecee17a46c1b2f22b417f636347e4b810bd06dd9c45ea.h5\n",
      "W0822 08:37:41.415009 140526050977600 modeling_tf_utils.py:511] Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "W0822 08:37:41.418100 140526050977600 modeling_tf_utils.py:528] All the weights of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "ner_model = TFBertNERClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=len(ner_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(labels, logits):\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "    # 0의 레이블 값은 손실 값을 계산할 때 제외\n",
    "    \n",
    "#     print(\"labels\")\n",
    "#     print(labels)\n",
    "\n",
    "    active_loss = tf.reshape(labels, (-1,)) != 0\n",
    "    \n",
    "#     print(\"Active loss\")\n",
    "#     print(active_loss)\n",
    "    \n",
    "    reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\n",
    "    \n",
    "#     print(reduced_logits)\n",
    "    \n",
    "#     print(\"labels\")\n",
    "#     print(labels)\n",
    "    \n",
    "    labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n",
    "    \n",
    "#     print(\"labels\")\n",
    "#     print(labels)\n",
    "    \n",
    "    return loss_fn(labels, reduced_logits)\n",
    "\n",
    "# labels\n",
    "# tf.Tensor(\n",
    "# [[ 0. 10. 11. 11. 11. 11. 11. 11.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
    "#    1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 10. 11. 11. 11.  1.  1.\n",
    "#    1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.]\n",
    "#  [ 0.  1.  1. 28. 29. 29.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.]], shape=(2, 111), dtype=float32)\n",
    "# Active loss\n",
    "# tf.Tensor(\n",
    "[False  True  True  True  True  True  True  True  True  True  True  True\n",
    "  True  True  True  True  True  True  True  True  True  True  True  True\n",
    "  True  True  True  True  True  True  True  True  True  True  True  True\n",
    "  True  True  True  True  True  True  True  True  True  True  True  True\n",
    "  True  True False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False  True  True  True  True  True  True  True  True\n",
    "  True  True  True  True  True  True  True  True  True False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False False False False False False False\n",
    " False False False False False False], shape=(222,), dtype=bool)\n",
    "# tf.Tensor(\n",
    "# [[-0.20070355  0.57105565 -0.5764023  ...  0.966773    0.6161363\n",
    "#    0.20100808]\n",
    "#  [-0.25403374  1.8692875   0.02586203 ...  1.727051    0.20142289\n",
    "#    1.2762938 ]\n",
    "#  [-0.413098    2.3735065   0.05344111 ...  1.8781955  -0.13177925\n",
    "#    0.5967046 ]\n",
    "#  ...\n",
    "#  [-0.27605966  1.8134694  -0.47742274 ...  0.9219384  -0.38688442\n",
    "#    0.44301265]\n",
    "#  [ 0.45511377  1.2056724  -0.3297121  ...  0.11512136  0.20294163\n",
    "#   -0.048159  ]\n",
    "#  [ 0.40559357  0.8873435  -0.8129963  ...  0.31500405  0.73742664\n",
    "#   -0.35371864]], shape=(66, 30), dtype=float32)\n",
    "# labels\n",
    "# tf.Tensor(\n",
    "# [[ 0. 10. 11. 11. 11. 11. 11. 11.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
    "#    1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 10. 11. 11. 11.  1.  1.\n",
    "#    1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.]\n",
    "#  [ 0.  1.  1. 28. 29. 29.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.]], shape=(2, 111), dtype=float32)\n",
    "# labels\n",
    "# tf.Tensor(\n",
    "# [10. 11. 11. 11. 11. 11. 11.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
    "#   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 10. 11. 11. 11.  1.  1.  1.\n",
    "#   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. 28. 29. 29.\n",
    "#   1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.], shape=(66,), dtype=float32)\n",
    "#  1/50 [..............................] - ETA: 0s - loss: 3.1371labels\n",
    "# tf.Tensor(\n",
    "# [[ 0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
    "#    1.  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.]\n",
    "#  [ 0.  2.  3.  3.  3.  3.  3.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
    "#    1. 12. 13. 13. 13.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
    "#    0.  0.  0.]], shape=(2, 111), dtype=float32)\n",
    "# Active loss\n",
    "# tf.Tensor(\n",
    "# [False  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True  True  True  True  True  True  True  True  True False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False  True  True  True  True  True  True  True  True\n",
    "#   True  True  True  True  True  True  True  True  True  True  True  True\n",
    "#   True  True  True False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False False False False False False False\n",
    "#  False False False False False False], shape=(222,), dtype=bool)\n",
    "# tf.Tensor(\n",
    "# [[ 0.14271234  1.716831   -0.47607824 ... -0.47392145 -0.02658497\n",
    "#    0.043262  ]\n",
    "#  [ 0.13837923  2.4716344  -0.06783289 ...  0.31900546 -0.6919821\n",
    "#    0.38450852]\n",
    "#  [-0.16288234  1.9954419   0.5078238  ...  1.2905562  -0.22989689\n",
    "#    0.7669436 ]\n",
    "#  ...\n",
    "#  [-0.6484789   2.6197963   0.50899017 ...  0.25902334  0.3628642\n",
    "#    0.59585446]\n",
    "#  [-0.17161797  2.446683    0.1203839  ...  0.29811338  0.03967901\n",
    "#    0.06480265]\n",
    "#  [-0.43927494  2.2669454   0.32655752 ...  0.45683378  0.74146104\n",
    "#    0.5793219 ]], shape=(43, 30), dtype=float32)\n",
    "\n",
    "\n",
    "# # labels\n",
    "# # Tensor(\"Cast:0\", shape=(None, 111), dtype=float32)\n",
    "# # Active loss\n",
    "# # Tensor(\"compute_loss/NotEqual:0\", shape=(None,), dtype=bool)\n",
    "# # Tensor(\"compute_loss/boolean_mask/GatherV2:0\", shape=(None, 30), dtype=float32)\n",
    "# # labels\n",
    "# # Tensor(\"Cast:0\", shape=(None, 111), dtype=float32)\n",
    "# # labels\n",
    "# # Tensor(\"compute_loss/boolean_mask_1/GatherV2:0\", shape=(None,), dtype=float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def compute_metrics(self, labels, preds):\n",
    "        assert len(preds) == len(labels)\n",
    "        return self.f1_pre_rec(labels, preds)\n",
    "\n",
    "    def f1_pre_rec(self, labels, preds):\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision_score(labels, preds, suffix=True),\n",
    "            \"recall\": recall_score(labels, preds, suffix=True),\n",
    "            \"f1\": f1_score(labels, preds, suffix=True)\n",
    "        }\n",
    "\n",
    "\n",
    "    def show_report(self, labels, preds):\n",
    "        return classification_report(labels, preds, suffix=True)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        results = {}\n",
    "        \n",
    "        pred = self.model.predict(self.x_eval)\n",
    "        label = self.y_eval\n",
    "        pred_argmax = np.argmax(pred, axis = 2)\n",
    "\n",
    "        slot_label_map = {i: label for i, label in enumerate(ner_labels)}\n",
    "\n",
    "        out_label_list = [[] for _ in range(label.shape[0])]\n",
    "        preds_list = [[] for _ in range(label.shape[0])]\n",
    "\n",
    "        for i in range(label.shape[0]):\n",
    "            for j in range(label.shape[1]):\n",
    "                if label[i, j] != 0:\n",
    "                    out_label_list[i].append(slot_label_map[label[i][j]])\n",
    "                    preds_list[i].append(slot_label_map[pred_argmax[i][j]])\n",
    "                    \n",
    "        result = self.compute_metrics(out_label_list, preds_list)\n",
    "        results.update(result)\n",
    "\n",
    "        print(\"********\")\n",
    "        print(\"F1 Score\")\n",
    "        for key in sorted(results.keys()):\n",
    "            print(\"{}, {:.4f}\".format(key, results[key]))\n",
    "        print(\"\\n\" + self.show_report(out_label_list, preds_list))\n",
    "        print(\"********\")\n",
    "\n",
    "f1_score_callback = F1Metrics(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "ner_model.compile(optimizer=optimizer, loss=compute_loss, run_eagerly=True)\n",
    "# ner_model.compile(optimizer=optimizer, loss=compute_loss, metrics=[metric], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/KOR/tf2_bert_ner -- Folder already exists \n",
      "\n",
      "Epoch 1/3\n",
      "tf.Tensor(\n",
      "[[[-0.07443924  0.24800523 -0.02131325 ... -0.0199714   0.15805037\n",
      "   -0.10380514]\n",
      "  [-0.40269506 -0.16692697 -0.6325792  ...  0.44971678  0.33717972\n",
      "   -0.10481893]\n",
      "  [-0.497388   -0.5864385  -0.7693258  ...  0.03826445 -0.05193064\n",
      "   -0.16569759]\n",
      "  ...\n",
      "  [ 0.25545835 -0.04935126  0.04217207 ...  0.38775048 -0.1972645\n",
      "   -0.01859268]\n",
      "  [ 0.22117865  0.12915228 -0.07454002 ...  0.48301572  0.07817091\n",
      "    0.02605512]\n",
      "  [ 0.05055051  0.03400309 -0.21688351 ...  0.03196582 -0.16636518\n",
      "   -0.05076252]]\n",
      "\n",
      " [[ 0.07619494 -0.15667984 -1.1669291  ...  0.14204237 -0.15298676\n",
      "    0.20735177]\n",
      "  [-0.00499333 -0.26836598 -0.7267086  ...  0.33563086 -0.0110449\n",
      "    0.35297087]\n",
      "  [ 0.09242608 -0.1499206  -0.78818    ...  0.4012647  -0.13695817\n",
      "    0.29675466]\n",
      "  ...\n",
      "  [ 0.18306959 -0.03468788 -0.7985733  ...  0.3316649  -0.09468274\n",
      "    0.05696651]\n",
      "  [-0.04009705  0.01112057 -1.3552696  ...  0.13506782 -0.20241247\n",
      "    0.10135588]\n",
      "  [-0.09465148  0.0076343  -0.9428734  ...  0.12743309 -0.20859575\n",
      "    0.15455101]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.25654185  1.3269972  -0.7489957  ... -0.9655971  -0.8143296\n",
      "    0.17500843]\n",
      "  [-0.8581743   3.1742148  -0.582418   ... -0.6838247   0.09974688\n",
      "    0.07082779]\n",
      "  [-0.6705809   3.554733   -0.3925336  ... -0.3846753  -0.6346247\n",
      "   -0.01945128]\n",
      "  ...\n",
      "  [-0.60852164  3.6168418  -0.06768963 ... -1.2912122  -0.03250771\n",
      "   -0.30057126]\n",
      "  [-0.34657934  4.4873853  -0.1238151  ... -0.10336818  0.06361368\n",
      "   -0.07551005]\n",
      "  [-0.91676515  3.5570667   0.25618732 ... -0.28243017 -0.30809516\n",
      "   -0.37008604]]\n",
      "\n",
      " [[-0.20125026  3.076334   -0.3019829  ... -0.9141725   0.05745435\n",
      "   -0.2506041 ]\n",
      "  [-0.49687028  4.1043735  -0.13702111 ... -0.8297798  -0.2644005\n",
      "   -0.25024784]\n",
      "  [-0.7404827   4.256695    0.17887151 ... -0.9533306   0.0189263\n",
      "    0.4480285 ]\n",
      "  ...\n",
      "  [-0.08041309  4.370757    0.31668308 ... -0.85948414 -0.5490813\n",
      "   -0.3145591 ]\n",
      "  [-0.7063926   5.0083838   0.3649758  ... -0.71674746  0.12568787\n",
      "   -0.5065663 ]\n",
      "  [-0.54023796  4.438438   -0.09256595 ... -1.3479186  -0.26839593\n",
      "   -0.44806826]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:36.101951 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:36.103462 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/50 [..............................] - ETA: 0s - loss: 1.1207tf.Tensor(\n",
      "[[[ 1.2433099e-01 -7.7975050e-02 -8.7228894e-01 ...  2.9896572e-01\n",
      "    5.0747279e-02  1.4806022e-01]\n",
      "  [ 2.3503663e-01 -2.9677296e-01 -5.6296504e-01 ...  2.8759035e-01\n",
      "    1.5319347e-01  1.5158972e-01]\n",
      "  [ 1.4340948e-01 -2.0895265e-02  3.1281739e-02 ... -2.3118678e-01\n",
      "   -1.2996504e-01 -2.1462013e-01]\n",
      "  ...\n",
      "  [ 2.5344330e-01 -1.5888764e-01 -3.2551700e-01 ... -1.5553352e-01\n",
      "   -2.0303488e-01  1.1983452e-01]\n",
      "  [ 1.2221143e-01  2.3326479e-02 -6.4863753e-01 ...  1.3692570e-01\n",
      "   -4.4130281e-01 -1.3751315e-01]\n",
      "  [ 3.2931414e-01  5.8767468e-02 -6.8074214e-01 ... -7.5803675e-02\n",
      "   -1.2960769e-03  2.2174536e-01]]\n",
      "\n",
      " [[-3.2329053e-02 -1.6198739e-02 -1.3751152e-01 ...  3.8511220e-01\n",
      "    1.3018037e-01  2.1118240e-01]\n",
      "  [-1.4711693e-01 -3.0221438e-01 -1.2786909e+00 ...  1.7345372e-01\n",
      "    1.2048785e-01  2.4047685e-01]\n",
      "  [ 1.8165800e-01 -4.2444348e-01 -1.1135237e+00 ...  1.0356566e-01\n",
      "   -1.5180463e-01 -6.8312734e-03]\n",
      "  ...\n",
      "  [ 1.3710111e-01 -2.6358396e-01 -1.1466630e+00 ...  7.0719367e-01\n",
      "    1.6876221e-02  2.3508203e-01]\n",
      "  [ 1.6712911e-02 -3.8505280e-01 -1.3114448e+00 ... -6.1401151e-02\n",
      "   -1.9707415e-01  3.5559213e-01]\n",
      "  [ 2.6751935e-01 -8.6868942e-02 -1.3024147e+00 ... -1.7084728e-01\n",
      "   -2.1167673e-01  6.7036939e-01]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-3.20924111e-02  2.78699064e+00  2.90348470e-01 ... -1.26346719e+00\n",
      "   -9.52386260e-01  2.66435388e-02]\n",
      "  [-1.95147693e+00  5.74029064e+00 -2.37575263e-01 ... -1.84242952e+00\n",
      "   -6.65581107e-01 -1.77648783e-01]\n",
      "  [-1.12532473e+00  5.55869770e+00  6.27849698e-01 ... -1.23304117e+00\n",
      "    1.59379110e-01  2.47986056e-03]\n",
      "  ...\n",
      "  [-1.43910670e+00  5.65272045e+00  1.23829499e-01 ... -1.55764198e+00\n",
      "   -1.06260848e+00  2.18254298e-01]\n",
      "  [-1.22314584e+00  5.24102163e+00  2.38492593e-01 ... -9.55490232e-01\n",
      "   -4.40130472e-01  3.33528727e-01]\n",
      "  [-1.08519828e+00  4.88244438e+00 -1.21552646e-01 ... -1.57364488e+00\n",
      "   -1.07167518e+00 -3.65387589e-01]]\n",
      "\n",
      " [[-2.94628084e-01  2.24683952e+00 -1.00457281e-01 ... -1.41160274e+00\n",
      "   -9.28481996e-01 -3.83082777e-01]\n",
      "  [-7.98051894e-01  3.93592334e+00  3.44224334e-01 ... -1.30769503e+00\n",
      "    6.89629316e-02 -2.06194729e-01]\n",
      "  [-1.16700971e+00  4.41763496e+00  1.01447618e+00 ... -1.19468796e+00\n",
      "   -2.96771228e-01  3.11321467e-01]\n",
      "  ...\n",
      "  [-5.43620229e-01  4.56933498e+00 -8.76711914e-04 ... -5.91128647e-01\n",
      "    3.60091895e-01 -7.47652113e-01]\n",
      "  [-1.26181448e+00  4.87003803e+00  1.00555420e-01 ... -6.14126444e-01\n",
      "   -1.56196028e-01 -6.96942568e-01]\n",
      "  [-8.28339398e-01  4.98965931e+00  3.60494465e-01 ... -6.51917219e-01\n",
      "    1.80007756e-01  2.94434816e-01]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:36.699764 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:36.701286 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/50 [>.............................] - ETA: 7s - loss: 0.9253tf.Tensor(\n",
      "[[[ 0.12091741  0.17787883 -0.43745708 ... -0.0335957  -0.00658043\n",
      "    0.00756799]\n",
      "  [ 0.4036661   0.7750824  -0.15617588 ...  0.1775846  -0.11455399\n",
      "    0.17278141]\n",
      "  [ 0.6079567  -0.01935063 -0.09362912 ...  0.32765418  0.19244489\n",
      "   -0.31727928]\n",
      "  ...\n",
      "  [ 0.15666397  0.5032347   0.10561304 ...  0.55810255 -0.29337856\n",
      "    0.11589751]\n",
      "  [ 0.19561337 -0.03576734 -0.12526375 ... -0.08428595 -0.13879427\n",
      "    0.15857942]\n",
      "  [-0.17123826 -0.12344179 -0.37702712 ...  0.20981991  0.29825002\n",
      "    0.15912986]]\n",
      "\n",
      " [[ 0.37964484  0.14706509 -0.3431179  ...  0.18491584  0.06459381\n",
      "    0.47014284]\n",
      "  [ 0.46691167  0.01011347 -0.08948401 ...  0.02671723  0.23768239\n",
      "    0.77586895]\n",
      "  [ 0.44910833  0.12127022 -0.24817225 ...  0.28868687 -0.18004084\n",
      "    0.5645289 ]\n",
      "  ...\n",
      "  [ 0.4933225   0.21431433 -0.26231366 ...  0.3692086  -0.24651214\n",
      "    0.521429  ]\n",
      "  [ 0.6138916   0.23157576  0.02333641 ...  0.5712595  -0.15962455\n",
      "    0.35604328]\n",
      "  [ 0.7569884   0.48473406 -0.36762768 ...  0.07073092 -0.21803802\n",
      "    0.5563423 ]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.09179618  1.3786137  -0.14750199 ... -0.46694398 -0.03069302\n",
      "   -0.74581206]\n",
      "  [-0.8663768   2.461109   -0.78142875 ... -1.0788125  -0.05863347\n",
      "    0.24060008]\n",
      "  [-0.4241086   1.9895852   0.06593718 ... -0.613696    0.5603684\n",
      "   -0.5455467 ]\n",
      "  ...\n",
      "  [-0.06182336  4.285264   -0.67556953 ...  0.34059122  0.15584147\n",
      "    0.06048864]\n",
      "  [ 0.2154158   2.6094043  -0.11576703 ... -0.2925976   0.27838406\n",
      "   -0.1383897 ]\n",
      "  [ 0.11997975  3.3863099   0.57722175 ... -0.42879638 -0.5750727\n",
      "    0.06501332]]\n",
      "\n",
      " [[ 0.1153974   3.7442327   0.32979384 ... -1.1207713  -1.2381438\n",
      "    0.09517187]\n",
      "  [-1.4244828   4.571047    0.0505272  ... -1.1426516  -0.4025655\n",
      "    0.91128457]\n",
      "  [-1.3621705   5.263656    0.27522162 ... -1.2077299  -0.6163544\n",
      "    0.12906212]\n",
      "  ...\n",
      "  [-0.4635052   4.7851014   0.16050895 ... -0.89268506 -0.15830329\n",
      "   -0.54029393]\n",
      "  [-2.108715    6.692896    0.4753165  ... -1.0434185  -0.22066803\n",
      "   -0.3193969 ]\n",
      "  [-1.4559872   5.00712     0.36750454 ... -1.109302   -0.77406263\n",
      "   -0.28875768]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:37.002016 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:37.003476 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/50 [>.............................] - ETA: 9s - loss: 1.1558tf.Tensor(\n",
      "[[[-0.02707453  0.06339432 -0.56469893 ...  0.03701512  0.08968805\n",
      "    0.20232914]\n",
      "  [-0.04994207 -0.42812756 -0.01025918 ...  0.4916075   0.6061877\n",
      "    0.05110875]\n",
      "  [ 0.12784986  0.5087373   0.31001046 ...  0.97569996  0.54126143\n",
      "    0.13998207]\n",
      "  ...\n",
      "  [ 0.51093185  0.56613946  0.17436771 ...  0.16432735  0.3963673\n",
      "    0.23925334]\n",
      "  [ 0.63094753  0.22842896  0.21835116 ...  0.17427029  0.30135334\n",
      "    0.41589427]\n",
      "  [ 0.42667115  0.11130663  0.09016742 ...  0.47373444  0.2229301\n",
      "    0.24694125]]\n",
      "\n",
      " [[-0.00949082  0.10907927 -0.940733   ...  0.31956345  0.28005192\n",
      "    0.22155473]\n",
      "  [-0.19209684 -0.3788687  -0.6552747  ...  0.6530351   0.5068382\n",
      "    0.7096187 ]\n",
      "  [ 0.16956048 -0.18899417 -0.5099542  ...  0.52477276  0.20355262\n",
      "    0.453044  ]\n",
      "  ...\n",
      "  [ 0.3402422  -0.1487709  -0.7788224  ...  0.9287153   0.30703717\n",
      "    0.23326425]\n",
      "  [ 0.03400918 -0.06527546 -0.78922296 ...  0.8367818   0.04295072\n",
      "    0.27087426]\n",
      "  [ 0.3747217  -0.10564937 -0.41939875 ...  0.90977544  0.49038452\n",
      "    0.3307979 ]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.13645667  0.45443398  0.18316366 ... -1.0377926  -1.1585591\n",
      "   -0.2588511 ]\n",
      "  [-0.5086691   2.6965196  -0.1713063  ... -1.3219101  -0.15048936\n",
      "   -0.06663867]\n",
      "  [-0.81857765  1.772342   -0.7982084  ... -1.5510044  -0.45955956\n",
      "    0.9749222 ]\n",
      "  ...\n",
      "  [-0.67654175  1.6777225  -0.3649723  ... -0.4085453   1.1858037\n",
      "    0.18927878]\n",
      "  [-0.7357062   2.4733384   0.5696913  ...  0.07129576  0.48751506\n",
      "    0.28488493]\n",
      "  [-0.7044098   2.6537855   0.49971202 ...  0.042995    0.4277535\n",
      "   -0.5883722 ]]\n",
      "\n",
      " [[ 0.05122865  3.286033   -0.43801224 ... -1.2603126  -0.9923288\n",
      "    0.39736447]\n",
      "  [-1.3064035   5.945246   -0.14434369 ... -1.3063365  -0.09682577\n",
      "   -0.06453233]\n",
      "  [-0.6184667   5.8858457  -0.02341361 ... -0.9553344  -0.7933246\n",
      "    0.58065605]\n",
      "  ...\n",
      "  [-0.8191863   6.2634263   0.5465334  ... -1.3473347  -0.27823323\n",
      "   -0.9721413 ]\n",
      "  [-0.45701465  7.04347     0.6259305  ... -1.2225634  -0.42057285\n",
      "    0.44713426]\n",
      "  [-0.9407013   6.879522    0.06317388 ... -1.0892624  -0.76633245\n",
      "   -0.08148416]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:37.314431 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:37.315898 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/50 [=>............................] - ETA: 10s - loss: 1.2817tf.Tensor(\n",
      "[[[ 0.3267191   0.14357321 -0.82271945 ...  0.7726398   0.2080428\n",
      "    0.3104596 ]\n",
      "  [ 0.52326024 -0.2843689  -0.5089729  ...  0.3716668   0.10364316\n",
      "    0.19255194]\n",
      "  [ 0.40628317  0.1462273  -0.4734526  ...  0.5229182  -0.05199898\n",
      "    0.15592836]\n",
      "  ...\n",
      "  [ 0.31033573 -0.12839115 -0.07337862 ...  0.43199635 -0.21864232\n",
      "    0.57176566]\n",
      "  [ 0.15042514 -0.0025755  -0.11571005 ...  0.3200792  -0.09418477\n",
      "    0.7860855 ]\n",
      "  [ 0.12858813  0.21609117 -0.00346324 ...  0.8145499  -0.23722735\n",
      "    0.5047684 ]]\n",
      "\n",
      " [[-0.02458411  0.26347607 -0.26619214 ...  0.11196942  0.22109278\n",
      "    0.0917889 ]\n",
      "  [ 0.2446397   0.04127125 -0.9598513  ... -0.34811267  0.33601546\n",
      "    0.14397004]\n",
      "  [ 0.14141208  0.24700567 -0.08236915 ... -0.31920528  0.42760202\n",
      "   -0.09140822]\n",
      "  ...\n",
      "  [-0.30127826  0.0126216  -0.44530612 ...  0.08870154 -0.16299501\n",
      "   -0.15924475]\n",
      "  [ 0.02708641  0.03611124 -0.33671454 ...  0.9743847   0.3216643\n",
      "   -0.00601815]\n",
      "  [-0.12147571  0.27409863 -0.43121463 ...  0.46155626  0.5390624\n",
      "    0.4155691 ]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.40572625  3.0125117   0.35760763 ... -1.7055683  -0.77899224\n",
      "    0.19027507]\n",
      "  [-1.4032882   4.962961    0.30123124 ... -0.90887886  0.34265175\n",
      "    0.09094427]\n",
      "  [-1.1491405   5.070636    0.02907628 ... -0.83760965 -0.05614909\n",
      "    0.6165436 ]\n",
      "  ...\n",
      "  [-1.0124236   4.5683823   0.22643042 ... -1.1671687  -0.03108909\n",
      "    0.4279457 ]\n",
      "  [-1.3029065   4.900139    0.21049568 ... -0.81611407  0.37729144\n",
      "    0.6012188 ]\n",
      "  [-1.5623362   5.362953   -0.40240616 ... -1.0313612  -0.10516556\n",
      "    0.43802136]]\n",
      "\n",
      " [[ 0.28936097  0.81204754 -0.36199078 ... -0.7487537  -0.49372095\n",
      "    0.33985698]\n",
      "  [-0.7067451   2.4520965  -0.8307729  ... -1.5509157  -0.34707162\n",
      "    0.50833094]\n",
      "  [-0.8968691   3.3588653   0.39274764 ... -0.26864943 -0.29619688\n",
      "   -0.3627513 ]\n",
      "  ...\n",
      "  [-1.535505    2.978908   -0.45087036 ... -0.74117815 -1.1413622\n",
      "    0.66326106]\n",
      "  [-0.13871412  4.1137686  -0.10673829 ... -0.5782103  -0.6009603\n",
      "    0.49521047]\n",
      "  [-0.46906534  4.124355   -0.22508514 ... -0.28823158 -1.0348498\n",
      "    0.17778946]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:37.635703 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:37.637937 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/50 [==>...........................] - ETA: 11s - loss: 1.1986tf.Tensor(\n",
      "[[[ 0.10430133  0.08953271 -0.36675438 ...  0.36195415  0.16151658\n",
      "    0.03467861]\n",
      "  [-0.22250359 -0.3334303  -0.80111074 ...  0.60524184  0.59272903\n",
      "   -0.1554309 ]\n",
      "  [ 0.976337    0.0633807   0.01543781 ...  0.63673663  0.65947944\n",
      "   -0.3896357 ]\n",
      "  ...\n",
      "  [ 0.08846288 -0.11462159 -0.8323675  ...  0.40718377  0.51345605\n",
      "    0.24673524]\n",
      "  [ 0.48533046  0.28254837 -0.5335032  ...  0.21943712  0.0316106\n",
      "    0.13011573]\n",
      "  [ 0.15112737 -0.14165305  0.2846888  ...  0.50318706  0.00391639\n",
      "    0.51422495]]\n",
      "\n",
      " [[ 0.19942394  0.36768076 -0.18706805 ...  0.19749644  0.19219911\n",
      "    0.37459272]\n",
      "  [-0.1871873   0.1449609  -0.40619254 ...  0.3212599   0.91593945\n",
      "    0.8187309 ]\n",
      "  [ 0.67335755 -0.18037121 -0.53261936 ...  0.00159602  0.6870138\n",
      "    0.3984916 ]\n",
      "  ...\n",
      "  [ 0.26276544 -0.20111339 -0.04112053 ... -0.04102193  0.1472848\n",
      "    0.4153378 ]\n",
      "  [ 0.05014079 -0.49471655  0.29945728 ...  0.2927215   0.34448525\n",
      "    0.80324   ]\n",
      "  [ 0.2797907   0.39160967  0.01952052 ...  0.02922265  0.63523835\n",
      "    0.5433661 ]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.7640131   0.6072704   0.0484516  ... -0.7375682  -1.0270174\n",
      "   -0.31193492]\n",
      "  [-0.47276074  4.0944004  -0.09304817 ... -1.6258649  -0.81320167\n",
      "    0.41879407]\n",
      "  [-0.41071442  3.7459903   1.0625967  ... -1.0998695  -2.0569954\n",
      "    0.05038456]\n",
      "  ...\n",
      "  [-0.3666587   3.5078144  -0.47598886 ... -0.53379774  0.17125918\n",
      "    0.4840437 ]\n",
      "  [-0.7089116   3.2866218  -0.47515395 ... -0.04261746 -0.6874411\n",
      "    0.11359436]\n",
      "  [-0.3125986   3.5557408   0.14160791 ... -0.12151612 -0.22241147\n",
      "   -0.20251055]]\n",
      "\n",
      " [[ 0.37777334  2.2927766  -0.09692772 ... -1.1282507  -0.21427251\n",
      "   -0.65009004]\n",
      "  [-1.1243627   2.2058823   1.214989   ... -0.639764   -0.82030314\n",
      "    0.8714537 ]\n",
      "  [-1.0517007   3.0463028   0.9904162  ... -1.5395496  -0.6857053\n",
      "    0.01666803]\n",
      "  ...\n",
      "  [-1.4478201   2.290235    0.39902946 ... -1.640865   -0.48892307\n",
      "   -0.59677   ]\n",
      "  [-0.93507206  3.0857816   0.4416988  ... -1.0232639  -0.18749145\n",
      "   -0.07307633]\n",
      "  [-0.86976117  2.3321362   1.208327   ... -0.64722174  0.01117987\n",
      "   -0.39219707]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:38.066971 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:38.068750 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/50 [==>...........................] - ETA: 12s - loss: 1.2403tf.Tensor(\n",
      "[[[ 0.0185107   0.3889622  -0.90924495 ...  0.4308744   0.18360311\n",
      "    0.26380712]\n",
      "  [ 0.04947934  0.22802344 -0.41288665 ...  0.5102527   0.38827685\n",
      "   -0.02004535]\n",
      "  [ 0.30114484  0.48366743 -0.23604447 ...  0.40030938  0.80857426\n",
      "    0.23987871]\n",
      "  ...\n",
      "  [ 0.55859244  0.07379024 -1.7390381  ...  0.66867167  0.08954856\n",
      "   -0.01739896]\n",
      "  [ 0.45154303  0.3540746  -1.2207863  ...  0.9016598   0.08297215\n",
      "    0.11864657]\n",
      "  [ 0.3816815   0.26794776 -0.7741056  ...  1.0555059   0.28972927\n",
      "    0.22472909]]\n",
      "\n",
      " [[ 0.06001178  0.17913108 -0.53430355 ...  0.13458829  0.06300414\n",
      "   -0.01657979]\n",
      "  [-0.22918057 -0.11195509 -1.1912218  ...  1.0497248   0.12951425\n",
      "   -0.235225  ]\n",
      "  [-0.25526807  0.27632245 -0.55515814 ...  0.58491206  0.17313346\n",
      "    0.09845532]\n",
      "  ...\n",
      "  [-0.24985282  0.25449523  0.12112086 ...  0.22525874  0.27900767\n",
      "   -0.10822768]\n",
      "  [-0.22846209  0.17193292 -0.21680933 ...  1.0149875   0.06215579\n",
      "   -0.65306187]\n",
      "  [ 0.00193155  0.13476701  0.1870601  ...  0.7471142   0.41483885\n",
      "   -0.35587835]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.34984282  3.6283786  -0.07179777 ... -0.96918386 -0.5354749\n",
      "    0.55727756]\n",
      "  [-1.3339398   3.8777568   1.8279788  ... -1.0325484  -0.701072\n",
      "   -0.35947755]\n",
      "  [-1.5520321   3.760212    1.5179598  ...  0.16313331 -0.86645854\n",
      "   -0.03482878]\n",
      "  ...\n",
      "  [-1.2768246   6.6116486   0.36142555 ... -1.2213145   0.56396055\n",
      "   -0.6749965 ]\n",
      "  [-0.7211416   6.6433167  -0.04848381 ... -1.672685    0.4647089\n",
      "   -0.37657717]\n",
      "  [-0.3547354   6.61311     0.08031269 ... -1.0479447  -0.4068572\n",
      "   -0.45588163]]\n",
      "\n",
      " [[ 0.496643    1.0540369  -0.26423898 ... -1.43298    -1.4117534\n",
      "    0.08487451]\n",
      "  [-0.25409836  5.019647   -1.0457712  ... -1.5605272  -0.9561705\n",
      "    0.38561732]\n",
      "  [ 0.2893689   4.952325    0.6229763  ... -0.9133466   0.24169976\n",
      "   -0.48932958]\n",
      "  ...\n",
      "  [-0.53709763  3.7715003   0.10254482 ... -0.05096402 -0.03606053\n",
      "   -0.58300906]\n",
      "  [ 0.44570404  5.4649243   0.46830344 ...  0.33108547  0.32875672\n",
      "   -1.1344856 ]\n",
      "  [ 0.25239384  5.310617   -0.32085764 ...  0.57112813  0.3434525\n",
      "   -1.3176081 ]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:38.417980 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:38.419396 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 7/50 [===>..........................] - ETA: 12s - loss: 1.1446tf.Tensor(\n",
      "[[[ 0.11343397 -0.02315342 -0.46622023 ...  0.3244945   0.08992109\n",
      "   -0.1698819 ]\n",
      "  [ 0.32477835  0.01557674  0.43695667 ...  1.1285846   0.2564889\n",
      "   -0.10824956]\n",
      "  [ 0.65005344 -0.34906167 -0.8641666  ...  0.568784    0.47370696\n",
      "    0.5693648 ]\n",
      "  ...\n",
      "  [ 0.36599222  0.35931492  0.36387917 ...  0.3405664   0.04133314\n",
      "    0.228023  ]\n",
      "  [ 0.16987498  0.04460997 -0.32145387 ...  0.4660999   0.3392039\n",
      "   -0.00184212]\n",
      "  [ 0.08654428 -0.27981713 -0.02508104 ... -0.09371141  0.41647476\n",
      "   -0.11086178]]\n",
      "\n",
      " [[-0.05341849  0.16199756 -0.22979787 ...  0.32295966  0.16490777\n",
      "    0.24773757]\n",
      "  [-0.05786699 -0.44303626  0.05435705 ...  0.4607816   0.6478481\n",
      "   -0.0626742 ]\n",
      "  [-0.28960603 -0.21889846  0.22224608 ... -0.01408732  0.4532699\n",
      "    0.4594182 ]\n",
      "  ...\n",
      "  [-0.14953092  0.20191702 -0.16509467 ...  0.11751957  0.3551899\n",
      "    0.16068244]\n",
      "  [-0.01214106  0.20305565  0.46310782 ...  0.742031    0.31815985\n",
      "    0.8197392 ]\n",
      "  [-0.06486445  0.03078596  0.5639961  ...  0.9156927   0.21605724\n",
      "    0.45937106]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.2900949   1.1469873   0.02776502 ... -0.6796786  -0.4327703\n",
      "    0.26708296]\n",
      "  [-1.3489833   6.5268807   0.30114448 ... -1.5306333  -0.64130306\n",
      "   -0.5969532 ]\n",
      "  [-0.4387646   5.524317    0.791987   ... -1.5935413  -0.7535392\n",
      "   -0.15137903]\n",
      "  ...\n",
      "  [-0.8599386   3.3880575   0.24071655 ...  0.14769155  0.46519613\n",
      "   -0.4393868 ]\n",
      "  [-0.50369465  3.4042358   0.59747636 ... -0.3143085   0.48076445\n",
      "    0.5181535 ]\n",
      "  [ 0.10034006  4.2498703   0.11405615 ... -0.5314541  -0.2543722\n",
      "   -1.0361996 ]]\n",
      "\n",
      " [[ 0.88399315  2.3504348  -0.17257425 ... -0.8471631  -0.69316983\n",
      "    0.37318996]\n",
      "  [-1.3256521   4.174482   -0.61438406 ... -1.178192   -0.49313188\n",
      "    0.65095717]\n",
      "  [-1.0679581   4.151676   -0.11672142 ... -0.8089917  -0.69309473\n",
      "   -0.29928204]\n",
      "  ...\n",
      "  [-0.73200095  3.5336428   0.729359   ... -0.26216683 -0.06333659\n",
      "   -0.02429843]\n",
      "  [-0.58397335  4.029741    0.06538829 ... -0.684749   -1.0358793\n",
      "   -0.37487724]\n",
      "  [-0.89405704  4.309803    0.44018683 ... -0.4273375  -0.68954194\n",
      "   -0.54745334]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:38.757402 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:38.758815 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/50 [===>..........................] - ETA: 12s - loss: 1.2479tf.Tensor(\n",
      "[[[ 0.34739223 -0.14923362 -0.85922635 ...  0.45530286  0.0777873\n",
      "    0.5357335 ]\n",
      "  [-0.07961209 -0.4552495  -0.8265435  ...  1.1469226   0.16127267\n",
      "    0.32571083]\n",
      "  [ 0.44099864 -0.1630134  -0.06860355 ...  1.1524965  -0.27471188\n",
      "    0.5355999 ]\n",
      "  ...\n",
      "  [ 0.79702616  0.08112405 -0.28102565 ...  0.391427    0.07707265\n",
      "    0.9570103 ]\n",
      "  [ 0.26381958 -0.22962746 -0.01012871 ...  0.62295514 -0.07096347\n",
      "    0.93980694]\n",
      "  [ 0.18563415  0.02854487 -0.0435186  ...  0.60955864 -0.02772327\n",
      "    0.8537201 ]]\n",
      "\n",
      " [[ 0.22908048 -0.07369515 -0.66198236 ...  0.2728032   0.5413142\n",
      "    0.13058582]\n",
      "  [ 0.43294933  0.02254111  0.22324285 ...  0.11194739  0.66540414\n",
      "    0.46246877]\n",
      "  [-0.05990149  0.06746811 -0.8555517  ...  0.40206838  0.23128802\n",
      "    0.34885585]\n",
      "  ...\n",
      "  [ 0.25552353  0.38460535  0.5162239  ...  0.28634763  0.7450752\n",
      "    0.13682637]\n",
      "  [ 0.31793374  0.08416631 -0.11229461 ...  0.40723842  0.5278444\n",
      "    0.4242002 ]\n",
      "  [ 0.2045141  -0.06678884  0.6095567  ...  0.23354882  0.6016771\n",
      "    0.37477398]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 5.0032020e-01  6.1591492e+00  6.6816217e-01 ... -1.1020346e+00\n",
      "   -3.6133996e-01 -2.7345550e-01]\n",
      "  [-1.7700979e-01  7.3563557e+00  9.1169730e-02 ... -1.8910257e+00\n",
      "   -8.8444757e-01 -5.2656686e-01]\n",
      "  [-5.8731735e-02  6.8299742e+00 -3.9667645e-01 ... -1.8941042e+00\n",
      "   -9.6857822e-01 -1.2199993e+00]\n",
      "  ...\n",
      "  [-3.9321080e-01  6.7823944e+00  1.4851848e+00 ... -5.6891668e-01\n",
      "   -3.5135812e-01  7.2456427e-02]\n",
      "  [-1.4428726e+00  6.5364633e+00  5.2223557e-01 ... -7.6574063e-01\n",
      "   -6.7524111e-01 -2.8866401e-01]\n",
      "  [-1.1807646e+00  7.6000519e+00  6.3253236e-01 ... -7.2001368e-02\n",
      "   -3.2432696e-01 -9.8929986e-02]]\n",
      "\n",
      " [[-4.7637534e-01  3.0386784e+00 -1.4596771e-01 ... -1.8864958e+00\n",
      "   -1.1289191e+00  1.8573129e-01]\n",
      "  [-8.2057077e-01  3.8885140e+00 -4.1041588e-03 ... -1.9672250e+00\n",
      "   -5.5590546e-01 -4.2159835e-01]\n",
      "  [-3.5922539e-01  3.7260189e+00  1.1463128e+00 ... -1.2400156e+00\n",
      "    3.9441249e-01 -4.4216629e-02]\n",
      "  ...\n",
      "  [-5.3723961e-01  3.4087031e+00  3.3057520e-01 ... -1.4216384e+00\n",
      "   -1.5540528e-01 -3.2177854e-01]\n",
      "  [-9.4480890e-01  4.1183038e+00  2.1959354e-01 ... -9.8407376e-01\n",
      "   -6.4382112e-01 -8.7694746e-01]\n",
      "  [-6.9932538e-01  4.5223589e+00  5.9996444e-01 ... -1.2180831e+00\n",
      "   -5.2043808e-01 -1.1406631e+00]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:39.101481 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:39.102923 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/50 [====>.........................] - ETA: 12s - loss: 1.2952tf.Tensor(\n",
      "[[[ 0.23810631 -0.00514393 -0.63531935 ...  0.53126824  0.4878931\n",
      "    0.2712312 ]\n",
      "  [-0.2927592  -0.06507796 -0.36047226 ...  0.97162503  0.5572517\n",
      "    0.031409  ]\n",
      "  [ 0.7194402   0.5215344   0.48527172 ...  0.4919303   0.4783795\n",
      "    0.24834782]\n",
      "  ...\n",
      "  [ 0.48780724  0.19788003 -0.8921285  ...  0.53957945  0.04769599\n",
      "    0.17067164]\n",
      "  [ 0.5432632   0.275411   -0.38775614 ...  0.19232783  0.20082694\n",
      "    0.5871106 ]\n",
      "  [ 0.8355129   0.31545335 -0.44046172 ...  0.46982342  0.4151628\n",
      "    0.7169848 ]]\n",
      "\n",
      " [[ 0.25806057 -0.01967619 -0.7187487  ...  0.2733629   0.05540989\n",
      "    0.44150645]\n",
      "  [-0.09747179 -0.2748967   1.1574316  ...  0.9228022  -0.42241073\n",
      "    0.9964894 ]\n",
      "  [ 0.03608075 -0.37683398  0.27040383 ...  0.50252056 -0.3650557\n",
      "    1.2947664 ]\n",
      "  ...\n",
      "  [ 0.44657737  0.02533473 -0.62067556 ...  0.67933077  0.14718759\n",
      "    0.16517329]\n",
      "  [ 0.69704926  0.1993094   0.17596363 ...  0.89743745  0.34098592\n",
      "    0.4159341 ]\n",
      "  [ 0.13286223  0.08826707  0.00431216 ...  0.8952005   0.35775766\n",
      "    0.88772136]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.09646524  1.8819396   0.61772346 ... -1.801417   -1.4944775\n",
      "    0.29392383]\n",
      "  [-1.5559585   2.2543046   0.5065312  ... -1.7069513  -1.2759144\n",
      "   -1.0233282 ]\n",
      "  [-2.8479865   1.064518    1.6224132  ... -0.469623   -2.2063293\n",
      "    0.2939828 ]\n",
      "  ...\n",
      "  [-1.5355449   3.0060494   0.39047655 ... -0.9399632  -0.7528085\n",
      "    0.05034123]\n",
      "  [-1.836142    3.4993393   0.68674815 ... -0.9890953  -0.8723664\n",
      "    0.25622895]\n",
      "  [-1.5657159   2.7416415   0.5649298  ... -1.2759078  -0.80473584\n",
      "   -0.6687356 ]]\n",
      "\n",
      " [[-0.1521659   4.326579   -0.3351148  ... -1.6768254  -1.2011135\n",
      "   -0.5758854 ]\n",
      "  [-1.191905    5.8230515   0.5463351  ... -2.096685   -0.06544614\n",
      "   -0.04194219]\n",
      "  [-1.4927847   7.3856487   0.081071   ... -1.9831364  -0.5738326\n",
      "    0.80743414]\n",
      "  ...\n",
      "  [-1.7128325   7.4652433  -0.78451276 ... -1.482693   -0.14372548\n",
      "   -0.49039727]\n",
      "  [-0.2616772   7.950987    0.34328437 ... -0.89974344  0.03381738\n",
      "   -0.71688026]\n",
      "  [-0.99221116  6.1402893   0.5249535  ... -0.90691    -0.1623635\n",
      "    0.38687226]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:39.452291 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:39.453831 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/50 [=====>........................] - ETA: 12s - loss: 1.4091tf.Tensor(\n",
      "[[[ 0.14637022  0.11426764 -0.58043724 ...  0.32282007  0.0956039\n",
      "   -0.03762397]\n",
      "  [-0.355387   -0.23371993  0.08454908 ... -0.6091751   0.8522158\n",
      "    0.36043906]\n",
      "  [ 0.32995397 -0.11021504 -0.5337098  ...  0.51247615  0.3950597\n",
      "   -0.24171361]\n",
      "  ...\n",
      "  [-0.0100745  -0.06881858 -0.00922298 ...  0.5479399   0.02510991\n",
      "    0.71182525]\n",
      "  [ 0.1637453   0.24770087 -0.29225442 ...  0.58248305 -0.04511673\n",
      "    0.5653794 ]\n",
      "  [ 0.5533381  -0.13427424  0.524014   ...  0.19804762  0.5235097\n",
      "   -0.06741232]]\n",
      "\n",
      " [[-0.10869975 -0.11473026 -0.4014783  ...  0.19623154  0.17908317\n",
      "   -0.12221663]\n",
      "  [ 0.00463295 -0.09600793  0.11226116 ...  1.3416728   0.17502931\n",
      "    0.17969324]\n",
      "  [-0.2741377  -0.31022155 -0.48043177 ...  0.84808314  0.35110024\n",
      "    0.6015091 ]\n",
      "  ...\n",
      "  [-0.31598574 -0.00844481  0.07380147 ...  1.0447005   0.4188996\n",
      "   -0.46366173]\n",
      "  [-0.27479127 -0.12177087  0.29607353 ...  1.5798637   0.39347693\n",
      "   -0.09640031]\n",
      "  [ 0.02220846 -0.09906498  0.30761868 ...  1.2801774   0.5963767\n",
      "   -0.47365826]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.2129236   0.94810617 -0.32908177 ... -1.1825751  -0.7111034\n",
      "    0.19942404]\n",
      "  [-0.5760043   4.0442257   0.22971523 ... -1.2468272  -0.24130823\n",
      "    0.52535194]\n",
      "  [-0.7668739   5.1935434  -0.01648841 ... -1.0116432  -0.32514426\n",
      "    1.3946885 ]\n",
      "  ...\n",
      "  [-0.10916377  3.7734277   0.0777313  ... -0.3670615   0.29172334\n",
      "    0.13840264]\n",
      "  [ 0.3224975   3.0126824   0.48598078 ... -0.59848934 -0.11254411\n",
      "    0.19337797]\n",
      "  [-0.869324    5.5575514   0.6034364  ... -0.9508599   0.24491073\n",
      "    0.16542427]]\n",
      "\n",
      " [[ 0.25047326  0.88356483 -0.01881774 ... -0.88490725 -0.8529028\n",
      "    0.03288104]\n",
      "  [-0.518187    5.840145    0.21002737 ... -0.38271073 -0.6581139\n",
      "    0.921651  ]\n",
      "  [-0.636664    4.4352226   1.0160016  ... -0.8322273  -0.61621493\n",
      "    0.7715034 ]\n",
      "  ...\n",
      "  [-0.1827425   6.896353    0.36699414 ... -0.6695067  -0.8311026\n",
      "   -0.31768584]\n",
      "  [ 0.42332244  6.6814003   0.9329715  ... -0.6648491  -0.7723644\n",
      "   -0.2986125 ]\n",
      "  [-0.03150344  5.9368534   0.90754193 ...  0.38227886 -0.70014924\n",
      "    0.36848292]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:39.767447 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:39.769222 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/50 [=====>........................] - ETA: 11s - loss: 1.3938tf.Tensor(\n",
      "[[[ 0.22503552  0.02869108 -0.47576174 ...  0.26698315  0.05816631\n",
      "    0.47592607]\n",
      "  [ 0.50278187  0.3645808  -0.03345862 ...  0.4885324   0.62683946\n",
      "    0.51966405]\n",
      "  [ 0.5435878   0.06249581  0.27029616 ...  0.03713716  0.3589834\n",
      "    0.6142628 ]\n",
      "  ...\n",
      "  [ 0.4353009   0.362906   -0.12274846 ...  0.2578777   0.29406738\n",
      "    0.2948125 ]\n",
      "  [ 0.30620205  0.08706452 -0.07132545 ...  0.5048328  -0.04627674\n",
      "    0.775682  ]\n",
      "  [ 0.6571654   0.40081507 -0.15986934 ...  0.6192552   0.2502951\n",
      "    0.73608404]]\n",
      "\n",
      " [[ 0.4065083   0.00788276 -0.5628518  ...  0.1794493  -0.14144695\n",
      "    0.5947923 ]\n",
      "  [ 0.7081712  -0.16910428 -0.66282946 ...  0.18093449  0.08200198\n",
      "    0.38397858]\n",
      "  [ 0.6226412   0.3943358  -0.03934196 ...  0.26119226 -0.01595322\n",
      "    0.6202468 ]\n",
      "  ...\n",
      "  [ 1.1942414   0.52835804 -0.6417072  ...  0.2965353   0.12168935\n",
      "    0.58344406]\n",
      "  [ 0.8709417   0.12215406 -0.62033296 ... -0.3639409  -0.40216777\n",
      "    0.48331946]\n",
      "  [ 0.61940455  0.41066626 -0.36036718 ...  0.20302738  0.19002399\n",
      "    0.5676817 ]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.14079899  1.1707263  -0.11737765 ... -1.5117857  -1.0184761\n",
      "   -0.446097  ]\n",
      "  [-1.0519725   1.5033705   1.7525841  ... -1.9001648  -1.3658893\n",
      "   -0.18634874]\n",
      "  [-1.028819    1.699898    1.5371943  ... -0.5741174  -0.5149979\n",
      "    0.13313739]\n",
      "  ...\n",
      "  [-0.99006253  3.803222    0.8648945  ... -1.4158336  -0.6316105\n",
      "   -0.15907907]\n",
      "  [-0.78294927  4.380646    0.54071903 ... -1.5708102  -0.49906725\n",
      "   -0.7023962 ]\n",
      "  [-1.3578323   4.8602686   0.02859016 ... -1.7138177  -0.36142695\n",
      "    0.2221922 ]]\n",
      "\n",
      " [[ 0.0269712   3.387773    0.15259449 ... -1.6929656  -1.2639778\n",
      "    0.8266836 ]\n",
      "  [-1.2120833   4.564573    1.0178326  ... -1.9077736  -0.9111099\n",
      "    1.623447  ]\n",
      "  [-1.2949284   3.4604669   0.52845967 ... -2.1875615   0.08002523\n",
      "    0.5951483 ]\n",
      "  ...\n",
      "  [ 0.20063585  5.9799604   0.34410366 ... -1.8912328   0.6626228\n",
      "    0.9270883 ]\n",
      "  [-0.07892803  4.7386103   0.22855112 ... -1.6564571  -0.15276405\n",
      "    0.42041233]\n",
      "  [-0.5298791   4.6533422   0.599855   ... -1.892516    0.62771916\n",
      "    0.72684073]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:40.110121 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:40.111548 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/50 [======>.......................] - ETA: 11s - loss: 1.4283tf.Tensor(\n",
      "[[[ 0.20618625  0.263678   -0.329118   ...  0.5004324   0.34752792\n",
      "    0.10614784]\n",
      "  [ 0.7758904   0.23542318  0.00202459 ...  0.8103794   0.36781797\n",
      "   -0.10286154]\n",
      "  [ 0.34542477 -0.15128578  0.5866106  ...  0.45643926  0.3260874\n",
      "   -0.14645526]\n",
      "  ...\n",
      "  [ 0.64632565 -0.09533376 -0.5887666  ...  0.492011    0.36903742\n",
      "   -0.2647433 ]\n",
      "  [ 0.75722796  0.26851255 -0.05915526 ...  0.2112911   0.21634953\n",
      "   -0.01682971]\n",
      "  [ 0.73034847  0.31994992 -0.20539477 ...  0.24824984  0.17408268\n",
      "    0.06458435]]\n",
      "\n",
      " [[ 0.18882455  0.25457817 -0.3733333  ...  0.03626493  0.13848476\n",
      "   -0.03957519]\n",
      "  [-0.20696777  0.04879305 -0.35135135 ...  1.2526258  -0.09867741\n",
      "   -0.17153645]\n",
      "  [ 0.4134841   0.01936951 -0.34480697 ...  0.5586119  -0.1669768\n",
      "   -0.57447183]\n",
      "  ...\n",
      "  [ 0.8805199   0.81405985  0.3859915  ... -0.14498408 -0.6875605\n",
      "    0.19211254]\n",
      "  [ 1.2575729   0.3274331   0.5102316  ... -0.21385393 -0.58263695\n",
      "    0.37356445]\n",
      "  [ 1.5641334   0.65995306  0.3350651  ... -0.3580795  -0.5089797\n",
      "    0.18445793]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[-0.62305284  0.1372467   0.00755274 ... -1.3063763  -1.2602962\n",
      "    0.3152217 ]\n",
      "  [-2.2155566   0.76107156  0.3792176  ... -0.85423905  0.6592294\n",
      "    0.7066049 ]\n",
      "  [-1.6726921   1.0000601  -0.41234547 ... -0.81577563 -0.17644772\n",
      "    0.04294754]\n",
      "  ...\n",
      "  [-0.82869583  1.526737    1.8257482  ... -0.32279414 -0.73496515\n",
      "    1.1171105 ]\n",
      "  [-1.8424138   0.46036088  1.0338686  ...  0.05713006  0.5712928\n",
      "    0.22085573]\n",
      "  [-1.516739    0.3008305   0.7131452  ... -1.7117136  -1.0008018\n",
      "    0.8507352 ]]\n",
      "\n",
      " [[-0.37021828  0.5348731   0.13490137 ... -1.0912286  -1.0574783\n",
      "   -0.18064824]\n",
      "  [-0.8578709   3.0759535   0.2909603  ... -1.3555216  -0.7918935\n",
      "   -0.459406  ]\n",
      "  [-1.6143763   3.338545    0.9004255  ... -0.06199351 -1.111497\n",
      "   -0.09089228]\n",
      "  ...\n",
      "  [-1.962515   -1.0562395   0.41283804 ...  0.10973196  0.31981644\n",
      "   -0.11989465]\n",
      "  [-1.4935184  -1.2244793  -0.2615962  ... -0.30215034  0.3136039\n",
      "    0.35899362]\n",
      "  [-0.8662301  -1.1072237   0.10577902 ... -0.44457757 -1.043711\n",
      "   -0.66137683]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:40.450340 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:40.451770 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/50 [======>.......................] - ETA: 11s - loss: 1.4361tf.Tensor(\n",
      "[[[ 0.20348324  0.09003997 -0.930439   ...  0.91893566  0.4512742\n",
      "    0.13375393]\n",
      "  [ 0.21788627 -0.45955908 -1.4475348  ...  1.3143643   0.12985313\n",
      "    0.04505189]\n",
      "  [-0.11048105  0.07325123 -1.2648622  ...  1.0945327   0.04375407\n",
      "    0.43634963]\n",
      "  ...\n",
      "  [ 0.44672975  0.61512345 -0.5734541  ...  0.6499382   0.36412406\n",
      "    0.5149528 ]\n",
      "  [ 0.4033171   0.64902997 -0.71786714 ...  0.07785157  0.200354\n",
      "    0.37429833]\n",
      "  [ 0.51627344  0.5373708  -0.19976199 ...  0.52322865  0.2904312\n",
      "    0.32049662]]\n",
      "\n",
      " [[ 0.00900133  0.11375403 -0.6202717  ...  0.02191635  0.11806437\n",
      "    0.19583905]\n",
      "  [-0.10500726  0.26883924 -0.5899325  ...  0.86554503  0.4976061\n",
      "   -0.0277999 ]\n",
      "  [-0.5786891  -0.17487606  0.48063684 ...  0.02243353  0.8249189\n",
      "   -0.38208848]\n",
      "  ...\n",
      "  [-0.06689796  0.07202585 -0.40001163 ...  0.6824783   0.14820777\n",
      "    0.2046926 ]\n",
      "  [ 0.24412946  0.6347864  -0.3147557  ...  0.1947681   0.2752711\n",
      "    0.806351  ]\n",
      "  [-0.19630516  0.2968298   0.28654447 ...  0.49908525 -0.15669885\n",
      "    0.04959645]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.19845448  2.6841903  -0.21882674 ... -1.6141024  -0.77463853\n",
      "    1.2094493 ]\n",
      "  [-1.3842205   4.3280873  -0.6971318  ... -1.9849178  -0.80752766\n",
      "    1.7819462 ]\n",
      "  [-0.25945693  4.504993    0.10756183 ... -1.9280936   0.4724005\n",
      "    1.6941364 ]\n",
      "  ...\n",
      "  [-0.51586425  2.89106     1.4084003  ... -1.1842403   0.32273832\n",
      "    1.6041276 ]\n",
      "  [-0.87597793  2.490346    1.1046617  ... -1.3570974  -0.9300934\n",
      "    0.99595135]\n",
      "  [-1.0083672   3.3643494   1.1682519  ... -1.045903   -0.39155698\n",
      "    0.8512922 ]]\n",
      "\n",
      " [[ 0.06039797  0.64215183  0.03874378 ... -1.31651    -1.7219507\n",
      "   -0.06617058]\n",
      "  [-1.4571863   0.98911047  0.467842   ... -1.9397472  -1.8502074\n",
      "    0.1539169 ]\n",
      "  [-1.8018215   0.869972   -0.67727464 ... -1.715313   -1.1201491\n",
      "    1.2242287 ]\n",
      "  ...\n",
      "  [-1.3054078   5.2849007   0.28765157 ...  0.3717471  -0.83912086\n",
      "    0.8565915 ]\n",
      "  [-0.8246946   1.137887    1.0417475  ... -0.46678236  0.21530388\n",
      "   -0.5006419 ]\n",
      "  [-0.98770654  6.097134    0.21865493 ... -0.9952943  -1.1385828\n",
      "    0.03957509]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:40.790529 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:40.791965 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/50 [=======>......................] - ETA: 11s - loss: 1.4480tf.Tensor(\n",
      "[[[ 0.2062209   0.2658833  -0.4755956  ...  0.17655873 -0.03328959\n",
      "    0.15790492]\n",
      "  [ 0.55436593 -0.4492835  -0.04917553 ...  0.35957995  0.45906806\n",
      "   -0.13254476]\n",
      "  [ 0.965685   -0.00721733  0.25907335 ...  0.2040354   0.29571474\n",
      "   -0.03505889]\n",
      "  ...\n",
      "  [ 0.5185468   0.32156378  0.41273618 ...  0.08716479  0.61108136\n",
      "    0.1936462 ]\n",
      "  [ 0.31219417  0.6110807   0.403148   ...  0.15541968  0.2122947\n",
      "    0.21912396]\n",
      "  [ 0.19724376  0.4058522  -0.15204963 ...  0.24897523  0.50864613\n",
      "    0.4344828 ]]\n",
      "\n",
      " [[ 0.0876306   0.10883363 -0.41463402 ...  0.10815148  0.14845963\n",
      "   -0.17800012]\n",
      "  [ 0.2163989  -0.02456857  0.17200491 ...  0.43255737  0.14176878\n",
      "    0.20627555]\n",
      "  [ 0.15533474 -0.035001   -0.8629497  ...  0.97618234  0.6683568\n",
      "   -0.5186572 ]\n",
      "  ...\n",
      "  [ 0.16123027  0.01371838 -0.41986597 ...  0.83426803  0.1821723\n",
      "    0.6046205 ]\n",
      "  [ 0.0120465  -0.05326521  0.4539233  ...  0.5851621   0.34489375\n",
      "    0.20643938]\n",
      "  [ 0.01506475 -0.13272989 -0.63483274 ...  0.8954728   0.43741\n",
      "   -0.1239294 ]]], shape=(2, 111, 768), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[ 0.35089207  1.3623685  -0.0673245  ... -0.6569062  -0.03239946\n",
      "    1.3642358 ]\n",
      "  [-2.5489674   1.93328     1.5161852  ... -0.59613466  0.08970819\n",
      "    2.1242712 ]\n",
      "  [-1.5128462   1.7381996   0.90384936 ... -0.8698721  -0.5719439\n",
      "    1.7054242 ]\n",
      "  ...\n",
      "  [-0.94694185  3.3259091   0.88290447 ... -0.6534954   0.46483782\n",
      "    1.2477479 ]\n",
      "  [-1.0139719   2.6957166   0.13168235 ... -1.503256    0.06137268\n",
      "    1.0348574 ]\n",
      "  [-0.7901479   2.2547429   0.42583883 ... -1.6701205  -0.19295345\n",
      "    1.1851774 ]]\n",
      "\n",
      " [[ 0.63814557  1.094173    0.22145517 ... -0.36408183 -0.8848045\n",
      "    0.21434198]\n",
      "  [-0.78465617  2.7431026   1.2325594  ... -1.6374081  -0.74485666\n",
      "    1.4837687 ]\n",
      "  [-1.4387826   3.323482    0.09788521 ... -2.8124483  -1.0164052\n",
      "    0.589028  ]\n",
      "  ...\n",
      "  [-0.09672511  3.3673494  -0.29525632 ... -1.3055469  -0.76101\n",
      "    1.1864251 ]\n",
      "  [-0.6139248   3.741099    0.4522544  ... -0.6716257  -0.20194979\n",
      "    0.36043426]\n",
      "  [-0.59261394  3.7862773  -0.51675934 ... -0.99401695 -0.36862257\n",
      "   -0.03826486]]], shape=(2, 111, 30), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0822 08:38:41.130949 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0822 08:38:41.132388 140526050977600 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-056fc7922f5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m history = ner_model.fit(train_inputs, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n\u001b[0;32m---> 22\u001b[0;31m                         callbacks=[cp_callback, f1_score_callback])\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    570\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m       outputs = self.distribute_strategy.run(\n\u001b[0;32m--> 572\u001b[0;31m           self.train_step, args=(data,))\n\u001b[0m\u001b[1;32m    573\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    574\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    949\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m    950\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m--> 951\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m   \u001b[0;31m# TODO(b/151224785): Remove deprecated alias.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2288\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2290\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2292\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2647\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2648\u001b[0m         replica_id_in_sync_group=constant_op.constant(0, dtypes.int32)):\n\u001b[0;32m-> 2649\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2650\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperimental_hints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0;31m# such as loss scaling and gradient clipping.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m     _minimize(self.distribute_strategy, tape, self.optimizer, loss,\n\u001b[0;32m--> 541\u001b[0;31m               self.trainable_variables)\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_minimize\u001b[0;34m(strategy, tape, optimizer, loss, trainable_variables)\u001b[0m\n\u001b[1;32m   1810\u001b[0m       optimizer.apply_gradients(\n\u001b[1;32m   1811\u001b[0m           \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1812\u001b[0;31m           experimental_aggregate_gradients=False)\n\u001b[0m\u001b[1;32m   1813\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1814\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    506\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m           kwargs={\n\u001b[0;32m--> 508\u001b[0;31m               \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m           })\n\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   2419\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2425\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   2426\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2427\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2428\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2429\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    280\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    590\u001b[0m                               \"update_\" + var.op.name, skip_on_eager=True):\n\u001b[1;32m    591\u001b[0m             update_ops.extend(distribution.extended.update(\n\u001b[0;32m--> 592\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2009\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m     fn = autograph.tf_convert(\n\u001b[0;32m-> 2011\u001b[0;31m         fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0m\u001b[1;32m   2012\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2013\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mtf_convert\u001b[0;34m(f, ctx, convert_by_default, user_requested)\u001b[0m\n\u001b[1;32m    213\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'This switch contains all possible cases!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m   \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdecorators\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mcall_with_unspecified_conversion_status\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m     \u001b[0mwrapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mautograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf2/lib/python3.6/functools.py\u001b[0m in \u001b[0;36mupdate_wrapper\u001b[0;34m(wrapper, wrapped, assigned, updated)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0massigned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_ner\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "# earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=2)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = ner_model.fit(train_inputs, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                        callbacks=[cp_callback, f1_score_callback])\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-compute-f1-score-for-named-entity-recognition-in-keras-6f28b31dccca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
