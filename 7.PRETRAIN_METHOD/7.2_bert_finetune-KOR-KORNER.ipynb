{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import copy\n",
    "\n",
    "import tensorflow as tf\n",
    "from transformers import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "try:\n",
    "#     os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "#     os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "    import setGPU\n",
    "except:\n",
    "    print('no setGPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시각화\n",
    "\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random seed 고정\n",
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 3\n",
    "MAX_LEN = 111 # EDA에서 추출된 Max Length\n",
    "DATA_IN_PATH = 'data_in/KOR'\n",
    "DATA_OUT_PATH = \"data_out/KOR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 학습 데이터 개수: 81000\n",
      "개체명 인식 테스트 데이터 개수: 9000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 준비\n",
    "DATA_TRAIN_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"train.tsv\")\n",
    "DATA_LABEL_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"label.txt\")\n",
    "DATA_TEST_PATH = os.path.join(DATA_IN_PATH, \"NER\", \"test.tsv\")\n",
    "\n",
    "def read_file(input_path):\n",
    "    \"\"\"Read tsv file, and return words and label as list\"\"\"\n",
    "    with open(input_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        sentences = []\n",
    "        labels = []\n",
    "        for line in f:\n",
    "            split_line = line.strip().split(\"\\t\")\n",
    "            sentences.append(split_line[0])\n",
    "            labels.append(split_line[1])\n",
    "        return sentences, labels\n",
    "\n",
    "train_sentences, train_labels = read_file(DATA_TRAIN_PATH)\n",
    "\n",
    "train_ner_dict = {\"sentence\": train_sentences, \"label\": train_labels}\n",
    "train_ner_df = pd.DataFrame(train_ner_dict)\n",
    "\n",
    "test_sentences, test_labels = read_file(DATA_TEST_PATH)\n",
    "test_ner_dict = {\"sentence\": test_sentences, \"label\": test_labels}\n",
    "test_ner_df = pd.DataFrame(test_ner_dict)\n",
    "\n",
    "print(\"개체명 인식 학습 데이터 개수: {}\".format(len(train_ner_df)))\n",
    "print(\"개체명 인식 테스트 데이터 개수: {}\".format(len(test_ner_df)))\n",
    "\n",
    "# 개체명 인식 학습 데이터 개수: 81000\n",
    "# 개체명 인식 테스트 데이터 개수: 9000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "개체명 인식 레이블 개수: 33\n"
     ]
    }
   ],
   "source": [
    "# Label 불러오기\n",
    "\n",
    "def get_labels(label_path):\n",
    "    return [label.strip() for label in open(os.path.join(label_path), 'r', encoding='utf-8')]\n",
    "\n",
    "ner_labels = get_labels(DATA_LABEL_PATH)\n",
    "\n",
    "print(\"개체명 인식 레이블 개수: {}\".format(len(ner_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0819 15:51:52.962816 139950230714176 tokenization_utils_base.py:1254] loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-vocab.txt from cache at bert_ckpt/96435fa287fbf7e469185f1062386e05a075cadbf6838b74da22bf64b080bc32.99bcd55fc66f4f3360bc49ba472b940b8dcf223ea6a345deb969d607ca900729\n"
     ]
    }
   ],
   "source": [
    "# 버트 토크나이저 설정\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\", cache_dir='bert_ckpt')\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id # 0\n",
    "pad_token_label_id = 0\n",
    "cls_token_label_id = 0\n",
    "sep_token_label_id = 0\n",
    "# cls_token_label_id = 1\n",
    "# sep_token_label_id = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_tokenizer(sent, MAX_LEN):\n",
    "    \n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "        text = sent,\n",
    "        truncation=True,\n",
    "        add_special_tokens = True, #'[CLS]'와 '[SEP]' 추가\n",
    "        max_length = MAX_LEN,           # 문장 패딩 및 자르기 진행\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True   # 어탠션 마스크 생성\n",
    "    )\n",
    "    \n",
    "    input_id = encoded_dict['input_ids']\n",
    "    attention_mask = encoded_dict['attention_mask'] \n",
    "    token_type_id = encoded_dict['token_type_ids']\n",
    "    \n",
    "    return input_id, attention_mask, token_type_id\n",
    "\n",
    "def convert_label(words, labels_idx, ner_begin_label, max_seq_len):\n",
    "            \n",
    "    tokens = []\n",
    "    label_ids = []\n",
    "\n",
    "    for word, slot_label in zip(words, labels_idx):\n",
    "\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        if not word_tokens:\n",
    "            word_tokens = [unk_token]\n",
    "        tokens.extend(word_tokens)\n",
    "        \n",
    "        # 슬롯 레이블 값이 Begin이면 I로 추가\n",
    "        if int(slot_label) in ner_begin_label:\n",
    "            label_ids.extend([int(slot_label)] + [int(slot_label) + 1] * (len(word_tokens) - 1))\n",
    "        else:\n",
    "            label_ids.extend([int(slot_label)] * len(word_tokens))\n",
    "  \n",
    "    # [CLS] and [SEP] 설정\n",
    "    special_tokens_count = 2\n",
    "    if len(label_ids) > max_seq_len - special_tokens_count:\n",
    "        label_ids = label_ids[: (max_seq_len - special_tokens_count)]\n",
    "\n",
    "    # [SEP] 토큰 추가\n",
    "    label_ids += [sep_token_label_id]\n",
    "\n",
    "    # [CLS] 토큰 추가\n",
    "    label_ids = [cls_token_label_id] + label_ids\n",
    "    \n",
    "    padding_length = max_seq_len - len(label_ids)\n",
    "    label_ids = label_ids + ([pad_token_label_id] * padding_length)\n",
    "    \n",
    "    return label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inputs_targets(df):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    token_type_ids = []\n",
    "    label_list = []\n",
    "\n",
    "    for i, data in enumerate(df[['sentence', 'label']].values):\n",
    "        sentence, labels = data\n",
    "        words = sentence.split()\n",
    "        labels = labels.split()\n",
    "        labels_idx = []\n",
    "        \n",
    "        for label in labels:\n",
    "            labels_idx.append(ner_labels.index(label) if label in ner_labels else ner_labels.index(\"UNK\"))\n",
    "\n",
    "        ner_begin_label = [ner_labels.index(begin_label) for begin_label in ner_labels if \"B\" in begin_label]\n",
    "        assert len(words) == len(labels_idx)\n",
    "\n",
    "        input_id, attention_mask, token_type_id = bert_tokenizer(sentence, MAX_LEN)\n",
    "\n",
    "        convert_label_id = convert_label(words, labels_idx, ner_begin_label, MAX_LEN)\n",
    "\n",
    "        input_ids.append(input_id)\n",
    "        attention_masks.append(attention_mask)\n",
    "        token_type_ids.append(token_type_id)\n",
    "        label_list.append(convert_label_id)\n",
    "\n",
    "    input_ids = np.array(input_ids, dtype=int)\n",
    "    attention_masks = np.array(attention_masks, dtype=int)\n",
    "    token_type_ids = np.array(token_type_ids, dtype=int)\n",
    "    label_list = np.asarray(label_list, dtype=int) #레이블 토크나이징 리스트\n",
    "    inputs = (input_ids, attention_masks, token_type_ids)\n",
    "    \n",
    "    return inputs, label_list\n",
    "\n",
    "train_inputs, train_labels = create_inputs_targets(train_ner_df)\n",
    "test_inputs, test_labels = create_inputs_targets(test_ner_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFBertNERClassifier(tf.keras.Model):\n",
    "    def __init__(self, model_name, dir_path, num_class):\n",
    "        super(TFBertNERClassifier, self).__init__()\n",
    "\n",
    "        self.bert = TFBertModel.from_pretrained(model_name, cache_dir=dir_path)\n",
    "        self.num_class = num_class\n",
    "        self.dropout = tf.keras.layers.Dropout(self.bert.config.hidden_dropout_prob)\n",
    "        self.classifier = tf.keras.layers.Dense(self.num_class, \n",
    "                                                kernel_initializer=tf.keras.initializers.TruncatedNormal(self.bert.config.initializer_range),\n",
    "                                                name=\"ner_classifier\")\n",
    "\n",
    "    def call(self, inputs, attention_mask=None, token_type_ids=None, training=False):\n",
    "\n",
    "        #outputs 값: # sequence_output, pooled_output, (hidden_states), (attentions)\n",
    "        outputs = self.bert(inputs, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        sequence_output = outputs[0]\n",
    "        sequence_output = self.dropout(sequence_output, training=training)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0819 15:53:21.063895 139950230714176 configuration_utils.py:264] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json from cache at bert_ckpt/45629519f3117b89d89fd9c740073d8e4c1f0a70f9842476185100a8afe715d1.65df3cef028a0c91a7b059e4c404a975ebe6843c71267b67019c0e9cfa8a88f0\n",
      "I0819 15:53:21.066581 139950230714176 configuration_utils.py:300] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "I0819 15:53:21.493538 139950230714176 modeling_tf_utils.py:473] loading weights file https://cdn.huggingface.co/bert-base-multilingual-cased-tf_model.h5 from cache at bert_ckpt/273ed844d60ef1d5a4ea8f7857e3c3869d05d7b22296f4ae9bc56026ed40eeb7.1b4841f14bf42137fc7ecee17a46c1b2f22b417f636347e4b810bd06dd9c45ea.h5\n",
      "W0819 15:53:30.600885 139950230714176 modeling_tf_utils.py:511] Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing TFBertModel: ['mlm___cls', 'nsp___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "W0819 15:53:30.602571 139950230714176 modeling_tf_utils.py:528] All the weights of TFBertModel were initialized from the model checkpoint at bert-base-multilingual-cased.\n",
      "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "ner_model = TFBertNERClassifier(model_name='bert-base-multilingual-cased',\n",
    "                                  dir_path='bert_ckpt',\n",
    "                                  num_class=len(ner_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(labels, logits):\n",
    "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "        from_logits=True, reduction=tf.keras.losses.Reduction.NONE\n",
    "    )\n",
    "\n",
    "    # 0의 레이블 값은 손실 값을 계산할 때 제외\n",
    "    active_loss = tf.reshape(labels, (-1,)) != 0\n",
    "    reduced_logits = tf.boolean_mask(tf.reshape(logits, (-1, shape_list(logits)[2])), active_loss)\n",
    "    labels = tf.boolean_mask(tf.reshape(labels, (-1,)), active_loss)\n",
    "    \n",
    "    return loss_fn(labels, reduced_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Metrics(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, x_eval, y_eval):\n",
    "        self.x_eval = x_eval\n",
    "        self.y_eval = y_eval\n",
    "\n",
    "    def compute_metrics(self, labels, preds):\n",
    "        assert len(preds) == len(labels)\n",
    "        return self.f1_pre_rec(labels, preds)\n",
    "\n",
    "    def f1_pre_rec(self, labels, preds):\n",
    "\n",
    "        return {\n",
    "            \"precision\": precision_score(labels, preds, suffix=True),\n",
    "            \"recall\": recall_score(labels, preds, suffix=True),\n",
    "            \"f1\": f1_score(labels, preds, suffix=True)\n",
    "        }\n",
    "\n",
    "\n",
    "    def show_report(self, labels, preds):\n",
    "        return classification_report(labels, preds, suffix=True)\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "\n",
    "        results = {}\n",
    "        \n",
    "        pred = self.model.predict(self.x_eval)\n",
    "        real = self.y_eval\n",
    "        preds = np.argmax(pred, axis = 2)\n",
    "\n",
    "        slot_label_map = {i: label for i, label in enumerate(ner_labels)}\n",
    "        out_label_ids = real\n",
    "\n",
    "        out_label_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "        preds_list = [[] for _ in range(out_label_ids.shape[0])]\n",
    "\n",
    "        for i in range(out_label_ids.shape[0]):\n",
    "            for j in range(out_label_ids.shape[1]):\n",
    "                if out_label_ids[i, j] != 0:\n",
    "                    out_label_list[i].append(slot_label_map[out_label_ids[i][j]])\n",
    "                    preds_list[i].append(slot_label_map[preds[i][j]])\n",
    "                    \n",
    "        result = self.compute_metrics(out_label_list, preds_list)\n",
    "        results.update(result)\n",
    "\n",
    "        print(\"********\")\n",
    "        print(\"F1 Score\")\n",
    "        for key in sorted(results.keys()):\n",
    "            print(\"{}, {:.4f}\".format(key, results[key]))\n",
    "        print(\"\\n\" + self.show_report(out_label_list, preds_list))\n",
    "        print(\"********\")\n",
    "\n",
    "f1_score_callback = F1Metrics(test_inputs, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training: Compile tf.keras model with optimizer, loss and learning rate schedule\n",
    "optimizer = tf.keras.optimizers.Adam(3e-5)\n",
    "ner_model.compile(optimizer=optimizer, loss=compute_loss)\n",
    "# ner_model.compile(optimizer=optimizer, loss=compute_loss, metrics=[metric], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_out/KOR/tf2_bert_ner -- Folder already exists \n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 15:53:36.949810 139950230714176 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0819 15:53:36.952247 139950230714176 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0819 15:53:42.528343 139950230714176 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "W0819 15:53:42.532379 139950230714176 optimizer_v2.py:1223] Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "633/633 [==============================] - ETA: 0s - loss: 0.4934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 16:03:34.025886 139950230714176 callbacks.py:1203] Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "F1 Score\n",
      "f1, 0.8325\n",
      "precision, 0.8170\n",
      "recall, 0.8486\n",
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      NUM       0.85      0.89      0.87      5544\n",
      "      CVL       0.66      0.67      0.67      5735\n",
      "      ORG       0.67      0.78      0.72      4055\n",
      "      DAT       0.83      0.87      0.85      2510\n",
      "      CLS       1.00      1.00      1.00      9000\n",
      "      PER       0.73      0.81      0.77      4412\n",
      "      EVT       0.61      0.68      0.64      1093\n",
      "      SEP       1.00      1.00      1.00      9000\n",
      "      LOC       0.71      0.71      0.71      2124\n",
      "      ANM       0.58      0.58      0.58       699\n",
      "      AFW       0.40      0.33      0.36       393\n",
      "      TRM       0.52      0.55      0.53      1950\n",
      "      TIM       0.75      0.84      0.79       314\n",
      "      FLD       0.45      0.46      0.45       228\n",
      "      PLT       0.00      0.00      0.00        34\n",
      "      MAT       0.00      0.00      0.00        12\n",
      "\n",
      "micro avg       0.82      0.85      0.83     47103\n",
      "macro avg       0.82      0.85      0.83     47103\n",
      "\n",
      "********\n",
      "633/633 [==============================] - 622s 983ms/step - loss: 0.4934\n",
      "Epoch 2/3\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2928"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 16:13:57.266344 139950230714176 callbacks.py:1203] Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "F1 Score\n",
      "f1, 0.8520\n",
      "precision, 0.8439\n",
      "recall, 0.8603\n",
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      NUM       0.85      0.90      0.88      5544\n",
      "      CVL       0.72      0.68      0.70      5735\n",
      "      ORG       0.77      0.77      0.77      4055\n",
      "      DAT       0.85      0.90      0.88      2510\n",
      "      CLS       1.00      1.00      1.00      9000\n",
      "      PER       0.80      0.81      0.81      4412\n",
      "      EVT       0.65      0.71      0.68      1093\n",
      "      SEP       1.00      1.00      1.00      9000\n",
      "      LOC       0.72      0.78      0.75      2124\n",
      "      ANM       0.66      0.59      0.63       699\n",
      "      AFW       0.37      0.49      0.42       393\n",
      "      TRM       0.54      0.63      0.58      1950\n",
      "      TIM       0.75      0.90      0.82       314\n",
      "      FLD       0.45      0.57      0.50       228\n",
      "      PLT       0.00      0.00      0.00        34\n",
      "      MAT       0.33      0.08      0.13        12\n",
      "\n",
      "micro avg       0.84      0.86      0.85     47103\n",
      "macro avg       0.85      0.86      0.85     47103\n",
      "\n",
      "********\n",
      "633/633 [==============================] - 619s 978ms/step - loss: 0.2928\n",
      "Epoch 3/3\n",
      "633/633 [==============================] - ETA: 0s - loss: 0.2369"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0819 16:24:17.373796 139950230714176 callbacks.py:1203] Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********\n",
      "F1 Score\n",
      "f1, 0.8650\n",
      "precision, 0.8534\n",
      "recall, 0.8769\n",
      "\n",
      "           precision    recall  f1-score   support\n",
      "\n",
      "      NUM       0.88      0.90      0.89      5544\n",
      "      CVL       0.70      0.76      0.73      5735\n",
      "      ORG       0.75      0.82      0.78      4055\n",
      "      DAT       0.88      0.90      0.89      2510\n",
      "      CLS       1.00      1.00      1.00      9000\n",
      "      PER       0.81      0.83      0.82      4412\n",
      "      EVT       0.67      0.74      0.70      1093\n",
      "      SEP       1.00      1.00      1.00      9000\n",
      "      LOC       0.76      0.78      0.77      2124\n",
      "      ANM       0.69      0.69      0.69       699\n",
      "      AFW       0.41      0.53      0.46       393\n",
      "      TRM       0.65      0.61      0.63      1950\n",
      "      TIM       0.81      0.85      0.83       314\n",
      "      FLD       0.54      0.56      0.55       228\n",
      "      PLT       0.25      0.09      0.13        34\n",
      "      MAT       0.20      0.08      0.12        12\n",
      "\n",
      "micro avg       0.85      0.88      0.87     47103\n",
      "macro avg       0.86      0.88      0.87     47103\n",
      "\n",
      "********\n",
      "633/633 [==============================] - 619s 978ms/step - loss: 0.2369\n",
      "{'loss': [0.4934200048446655, 0.2927936315536499, 0.2368599772453308]}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tf2_bert_ner\"\n",
    "\n",
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "# earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=2)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\\\n",
    "\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name, 'weights.h5')\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "history = ner_model.fit(train_inputs, train_labels, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                        callbacks=[cp_callback, f1_score_callback])\n",
    "\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-compute-f1-score-for-named-entity-recognition-in-keras-6f28b31dccca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
