{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "PAD = \"<PAD>\"\n",
    "STD = \"<SOS>\"\n",
    "END = \"<END>\"\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "MARKER = [PAD, STD, END, UNK]\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "PATH = 'data_in/ChatBotData.csv_short'\n",
    "VOCAB_PATH = 'data_in/vocabulary.txt'\n",
    "\n",
    "MAX_SEQUENCE = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # 판다스를 통해서 데이터를 불러온다.\n",
    "    data_df = pd.read_csv(path, header=0)\n",
    "    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = load_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징과 어휘사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tokenizer(data):\n",
    "    # 토크나이징 해서 담을 배열 생성\n",
    "    words = []\n",
    "    for sentence in data:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 위 필터와 같은 값들을 정규화 표현식을\n",
    "        # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "        for word in sentence.split():\n",
    "            words.append(word)\n",
    "    # 토그나이징과 정규표현식을 통해 만들어진\n",
    "    # 값들을 넘겨 준다.\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def load_vocabulary(path, vocab_path):\n",
    "    # 사전을 담을 배열 준비한다.\n",
    "    vocabulary_list = []\n",
    "    # 사전을 구성한 후 파일로 저장 진행한다.\n",
    "    # 그 파일의 존재 유무를 확인한다.\n",
    "    if not os.path.exists(vocab_path):\n",
    "        # 이미 생성된 사전 파일이 존재하지 않으므로\n",
    "        # 데이터를 가지고 만들어야 한다.\n",
    "        # 그래서 데이터가 존재 하면 사전을 만들기 위해서\n",
    "        # 데이터 파일의 존재 유무를 확인한다.\n",
    "        if (os.path.exists(path)):\n",
    "            # 데이터가 존재하니 판단스를 통해서\n",
    "            # 데이터를 불러오자\n",
    "            data_df = pd.read_csv(path, encoding='utf-8')\n",
    "            # 판다스의 데이터 프레임을 통해서\n",
    "            # 질문과 답에 대한 열을 가져 온다.\n",
    "            question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "#             if DEFINES.tokenize_as_morph:  # 형태소에 따른 토크나이져 처리\n",
    "#                 question = prepro_like_morphlized(question)\n",
    "#                 answer = prepro_like_morphlized(answer)\n",
    "            data = []\n",
    "            # 질문과 답변을 extend을\n",
    "            # 통해서 구조가 없는 배열로 만든다.\n",
    "            data.extend(question)\n",
    "            data.extend(answer)\n",
    "            # 토큰나이져 처리 하는 부분이다.\n",
    "            words = data_tokenizer(data)\n",
    "            # 공통적인 단어에 대해서는 모두\n",
    "            # 필요 없으므로 한개로 만들어 주기 위해서\n",
    "            # set해주고 이것들을 리스트로 만들어 준다.\n",
    "            words = list(set(words))\n",
    "            # 데이터 없는 내용중에 MARKER를 사전에\n",
    "            # 추가 하기 위해서 아래와 같이 처리 한다.\n",
    "            # 아래는 MARKER 값이며 리스트의 첫번째 부터\n",
    "            # 순서대로 넣기 위해서 인덱스 0에 추가한다.\n",
    "            # PAD = \"<PADDING>\"\n",
    "            # STD = \"<START>\"\n",
    "            # END = \"<END>\"\n",
    "            # UNK = \"<UNKNWON>\"\n",
    "            words[:0] = MARKER\n",
    "        # 사전을 리스트로 만들었으니 이 내용을\n",
    "        # 사전 파일을 만들어 넣는다.\n",
    "        with open(vocab_path, 'w', encoding='utf-8') as vocabulary_file:\n",
    "            for word in words:\n",
    "                vocabulary_file.write(word + '\\n')\n",
    "\n",
    "    # 사전 파일이 존재하면 여기에서\n",
    "    # 그 파일을 불러서 배열에 넣어 준다.\n",
    "    with open(vocab_path, 'r', encoding='utf-8') as vocabulary_file:\n",
    "        for line in vocabulary_file:\n",
    "            vocabulary_list.append(line.strip())\n",
    "\n",
    "    # 배열에 내용을 키와 값이 있는\n",
    "    # 딕셔너리 구조로 만든다.\n",
    "    char2idx, idx2char = make_vocabulary(vocabulary_list)\n",
    "    # 두가지 형태의 키와 값이 있는 형태를 리턴한다.\n",
    "    # (예) 단어: 인덱스 , 인덱스: 단어)\n",
    "    return char2idx, idx2char, len(char2idx)\n",
    "\n",
    "\n",
    "def make_vocabulary(vocabulary_list):\n",
    "    # 리스트를 키가 단어이고 값이 인덱스인\n",
    "    # 딕셔너리를 만든다.\n",
    "    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n",
    "    # 리스트를 키가 인덱스이고 값이 단어인\n",
    "    # 딕셔너리를 만든다.\n",
    "    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n",
    "    # 두개의 딕셔너리를 넘겨 준다.\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx, idx2char, vocab_size = load_vocabulary(PATH, VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다.)\n",
    "    sequences_input_index = []\n",
    "    # 하나의 인코딩 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다.)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "\n",
    "    print(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 인코딩 할때\n",
    "        # 가지고 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 문장을 스페이스 단위로\n",
    "        # 자르고 있다.\n",
    "        for word in sequence.split():\n",
    "            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고\n",
    "            # 그 값을 가져와 sequence_index에 추가한다.\n",
    "            if dictionary.get(word) is not None:\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "            # 잘려진 단어가 딕셔너리에 존재 하지 않는\n",
    "            # 경우 이므로 UNK(2)를 넣어 준다.\n",
    "            else:\n",
    "                sequence_index.extend([dictionary[UNK]])\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_input_index에 넣어 준다.\n",
    "        sequences_input_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과\n",
    "    # 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_input_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_output_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_output_index = []\n",
    "    # 하나의 디코딩 입력 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 디코딩 할때 가지고\n",
    "        # 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 디코딩 입력의 처음에는 START가 와야 하므로\n",
    "        # 그 값을 넣어 주고 시작한다.\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서 딕셔너리의\n",
    "        # 값인 인덱스를 넣어 준다.\n",
    "        sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_output_index 넣어 준다.\n",
    "        sequences_output_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_output_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_target_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_target_index = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서\n",
    "        # 딕셔너리의 값인 인덱스를 넣어 준다.\n",
    "        # 디코딩 출력의 마지막에 END를 넣어 준다.\n",
    "        sequence_index = [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        # 그리고 END 토큰을 넣어 준다\n",
    "        if len(sequence_index) >= MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE - 1] + [dictionary[END]]\n",
    "        else:\n",
    "            sequence_index += [dictionary[END]]\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_target_index에 넣어 준다.\n",
    "        sequences_target_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가끔 궁금해', '가끔 뭐하는지 궁금해', '가끔은 혼자인게 좋다', '가난한 자의 설움', '가만 있어도 땀난다', '가상화폐 쫄딱 망함', '가스불 켜고 나갔어', '가스불 켜놓고 나온거 같아', '가스비 너무 많이 나왔다.', '가스비 비싼데 감기 걸리겠어', '남자친구 교회 데려가고 싶어', '남자친구 또 운동 갔어', '남자친구 생일인데 뭘 줄까', '남자친구 승진 선물로 뭐가 좋을까?', '남자친구 오늘 따라 훈훈해 보인다', '남자친구 오늘 좀 질린다.', '남자친구가 나 안 믿어줘', '남자친구가 너무 바빠', '남자친구가 너무 운동만 해', '남자친구가 너무 잘생겼어']\n"
     ]
    }
   ],
   "source": [
    "index_inputs, input_seq_len = enc_processing(inputs, char2idx)\n",
    "index_outputs, output_seq_len = dec_output_processing(outputs, char2idx)\n",
    "index_targets = dec_target_processing(outputs, char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "# Show length\n",
    "print(len(index_inputs), len(input_seq_len), len(index_outputs), len(output_seq_len), len(index_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SPLIT = 0.2\n",
    "BATCH_SIZE = 1\n",
    "units = 1024\n",
    "embedding_dim = 256\n",
    "EPOCH = 200\n",
    "steps_per_epoch = len(index_inputs)//BATCH_SIZE\n",
    "BUFFER_SIZE = len(index_inputs)\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "DATA_IN_PATH = './data_in/'\n",
    "model_name = 'seq2seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    #def __init__(self, **kargs):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim          \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim  \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "            \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz):    \n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz) #vocab_size, embedding_dim, enc_units, batch_sz\n",
    "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz) #vocab_size, embedding_dim, dec_units, batch_sz\n",
    "\n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "\n",
    "        enc_hidden = self.encoder.initialize_hidden_state()\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([STD_INDEX] * BATCH_SIZE, 1)\n",
    "        predict_tokens = list()\n",
    "        for t in range(0, tar.shape[1]):\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims(tar[:, t], 1), tf.float32)      \n",
    "        return tf.stack(predict_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2seq(vocab_size, embedding_dim, units, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_function,\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=[accuracy_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/seq2seq -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.{epoch:02d}-{val_accuracy_function:.2f}.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "\n",
    "#SAVE_FILE_LW = 'weights.99-0.83.h5'\n",
    "#model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_LW))\n",
    "\n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_accuracy_function', verbose=2, save_best_only=True, save_weights_only=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 00001: val_accuracy_function improved from -inf to 0.81202, saving model to ./data_out/seq2seq/weights.01-0.81.h5\n",
      "16/16 - 38s - loss: 1.0989 - accuracy_function: 0.7984 - val_loss: 0.9269 - val_accuracy_function: 0.8120\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 00002: val_accuracy_function improved from 0.81202 to 0.81751, saving model to ./data_out/seq2seq/weights.02-0.82.h5\n",
      "16/16 - 5s - loss: 1.0408 - accuracy_function: 0.8091 - val_loss: 0.8692 - val_accuracy_function: 0.8175\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 00003: val_accuracy_function improved from 0.81751 to 0.81922, saving model to ./data_out/seq2seq/weights.03-0.82.h5\n",
      "16/16 - 5s - loss: 0.9350 - accuracy_function: 0.8182 - val_loss: 0.8267 - val_accuracy_function: 0.8192\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 00004: val_accuracy_function improved from 0.81922 to 0.82006, saving model to ./data_out/seq2seq/weights.04-0.82.h5\n",
      "16/16 - 5s - loss: 0.8875 - accuracy_function: 0.8203 - val_loss: 0.8449 - val_accuracy_function: 0.8201\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 00005: val_accuracy_function improved from 0.82006 to 0.82055, saving model to ./data_out/seq2seq/weights.05-0.82.h5\n",
      "16/16 - 5s - loss: 0.8659 - accuracy_function: 0.8195 - val_loss: 0.8827 - val_accuracy_function: 0.8206\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 00006: val_accuracy_function improved from 0.82055 to 0.82088, saving model to ./data_out/seq2seq/weights.06-0.82.h5\n",
      "16/16 - 5s - loss: 0.8376 - accuracy_function: 0.8199 - val_loss: 0.9067 - val_accuracy_function: 0.8209\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 00007: val_accuracy_function improved from 0.82088 to 0.82112, saving model to ./data_out/seq2seq/weights.07-0.82.h5\n",
      "16/16 - 5s - loss: 0.8281 - accuracy_function: 0.8213 - val_loss: 0.9025 - val_accuracy_function: 0.8211\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 00008: val_accuracy_function improved from 0.82112 to 0.82129, saving model to ./data_out/seq2seq/weights.08-0.82.h5\n",
      "16/16 - 5s - loss: 0.8161 - accuracy_function: 0.8209 - val_loss: 0.8949 - val_accuracy_function: 0.8213\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 00009: val_accuracy_function improved from 0.82129 to 0.82143, saving model to ./data_out/seq2seq/weights.09-0.82.h5\n",
      "16/16 - 5s - loss: 0.8048 - accuracy_function: 0.8210 - val_loss: 0.9210 - val_accuracy_function: 0.8214\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 00010: val_accuracy_function improved from 0.82143 to 0.82154, saving model to ./data_out/seq2seq/weights.10-0.82.h5\n",
      "16/16 - 5s - loss: 0.7939 - accuracy_function: 0.8218 - val_loss: 0.9073 - val_accuracy_function: 0.8215\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 00011: val_accuracy_function improved from 0.82154 to 0.82162, saving model to ./data_out/seq2seq/weights.11-0.82.h5\n",
      "16/16 - 5s - loss: 0.7875 - accuracy_function: 0.8215 - val_loss: 0.9589 - val_accuracy_function: 0.8216\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 00012: val_accuracy_function improved from 0.82162 to 0.82170, saving model to ./data_out/seq2seq/weights.12-0.82.h5\n",
      "16/16 - 5s - loss: 0.7813 - accuracy_function: 0.8220 - val_loss: 0.9217 - val_accuracy_function: 0.8217\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 00013: val_accuracy_function improved from 0.82170 to 0.82176, saving model to ./data_out/seq2seq/weights.13-0.82.h5\n",
      "16/16 - 5s - loss: 0.7709 - accuracy_function: 0.8215 - val_loss: 0.9578 - val_accuracy_function: 0.8218\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 00014: val_accuracy_function improved from 0.82176 to 0.82181, saving model to ./data_out/seq2seq/weights.14-0.82.h5\n",
      "16/16 - 5s - loss: 0.7513 - accuracy_function: 0.8214 - val_loss: 0.9336 - val_accuracy_function: 0.8218\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 00015: val_accuracy_function improved from 0.82181 to 0.82186, saving model to ./data_out/seq2seq/weights.15-0.82.h5\n",
      "16/16 - 5s - loss: 0.7420 - accuracy_function: 0.8220 - val_loss: 0.8573 - val_accuracy_function: 0.8219\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 00016: val_accuracy_function improved from 0.82186 to 0.82190, saving model to ./data_out/seq2seq/weights.16-0.82.h5\n",
      "16/16 - 5s - loss: 0.7192 - accuracy_function: 0.8218 - val_loss: 0.8325 - val_accuracy_function: 0.8219\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 00017: val_accuracy_function improved from 0.82190 to 0.82238, saving model to ./data_out/seq2seq/weights.17-0.82.h5\n",
      "16/16 - 5s - loss: 0.7273 - accuracy_function: 0.8223 - val_loss: 0.8676 - val_accuracy_function: 0.8224\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 00018: val_accuracy_function improved from 0.82238 to 0.82266, saving model to ./data_out/seq2seq/weights.18-0.82.h5\n",
      "16/16 - 5s - loss: 0.6994 - accuracy_function: 0.8223 - val_loss: 0.8853 - val_accuracy_function: 0.8227\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 00019: val_accuracy_function improved from 0.82266 to 0.82318, saving model to ./data_out/seq2seq/weights.19-0.82.h5\n",
      "16/16 - 5s - loss: 0.6840 - accuracy_function: 0.8229 - val_loss: 0.9446 - val_accuracy_function: 0.8232\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 00020: val_accuracy_function improved from 0.82318 to 0.82340, saving model to ./data_out/seq2seq/weights.20-0.82.h5\n",
      "16/16 - 5s - loss: 0.6791 - accuracy_function: 0.8236 - val_loss: 0.8677 - val_accuracy_function: 0.8234\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 00021: val_accuracy_function improved from 0.82340 to 0.82348, saving model to ./data_out/seq2seq/weights.21-0.82.h5\n",
      "16/16 - 5s - loss: 0.6600 - accuracy_function: 0.8234 - val_loss: 0.8328 - val_accuracy_function: 0.8235\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 00022: val_accuracy_function improved from 0.82348 to 0.82366, saving model to ./data_out/seq2seq/weights.22-0.82.h5\n",
      "16/16 - 5s - loss: 0.6673 - accuracy_function: 0.8234 - val_loss: 0.8647 - val_accuracy_function: 0.8237\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 00023: val_accuracy_function improved from 0.82366 to 0.82415, saving model to ./data_out/seq2seq/weights.23-0.82.h5\n",
      "16/16 - 5s - loss: 0.6503 - accuracy_function: 0.8241 - val_loss: 0.8374 - val_accuracy_function: 0.8242\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 00024: val_accuracy_function improved from 0.82415 to 0.82471, saving model to ./data_out/seq2seq/weights.24-0.82.h5\n",
      "16/16 - 5s - loss: 0.6350 - accuracy_function: 0.8245 - val_loss: 0.9381 - val_accuracy_function: 0.8247\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 00025: val_accuracy_function improved from 0.82471 to 0.82502, saving model to ./data_out/seq2seq/weights.25-0.83.h5\n",
      "16/16 - 5s - loss: 0.6246 - accuracy_function: 0.8249 - val_loss: 0.8785 - val_accuracy_function: 0.8250\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 00026: val_accuracy_function improved from 0.82502 to 0.82570, saving model to ./data_out/seq2seq/weights.26-0.83.h5\n",
      "16/16 - 5s - loss: 0.6028 - accuracy_function: 0.8253 - val_loss: 0.9134 - val_accuracy_function: 0.8257\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 00027: val_accuracy_function improved from 0.82570 to 0.82623, saving model to ./data_out/seq2seq/weights.27-0.83.h5\n",
      "16/16 - 5s - loss: 0.6030 - accuracy_function: 0.8260 - val_loss: 0.8990 - val_accuracy_function: 0.8262\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 00028: val_accuracy_function improved from 0.82623 to 0.82681, saving model to ./data_out/seq2seq/weights.28-0.83.h5\n",
      "16/16 - 5s - loss: 0.5979 - accuracy_function: 0.8266 - val_loss: 0.9226 - val_accuracy_function: 0.8268\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 00029: val_accuracy_function improved from 0.82681 to 0.82736, saving model to ./data_out/seq2seq/weights.29-0.83.h5\n",
      "16/16 - 5s - loss: 0.5873 - accuracy_function: 0.8272 - val_loss: 0.9300 - val_accuracy_function: 0.8274\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 00030: val_accuracy_function improved from 0.82736 to 0.82794, saving model to ./data_out/seq2seq/weights.30-0.83.h5\n",
      "16/16 - 5s - loss: 0.5791 - accuracy_function: 0.8277 - val_loss: 0.9365 - val_accuracy_function: 0.8279\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 00031: val_accuracy_function improved from 0.82794 to 0.82866, saving model to ./data_out/seq2seq/weights.31-0.83.h5\n",
      "16/16 - 5s - loss: 0.5594 - accuracy_function: 0.8282 - val_loss: 0.9164 - val_accuracy_function: 0.8287\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 00032: val_accuracy_function improved from 0.82866 to 0.82956, saving model to ./data_out/seq2seq/weights.32-0.83.h5\n",
      "16/16 - 5s - loss: 0.5416 - accuracy_function: 0.8293 - val_loss: 0.9342 - val_accuracy_function: 0.8296\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 00033: val_accuracy_function improved from 0.82956 to 0.83041, saving model to ./data_out/seq2seq/weights.33-0.83.h5\n",
      "16/16 - 5s - loss: 0.5291 - accuracy_function: 0.8298 - val_loss: 0.9330 - val_accuracy_function: 0.8304\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 00034: val_accuracy_function improved from 0.83041 to 0.83084, saving model to ./data_out/seq2seq/weights.34-0.83.h5\n",
      "16/16 - 5s - loss: 0.5201 - accuracy_function: 0.8308 - val_loss: 0.9882 - val_accuracy_function: 0.8308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/200\n",
      "\n",
      "Epoch 00035: val_accuracy_function improved from 0.83084 to 0.83175, saving model to ./data_out/seq2seq/weights.35-0.83.h5\n",
      "16/16 - 5s - loss: 0.4991 - accuracy_function: 0.8312 - val_loss: 0.9029 - val_accuracy_function: 0.8317\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 00036: val_accuracy_function improved from 0.83175 to 0.83260, saving model to ./data_out/seq2seq/weights.36-0.83.h5\n",
      "16/16 - 5s - loss: 0.4864 - accuracy_function: 0.8321 - val_loss: 0.9833 - val_accuracy_function: 0.8326\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 00037: val_accuracy_function improved from 0.83260 to 0.83328, saving model to ./data_out/seq2seq/weights.37-0.83.h5\n",
      "16/16 - 5s - loss: 0.4726 - accuracy_function: 0.8331 - val_loss: 0.9233 - val_accuracy_function: 0.8333\n",
      "Epoch 38/200\n",
      "\n",
      "Epoch 00038: val_accuracy_function improved from 0.83328 to 0.83392, saving model to ./data_out/seq2seq/weights.38-0.83.h5\n",
      "16/16 - 5s - loss: 0.4909 - accuracy_function: 0.8336 - val_loss: 1.0602 - val_accuracy_function: 0.8339\n",
      "Epoch 39/200\n",
      "\n",
      "Epoch 00039: val_accuracy_function improved from 0.83392 to 0.83430, saving model to ./data_out/seq2seq/weights.39-0.83.h5\n",
      "16/16 - 5s - loss: 0.4677 - accuracy_function: 0.8341 - val_loss: 0.9415 - val_accuracy_function: 0.8343\n",
      "Epoch 40/200\n",
      "\n",
      "Epoch 00040: val_accuracy_function improved from 0.83430 to 0.83572, saving model to ./data_out/seq2seq/weights.40-0.84.h5\n",
      "16/16 - 5s - loss: 0.4088 - accuracy_function: 0.8351 - val_loss: 0.9982 - val_accuracy_function: 0.8357\n",
      "Epoch 41/200\n",
      "\n",
      "Epoch 00041: val_accuracy_function improved from 0.83572 to 0.83653, saving model to ./data_out/seq2seq/weights.41-0.84.h5\n",
      "16/16 - 5s - loss: 0.4227 - accuracy_function: 0.8363 - val_loss: 0.9655 - val_accuracy_function: 0.8365\n",
      "Epoch 42/200\n",
      "\n",
      "Epoch 00042: val_accuracy_function improved from 0.83653 to 0.83754, saving model to ./data_out/seq2seq/weights.42-0.84.h5\n",
      "16/16 - 5s - loss: 0.3896 - accuracy_function: 0.8372 - val_loss: 0.9887 - val_accuracy_function: 0.8375\n",
      "Epoch 43/200\n",
      "\n",
      "Epoch 00043: val_accuracy_function improved from 0.83754 to 0.83856, saving model to ./data_out/seq2seq/weights.43-0.84.h5\n",
      "16/16 - 5s - loss: 0.3857 - accuracy_function: 0.8382 - val_loss: 0.9867 - val_accuracy_function: 0.8386\n",
      "Epoch 44/200\n",
      "\n",
      "Epoch 00044: val_accuracy_function improved from 0.83856 to 0.83974, saving model to ./data_out/seq2seq/weights.44-0.84.h5\n",
      "16/16 - 5s - loss: 0.3724 - accuracy_function: 0.8392 - val_loss: 0.9685 - val_accuracy_function: 0.8397\n",
      "Epoch 45/200\n",
      "\n",
      "Epoch 00045: val_accuracy_function improved from 0.83974 to 0.84082, saving model to ./data_out/seq2seq/weights.45-0.84.h5\n",
      "16/16 - 5s - loss: 0.3630 - accuracy_function: 0.8406 - val_loss: 1.0013 - val_accuracy_function: 0.8408\n",
      "Epoch 46/200\n",
      "\n",
      "Epoch 00046: val_accuracy_function improved from 0.84082 to 0.84186, saving model to ./data_out/seq2seq/weights.46-0.84.h5\n",
      "16/16 - 5s - loss: 0.3624 - accuracy_function: 0.8414 - val_loss: 0.9946 - val_accuracy_function: 0.8419\n",
      "Epoch 47/200\n",
      "\n",
      "Epoch 00047: val_accuracy_function improved from 0.84186 to 0.84295, saving model to ./data_out/seq2seq/weights.47-0.84.h5\n",
      "16/16 - 5s - loss: 0.3459 - accuracy_function: 0.8424 - val_loss: 1.0046 - val_accuracy_function: 0.8430\n",
      "Epoch 48/200\n",
      "\n",
      "Epoch 00048: val_accuracy_function improved from 0.84295 to 0.84424, saving model to ./data_out/seq2seq/weights.48-0.84.h5\n",
      "16/16 - 5s - loss: 0.3301 - accuracy_function: 0.8436 - val_loss: 0.9974 - val_accuracy_function: 0.8442\n",
      "Epoch 49/200\n",
      "\n",
      "Epoch 00049: val_accuracy_function improved from 0.84424 to 0.84525, saving model to ./data_out/seq2seq/weights.49-0.85.h5\n",
      "16/16 - 5s - loss: 0.3348 - accuracy_function: 0.8449 - val_loss: 1.0777 - val_accuracy_function: 0.8452\n",
      "Epoch 50/200\n",
      "\n",
      "Epoch 00050: val_accuracy_function improved from 0.84525 to 0.84639, saving model to ./data_out/seq2seq/weights.50-0.85.h5\n",
      "16/16 - 5s - loss: 0.3322 - accuracy_function: 0.8459 - val_loss: 1.0839 - val_accuracy_function: 0.8464\n",
      "Epoch 51/200\n",
      "\n",
      "Epoch 00051: val_accuracy_function improved from 0.84639 to 0.84772, saving model to ./data_out/seq2seq/weights.51-0.85.h5\n",
      "16/16 - 5s - loss: 0.3087 - accuracy_function: 0.8471 - val_loss: 1.0055 - val_accuracy_function: 0.8477\n",
      "Epoch 52/200\n",
      "\n",
      "Epoch 00052: val_accuracy_function improved from 0.84772 to 0.84860, saving model to ./data_out/seq2seq/weights.52-0.85.h5\n",
      "16/16 - 5s - loss: 0.3261 - accuracy_function: 0.8482 - val_loss: 1.0216 - val_accuracy_function: 0.8486\n",
      "Epoch 53/200\n",
      "\n",
      "Epoch 00053: val_accuracy_function improved from 0.84860 to 0.84983, saving model to ./data_out/seq2seq/weights.53-0.85.h5\n",
      "16/16 - 5s - loss: 0.2916 - accuracy_function: 0.8494 - val_loss: 1.0655 - val_accuracy_function: 0.8498\n",
      "Epoch 54/200\n",
      "\n",
      "Epoch 00054: val_accuracy_function improved from 0.84983 to 0.85078, saving model to ./data_out/seq2seq/weights.54-0.85.h5\n",
      "16/16 - 5s - loss: 0.3094 - accuracy_function: 0.8504 - val_loss: 1.0316 - val_accuracy_function: 0.8508\n",
      "Epoch 55/200\n",
      "\n",
      "Epoch 00055: val_accuracy_function improved from 0.85078 to 0.85184, saving model to ./data_out/seq2seq/weights.55-0.85.h5\n",
      "16/16 - 5s - loss: 0.2896 - accuracy_function: 0.8514 - val_loss: 1.0489 - val_accuracy_function: 0.8518\n",
      "Epoch 56/200\n",
      "\n",
      "Epoch 00056: val_accuracy_function improved from 0.85184 to 0.85279, saving model to ./data_out/seq2seq/weights.56-0.85.h5\n",
      "16/16 - 5s - loss: 0.2781 - accuracy_function: 0.8523 - val_loss: 1.0206 - val_accuracy_function: 0.8528\n",
      "Epoch 57/200\n",
      "\n",
      "Epoch 00057: val_accuracy_function improved from 0.85279 to 0.85378, saving model to ./data_out/seq2seq/weights.57-0.85.h5\n",
      "16/16 - 5s - loss: 0.2648 - accuracy_function: 0.8533 - val_loss: 1.0695 - val_accuracy_function: 0.8538\n",
      "Epoch 58/200\n",
      "\n",
      "Epoch 00058: val_accuracy_function improved from 0.85378 to 0.85473, saving model to ./data_out/seq2seq/weights.58-0.85.h5\n",
      "16/16 - 5s - loss: 0.2542 - accuracy_function: 0.8543 - val_loss: 1.0845 - val_accuracy_function: 0.8547\n",
      "Epoch 59/200\n",
      "\n",
      "Epoch 00059: val_accuracy_function improved from 0.85473 to 0.85589, saving model to ./data_out/seq2seq/weights.59-0.86.h5\n",
      "16/16 - 5s - loss: 0.2514 - accuracy_function: 0.8554 - val_loss: 1.0118 - val_accuracy_function: 0.8559\n",
      "Epoch 60/200\n",
      "\n",
      "Epoch 00060: val_accuracy_function improved from 0.85589 to 0.85693, saving model to ./data_out/seq2seq/weights.60-0.86.h5\n",
      "16/16 - 5s - loss: 0.2404 - accuracy_function: 0.8565 - val_loss: 1.0511 - val_accuracy_function: 0.8569\n",
      "Epoch 61/200\n",
      "\n",
      "Epoch 00061: val_accuracy_function improved from 0.85693 to 0.85790, saving model to ./data_out/seq2seq/weights.61-0.86.h5\n",
      "16/16 - 5s - loss: 0.2355 - accuracy_function: 0.8574 - val_loss: 1.0466 - val_accuracy_function: 0.8579\n",
      "Epoch 62/200\n",
      "\n",
      "Epoch 00062: val_accuracy_function improved from 0.85790 to 0.85886, saving model to ./data_out/seq2seq/weights.62-0.86.h5\n",
      "16/16 - 5s - loss: 0.2293 - accuracy_function: 0.8584 - val_loss: 1.0902 - val_accuracy_function: 0.8589\n",
      "Epoch 63/200\n",
      "\n",
      "Epoch 00063: val_accuracy_function improved from 0.85886 to 0.85983, saving model to ./data_out/seq2seq/weights.63-0.86.h5\n",
      "16/16 - 5s - loss: 0.2246 - accuracy_function: 0.8594 - val_loss: 1.0156 - val_accuracy_function: 0.8598\n",
      "Epoch 64/200\n",
      "\n",
      "Epoch 00064: val_accuracy_function improved from 0.85983 to 0.86074, saving model to ./data_out/seq2seq/weights.64-0.86.h5\n",
      "16/16 - 5s - loss: 0.2196 - accuracy_function: 0.8604 - val_loss: 1.0454 - val_accuracy_function: 0.8607\n",
      "Epoch 65/200\n",
      "\n",
      "Epoch 00065: val_accuracy_function improved from 0.86074 to 0.86163, saving model to ./data_out/seq2seq/weights.65-0.86.h5\n",
      "16/16 - 5s - loss: 0.2124 - accuracy_function: 0.8612 - val_loss: 1.1393 - val_accuracy_function: 0.8616\n",
      "Epoch 66/200\n",
      "\n",
      "Epoch 00066: val_accuracy_function improved from 0.86163 to 0.86253, saving model to ./data_out/seq2seq/weights.66-0.86.h5\n",
      "16/16 - 5s - loss: 0.1996 - accuracy_function: 0.8622 - val_loss: 1.0719 - val_accuracy_function: 0.8625\n",
      "Epoch 67/200\n",
      "\n",
      "Epoch 00067: val_accuracy_function improved from 0.86253 to 0.86350, saving model to ./data_out/seq2seq/weights.67-0.86.h5\n",
      "16/16 - 5s - loss: 0.1949 - accuracy_function: 0.8631 - val_loss: 1.0921 - val_accuracy_function: 0.8635\n",
      "Epoch 68/200\n",
      "\n",
      "Epoch 00068: val_accuracy_function improved from 0.86350 to 0.86434, saving model to ./data_out/seq2seq/weights.68-0.86.h5\n",
      "16/16 - 5s - loss: 0.2117 - accuracy_function: 0.8640 - val_loss: 1.0918 - val_accuracy_function: 0.8643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/200\n",
      "\n",
      "Epoch 00069: val_accuracy_function improved from 0.86434 to 0.86525, saving model to ./data_out/seq2seq/weights.69-0.87.h5\n",
      "16/16 - 5s - loss: 0.2051 - accuracy_function: 0.8648 - val_loss: 1.0772 - val_accuracy_function: 0.8653\n",
      "Epoch 70/200\n",
      "\n",
      "Epoch 00070: val_accuracy_function improved from 0.86525 to 0.86590, saving model to ./data_out/seq2seq/weights.70-0.87.h5\n",
      "16/16 - 5s - loss: 0.2184 - accuracy_function: 0.8656 - val_loss: 1.0915 - val_accuracy_function: 0.8659\n",
      "Epoch 71/200\n",
      "\n",
      "Epoch 00071: val_accuracy_function improved from 0.86590 to 0.86680, saving model to ./data_out/seq2seq/weights.71-0.87.h5\n",
      "16/16 - 5s - loss: 0.1950 - accuracy_function: 0.8664 - val_loss: 1.0454 - val_accuracy_function: 0.8668\n",
      "Epoch 72/200\n",
      "\n",
      "Epoch 00072: val_accuracy_function improved from 0.86680 to 0.86764, saving model to ./data_out/seq2seq/weights.72-0.87.h5\n",
      "16/16 - 5s - loss: 0.1981 - accuracy_function: 0.8672 - val_loss: 1.0410 - val_accuracy_function: 0.8676\n",
      "Epoch 73/200\n",
      "\n",
      "Epoch 00073: val_accuracy_function improved from 0.86764 to 0.86849, saving model to ./data_out/seq2seq/weights.73-0.87.h5\n",
      "16/16 - 5s - loss: 0.1887 - accuracy_function: 0.8682 - val_loss: 1.0916 - val_accuracy_function: 0.8685\n",
      "Epoch 74/200\n",
      "\n",
      "Epoch 00074: val_accuracy_function improved from 0.86849 to 0.86926, saving model to ./data_out/seq2seq/weights.74-0.87.h5\n",
      "16/16 - 5s - loss: 0.1775 - accuracy_function: 0.8689 - val_loss: 1.0860 - val_accuracy_function: 0.8693\n",
      "Epoch 75/200\n",
      "\n",
      "Epoch 00075: val_accuracy_function improved from 0.86926 to 0.87004, saving model to ./data_out/seq2seq/weights.75-0.87.h5\n",
      "16/16 - 5s - loss: 0.1685 - accuracy_function: 0.8697 - val_loss: 1.1014 - val_accuracy_function: 0.8700\n",
      "Epoch 76/200\n",
      "\n",
      "Epoch 00076: val_accuracy_function improved from 0.87004 to 0.87078, saving model to ./data_out/seq2seq/weights.76-0.87.h5\n",
      "16/16 - 5s - loss: 0.1666 - accuracy_function: 0.8705 - val_loss: 1.1255 - val_accuracy_function: 0.8708\n",
      "Epoch 77/200\n",
      "\n",
      "Epoch 00077: val_accuracy_function improved from 0.87078 to 0.87151, saving model to ./data_out/seq2seq/weights.77-0.87.h5\n",
      "16/16 - 5s - loss: 0.1627 - accuracy_function: 0.8712 - val_loss: 1.0543 - val_accuracy_function: 0.8715\n",
      "Epoch 78/200\n",
      "\n",
      "Epoch 00078: val_accuracy_function improved from 0.87151 to 0.87230, saving model to ./data_out/seq2seq/weights.78-0.87.h5\n",
      "16/16 - 5s - loss: 0.1633 - accuracy_function: 0.8720 - val_loss: 1.1058 - val_accuracy_function: 0.8723\n",
      "Epoch 79/200\n",
      "\n",
      "Epoch 00079: val_accuracy_function improved from 0.87230 to 0.87308, saving model to ./data_out/seq2seq/weights.79-0.87.h5\n",
      "16/16 - 5s - loss: 0.1624 - accuracy_function: 0.8728 - val_loss: 1.1178 - val_accuracy_function: 0.8731\n",
      "Epoch 80/200\n",
      "\n",
      "Epoch 00080: val_accuracy_function improved from 0.87308 to 0.87385, saving model to ./data_out/seq2seq/weights.80-0.87.h5\n",
      "16/16 - 5s - loss: 0.1501 - accuracy_function: 0.8736 - val_loss: 1.0887 - val_accuracy_function: 0.8739\n",
      "Epoch 81/200\n",
      "\n",
      "Epoch 00081: val_accuracy_function improved from 0.87385 to 0.87454, saving model to ./data_out/seq2seq/weights.81-0.87.h5\n",
      "16/16 - 5s - loss: 0.1509 - accuracy_function: 0.8742 - val_loss: 1.1043 - val_accuracy_function: 0.8745\n",
      "Epoch 82/200\n",
      "\n",
      "Epoch 00082: val_accuracy_function improved from 0.87454 to 0.87518, saving model to ./data_out/seq2seq/weights.82-0.88.h5\n",
      "16/16 - 5s - loss: 0.1440 - accuracy_function: 0.8749 - val_loss: 1.1405 - val_accuracy_function: 0.8752\n",
      "Epoch 83/200\n",
      "\n",
      "Epoch 00083: val_accuracy_function improved from 0.87518 to 0.87582, saving model to ./data_out/seq2seq/weights.83-0.88.h5\n",
      "16/16 - 5s - loss: 0.1475 - accuracy_function: 0.8755 - val_loss: 1.1402 - val_accuracy_function: 0.8758\n",
      "Epoch 84/200\n",
      "\n",
      "Epoch 00084: val_accuracy_function improved from 0.87582 to 0.87642, saving model to ./data_out/seq2seq/weights.84-0.88.h5\n",
      "16/16 - 5s - loss: 0.1408 - accuracy_function: 0.8762 - val_loss: 1.1336 - val_accuracy_function: 0.8764\n",
      "Epoch 85/200\n",
      "\n",
      "Epoch 00085: val_accuracy_function improved from 0.87642 to 0.87713, saving model to ./data_out/seq2seq/weights.85-0.88.h5\n",
      "16/16 - 5s - loss: 0.1316 - accuracy_function: 0.8768 - val_loss: 1.1239 - val_accuracy_function: 0.8771\n",
      "Epoch 86/200\n",
      "\n",
      "Epoch 00086: val_accuracy_function improved from 0.87713 to 0.87776, saving model to ./data_out/seq2seq/weights.86-0.88.h5\n",
      "16/16 - 5s - loss: 0.1373 - accuracy_function: 0.8776 - val_loss: 1.1689 - val_accuracy_function: 0.8778\n",
      "Epoch 87/200\n",
      "\n",
      "Epoch 00087: val_accuracy_function improved from 0.87776 to 0.87842, saving model to ./data_out/seq2seq/weights.87-0.88.h5\n",
      "16/16 - 5s - loss: 0.1327 - accuracy_function: 0.8782 - val_loss: 1.1231 - val_accuracy_function: 0.8784\n",
      "Epoch 88/200\n",
      "\n",
      "Epoch 00088: val_accuracy_function improved from 0.87842 to 0.87903, saving model to ./data_out/seq2seq/weights.88-0.88.h5\n",
      "16/16 - 5s - loss: 0.1321 - accuracy_function: 0.8788 - val_loss: 1.1542 - val_accuracy_function: 0.8790\n",
      "Epoch 89/200\n",
      "\n",
      "Epoch 00089: val_accuracy_function improved from 0.87903 to 0.87946, saving model to ./data_out/seq2seq/weights.89-0.88.h5\n",
      "16/16 - 5s - loss: 0.1433 - accuracy_function: 0.8793 - val_loss: 1.1813 - val_accuracy_function: 0.8795\n",
      "Epoch 90/200\n",
      "\n",
      "Epoch 00090: val_accuracy_function improved from 0.87946 to 0.87997, saving model to ./data_out/seq2seq/weights.90-0.88.h5\n",
      "16/16 - 5s - loss: 0.1415 - accuracy_function: 0.8798 - val_loss: 1.2192 - val_accuracy_function: 0.8800\n",
      "Epoch 91/200\n",
      "\n",
      "Epoch 00091: val_accuracy_function improved from 0.87997 to 0.88033, saving model to ./data_out/seq2seq/weights.91-0.88.h5\n",
      "16/16 - 5s - loss: 0.2333 - accuracy_function: 0.8802 - val_loss: 1.0962 - val_accuracy_function: 0.8803\n",
      "Epoch 92/200\n",
      "\n",
      "Epoch 00092: val_accuracy_function improved from 0.88033 to 0.88062, saving model to ./data_out/seq2seq/weights.92-0.88.h5\n",
      "16/16 - 5s - loss: 0.2409 - accuracy_function: 0.8805 - val_loss: 1.0832 - val_accuracy_function: 0.8806\n",
      "Epoch 93/200\n",
      "\n",
      "Epoch 00093: val_accuracy_function improved from 0.88062 to 0.88091, saving model to ./data_out/seq2seq/weights.93-0.88.h5\n",
      "16/16 - 5s - loss: 0.2277 - accuracy_function: 0.8808 - val_loss: 1.0646 - val_accuracy_function: 0.8809\n",
      "Epoch 94/200\n",
      "\n",
      "Epoch 00094: val_accuracy_function improved from 0.88091 to 0.88150, saving model to ./data_out/seq2seq/weights.94-0.88.h5\n",
      "16/16 - 5s - loss: 0.1570 - accuracy_function: 0.8813 - val_loss: 1.1248 - val_accuracy_function: 0.8815\n",
      "Epoch 95/200\n",
      "\n",
      "Epoch 00095: val_accuracy_function improved from 0.88150 to 0.88199, saving model to ./data_out/seq2seq/weights.95-0.88.h5\n",
      "16/16 - 5s - loss: 0.1447 - accuracy_function: 0.8817 - val_loss: 1.1042 - val_accuracy_function: 0.8820\n",
      "Epoch 96/200\n",
      "\n",
      "Epoch 00096: val_accuracy_function improved from 0.88199 to 0.88262, saving model to ./data_out/seq2seq/weights.96-0.88.h5\n",
      "16/16 - 5s - loss: 0.1261 - accuracy_function: 0.8824 - val_loss: 1.1081 - val_accuracy_function: 0.8826\n",
      "Epoch 97/200\n",
      "\n",
      "Epoch 00097: val_accuracy_function improved from 0.88262 to 0.88324, saving model to ./data_out/seq2seq/weights.97-0.88.h5\n",
      "16/16 - 5s - loss: 0.1217 - accuracy_function: 0.8830 - val_loss: 1.1264 - val_accuracy_function: 0.8832\n",
      "Epoch 98/200\n",
      "\n",
      "Epoch 00098: val_accuracy_function improved from 0.88324 to 0.88387, saving model to ./data_out/seq2seq/weights.98-0.88.h5\n",
      "16/16 - 5s - loss: 0.1156 - accuracy_function: 0.8836 - val_loss: 1.1286 - val_accuracy_function: 0.8839\n",
      "Epoch 99/200\n",
      "\n",
      "Epoch 00099: val_accuracy_function improved from 0.88387 to 0.88448, saving model to ./data_out/seq2seq/weights.99-0.88.h5\n",
      "16/16 - 5s - loss: 0.1108 - accuracy_function: 0.8842 - val_loss: 1.1310 - val_accuracy_function: 0.8845\n",
      "Epoch 100/200\n",
      "\n",
      "Epoch 00100: val_accuracy_function improved from 0.88448 to 0.88506, saving model to ./data_out/seq2seq/weights.100-0.89.h5\n",
      "16/16 - 5s - loss: 0.1147 - accuracy_function: 0.8848 - val_loss: 1.1415 - val_accuracy_function: 0.8851\n",
      "Epoch 101/200\n",
      "\n",
      "Epoch 00101: val_accuracy_function improved from 0.88506 to 0.88561, saving model to ./data_out/seq2seq/weights.101-0.89.h5\n",
      "16/16 - 5s - loss: 0.1128 - accuracy_function: 0.8854 - val_loss: 1.1529 - val_accuracy_function: 0.8856\n",
      "Epoch 102/200\n",
      "\n",
      "Epoch 00102: val_accuracy_function improved from 0.88561 to 0.88622, saving model to ./data_out/seq2seq/weights.102-0.89.h5\n",
      "16/16 - 5s - loss: 0.1058 - accuracy_function: 0.8860 - val_loss: 1.1431 - val_accuracy_function: 0.8862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/200\n",
      "\n",
      "Epoch 00103: val_accuracy_function improved from 0.88622 to 0.88681, saving model to ./data_out/seq2seq/weights.103-0.89.h5\n",
      "16/16 - 5s - loss: 0.1057 - accuracy_function: 0.8866 - val_loss: 1.1825 - val_accuracy_function: 0.8868\n",
      "Epoch 104/200\n",
      "\n",
      "Epoch 00104: val_accuracy_function improved from 0.88681 to 0.88737, saving model to ./data_out/seq2seq/weights.104-0.89.h5\n",
      "16/16 - 5s - loss: 0.1020 - accuracy_function: 0.8871 - val_loss: 1.1574 - val_accuracy_function: 0.8874\n",
      "Epoch 105/200\n",
      "\n",
      "Epoch 00105: val_accuracy_function improved from 0.88737 to 0.88792, saving model to ./data_out/seq2seq/weights.105-0.89.h5\n",
      "16/16 - 5s - loss: 0.1040 - accuracy_function: 0.8877 - val_loss: 1.1807 - val_accuracy_function: 0.8879\n",
      "Epoch 106/200\n",
      "\n",
      "Epoch 00106: val_accuracy_function improved from 0.88792 to 0.88851, saving model to ./data_out/seq2seq/weights.106-0.89.h5\n",
      "16/16 - 5s - loss: 0.0993 - accuracy_function: 0.8882 - val_loss: 1.1645 - val_accuracy_function: 0.8885\n",
      "Epoch 107/200\n",
      "\n",
      "Epoch 00107: val_accuracy_function improved from 0.88851 to 0.88906, saving model to ./data_out/seq2seq/weights.107-0.89.h5\n",
      "16/16 - 5s - loss: 0.0958 - accuracy_function: 0.8889 - val_loss: 1.1725 - val_accuracy_function: 0.8891\n",
      "Epoch 108/200\n",
      "\n",
      "Epoch 00108: val_accuracy_function improved from 0.88906 to 0.88967, saving model to ./data_out/seq2seq/weights.108-0.89.h5\n",
      "16/16 - 5s - loss: 0.0950 - accuracy_function: 0.8895 - val_loss: 1.1520 - val_accuracy_function: 0.8897\n",
      "Epoch 109/200\n",
      "\n",
      "Epoch 00109: val_accuracy_function improved from 0.88967 to 0.89013, saving model to ./data_out/seq2seq/weights.109-0.89.h5\n",
      "16/16 - 5s - loss: 0.0965 - accuracy_function: 0.8900 - val_loss: 1.1809 - val_accuracy_function: 0.8901\n",
      "Epoch 110/200\n",
      "\n",
      "Epoch 00110: val_accuracy_function improved from 0.89013 to 0.89070, saving model to ./data_out/seq2seq/weights.110-0.89.h5\n",
      "16/16 - 5s - loss: 0.0896 - accuracy_function: 0.8905 - val_loss: 1.2042 - val_accuracy_function: 0.8907\n",
      "Epoch 111/200\n",
      "\n",
      "Epoch 00111: val_accuracy_function improved from 0.89070 to 0.89128, saving model to ./data_out/seq2seq/weights.111-0.89.h5\n",
      "16/16 - 5s - loss: 0.0888 - accuracy_function: 0.8910 - val_loss: 1.1773 - val_accuracy_function: 0.8913\n",
      "Epoch 112/200\n",
      "\n",
      "Epoch 00112: val_accuracy_function improved from 0.89128 to 0.89182, saving model to ./data_out/seq2seq/weights.112-0.89.h5\n",
      "16/16 - 5s - loss: 0.0896 - accuracy_function: 0.8916 - val_loss: 1.2092 - val_accuracy_function: 0.8918\n",
      "Epoch 113/200\n",
      "\n",
      "Epoch 00113: val_accuracy_function improved from 0.89182 to 0.89240, saving model to ./data_out/seq2seq/weights.113-0.89.h5\n",
      "16/16 - 5s - loss: 0.0887 - accuracy_function: 0.8922 - val_loss: 1.1539 - val_accuracy_function: 0.8924\n",
      "Epoch 114/200\n",
      "\n",
      "Epoch 00114: val_accuracy_function improved from 0.89240 to 0.89291, saving model to ./data_out/seq2seq/weights.114-0.89.h5\n",
      "16/16 - 5s - loss: 0.0892 - accuracy_function: 0.8927 - val_loss: 1.2240 - val_accuracy_function: 0.8929\n",
      "Epoch 115/200\n",
      "\n",
      "Epoch 00115: val_accuracy_function improved from 0.89291 to 0.89344, saving model to ./data_out/seq2seq/weights.115-0.89.h5\n",
      "16/16 - 5s - loss: 0.0901 - accuracy_function: 0.8932 - val_loss: 1.2199 - val_accuracy_function: 0.8934\n",
      "Epoch 116/200\n",
      "\n",
      "Epoch 00116: val_accuracy_function improved from 0.89344 to 0.89377, saving model to ./data_out/seq2seq/weights.116-0.89.h5\n",
      "16/16 - 5s - loss: 0.1233 - accuracy_function: 0.8936 - val_loss: 1.1877 - val_accuracy_function: 0.8938\n",
      "Epoch 117/200\n",
      "\n",
      "Epoch 00117: val_accuracy_function improved from 0.89377 to 0.89410, saving model to ./data_out/seq2seq/weights.117-0.89.h5\n",
      "16/16 - 5s - loss: 0.1506 - accuracy_function: 0.8940 - val_loss: 1.1882 - val_accuracy_function: 0.8941\n",
      "Epoch 118/200\n",
      "\n",
      "Epoch 00118: val_accuracy_function improved from 0.89410 to 0.89436, saving model to ./data_out/seq2seq/weights.118-0.89.h5\n",
      "16/16 - 5s - loss: 0.1767 - accuracy_function: 0.8942 - val_loss: 1.0920 - val_accuracy_function: 0.8944\n",
      "Epoch 119/200\n",
      "\n",
      "Epoch 00119: val_accuracy_function improved from 0.89436 to 0.89466, saving model to ./data_out/seq2seq/weights.119-0.89.h5\n",
      "16/16 - 5s - loss: 0.1568 - accuracy_function: 0.8946 - val_loss: 1.0985 - val_accuracy_function: 0.8947\n",
      "Epoch 120/200\n",
      "\n",
      "Epoch 00120: val_accuracy_function improved from 0.89466 to 0.89501, saving model to ./data_out/seq2seq/weights.120-0.90.h5\n",
      "16/16 - 5s - loss: 0.1461 - accuracy_function: 0.8948 - val_loss: 1.1544 - val_accuracy_function: 0.8950\n",
      "Epoch 121/200\n",
      "\n",
      "Epoch 00121: val_accuracy_function improved from 0.89501 to 0.89548, saving model to ./data_out/seq2seq/weights.121-0.90.h5\n",
      "16/16 - 5s - loss: 0.1079 - accuracy_function: 0.8953 - val_loss: 1.1427 - val_accuracy_function: 0.8955\n",
      "Epoch 122/200\n",
      "\n",
      "Epoch 00122: val_accuracy_function improved from 0.89548 to 0.89592, saving model to ./data_out/seq2seq/weights.122-0.90.h5\n",
      "16/16 - 5s - loss: 0.1032 - accuracy_function: 0.8958 - val_loss: 1.1913 - val_accuracy_function: 0.8959\n",
      "Epoch 123/200\n",
      "\n",
      "Epoch 00123: val_accuracy_function improved from 0.89592 to 0.89643, saving model to ./data_out/seq2seq/weights.123-0.90.h5\n",
      "16/16 - 5s - loss: 0.0920 - accuracy_function: 0.8962 - val_loss: 1.1467 - val_accuracy_function: 0.8964\n",
      "Epoch 124/200\n",
      "\n",
      "Epoch 00124: val_accuracy_function improved from 0.89643 to 0.89699, saving model to ./data_out/seq2seq/weights.124-0.90.h5\n",
      "16/16 - 5s - loss: 0.0846 - accuracy_function: 0.8968 - val_loss: 1.2111 - val_accuracy_function: 0.8970\n",
      "Epoch 125/200\n",
      "\n",
      "Epoch 00125: val_accuracy_function improved from 0.89699 to 0.89751, saving model to ./data_out/seq2seq/weights.125-0.90.h5\n",
      "16/16 - 5s - loss: 0.0772 - accuracy_function: 0.8973 - val_loss: 1.1750 - val_accuracy_function: 0.8975\n",
      "Epoch 126/200\n",
      "\n",
      "Epoch 00126: val_accuracy_function improved from 0.89751 to 0.89809, saving model to ./data_out/seq2seq/weights.126-0.90.h5\n",
      "16/16 - 5s - loss: 0.0731 - accuracy_function: 0.8978 - val_loss: 1.1876 - val_accuracy_function: 0.8981\n",
      "Epoch 127/200\n",
      "\n",
      "Epoch 00127: val_accuracy_function improved from 0.89809 to 0.89858, saving model to ./data_out/seq2seq/weights.127-0.90.h5\n",
      "16/16 - 5s - loss: 0.0751 - accuracy_function: 0.8984 - val_loss: 1.2041 - val_accuracy_function: 0.8986\n",
      "Epoch 128/200\n",
      "\n",
      "Epoch 00128: val_accuracy_function improved from 0.89858 to 0.89906, saving model to ./data_out/seq2seq/weights.128-0.90.h5\n",
      "16/16 - 5s - loss: 0.0711 - accuracy_function: 0.8989 - val_loss: 1.1932 - val_accuracy_function: 0.8991\n",
      "Epoch 129/200\n",
      "\n",
      "Epoch 00129: val_accuracy_function improved from 0.89906 to 0.89958, saving model to ./data_out/seq2seq/weights.129-0.90.h5\n",
      "16/16 - 5s - loss: 0.0713 - accuracy_function: 0.8994 - val_loss: 1.2136 - val_accuracy_function: 0.8996\n",
      "Epoch 130/200\n",
      "\n",
      "Epoch 00130: val_accuracy_function improved from 0.89958 to 0.90008, saving model to ./data_out/seq2seq/weights.130-0.90.h5\n",
      "16/16 - 5s - loss: 0.0665 - accuracy_function: 0.8999 - val_loss: 1.2066 - val_accuracy_function: 0.9001\n",
      "Epoch 131/200\n",
      "\n",
      "Epoch 00131: val_accuracy_function improved from 0.90008 to 0.90058, saving model to ./data_out/seq2seq/weights.131-0.90.h5\n",
      "16/16 - 5s - loss: 0.0652 - accuracy_function: 0.9004 - val_loss: 1.2211 - val_accuracy_function: 0.9006\n",
      "Epoch 132/200\n",
      "\n",
      "Epoch 00132: val_accuracy_function improved from 0.90058 to 0.90106, saving model to ./data_out/seq2seq/weights.132-0.90.h5\n",
      "16/16 - 5s - loss: 0.0636 - accuracy_function: 0.9009 - val_loss: 1.2153 - val_accuracy_function: 0.9011\n",
      "Epoch 133/200\n",
      "\n",
      "Epoch 00133: val_accuracy_function improved from 0.90106 to 0.90156, saving model to ./data_out/seq2seq/weights.133-0.90.h5\n",
      "16/16 - 5s - loss: 0.0626 - accuracy_function: 0.9013 - val_loss: 1.2022 - val_accuracy_function: 0.9016\n",
      "Epoch 134/200\n",
      "\n",
      "Epoch 00134: val_accuracy_function improved from 0.90156 to 0.90206, saving model to ./data_out/seq2seq/weights.134-0.90.h5\n",
      "16/16 - 5s - loss: 0.0594 - accuracy_function: 0.9019 - val_loss: 1.2152 - val_accuracy_function: 0.9021\n",
      "Epoch 135/200\n",
      "\n",
      "Epoch 00135: val_accuracy_function improved from 0.90206 to 0.90256, saving model to ./data_out/seq2seq/weights.135-0.90.h5\n",
      "16/16 - 5s - loss: 0.0587 - accuracy_function: 0.9023 - val_loss: 1.2655 - val_accuracy_function: 0.9026\n",
      "Epoch 136/200\n",
      "\n",
      "Epoch 00136: val_accuracy_function improved from 0.90256 to 0.90304, saving model to ./data_out/seq2seq/weights.136-0.90.h5\n",
      "16/16 - 5s - loss: 0.0590 - accuracy_function: 0.9028 - val_loss: 1.2151 - val_accuracy_function: 0.9030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/200\n",
      "\n",
      "Epoch 00137: val_accuracy_function improved from 0.90304 to 0.90349, saving model to ./data_out/seq2seq/weights.137-0.90.h5\n",
      "16/16 - 5s - loss: 0.0594 - accuracy_function: 0.9033 - val_loss: 1.2352 - val_accuracy_function: 0.9035\n",
      "Epoch 138/200\n",
      "\n",
      "Epoch 00138: val_accuracy_function improved from 0.90349 to 0.90395, saving model to ./data_out/seq2seq/weights.138-0.90.h5\n",
      "16/16 - 5s - loss: 0.0539 - accuracy_function: 0.9037 - val_loss: 1.2550 - val_accuracy_function: 0.9040\n",
      "Epoch 139/200\n",
      "\n",
      "Epoch 00139: val_accuracy_function improved from 0.90395 to 0.90443, saving model to ./data_out/seq2seq/weights.139-0.90.h5\n",
      "16/16 - 5s - loss: 0.0553 - accuracy_function: 0.9042 - val_loss: 1.2287 - val_accuracy_function: 0.9044\n",
      "Epoch 140/200\n",
      "\n",
      "Epoch 00140: val_accuracy_function improved from 0.90443 to 0.90490, saving model to ./data_out/seq2seq/weights.140-0.90.h5\n",
      "16/16 - 5s - loss: 0.0521 - accuracy_function: 0.9047 - val_loss: 1.2658 - val_accuracy_function: 0.9049\n",
      "Epoch 141/200\n",
      "\n",
      "Epoch 00141: val_accuracy_function improved from 0.90490 to 0.90536, saving model to ./data_out/seq2seq/weights.141-0.91.h5\n",
      "16/16 - 5s - loss: 0.0506 - accuracy_function: 0.9052 - val_loss: 1.2556 - val_accuracy_function: 0.9054\n",
      "Epoch 142/200\n",
      "\n",
      "Epoch 00142: val_accuracy_function improved from 0.90536 to 0.90578, saving model to ./data_out/seq2seq/weights.142-0.91.h5\n",
      "16/16 - 5s - loss: 0.0494 - accuracy_function: 0.9056 - val_loss: 1.2600 - val_accuracy_function: 0.9058\n",
      "Epoch 143/200\n",
      "\n",
      "Epoch 00143: val_accuracy_function improved from 0.90578 to 0.90619, saving model to ./data_out/seq2seq/weights.143-0.91.h5\n",
      "16/16 - 5s - loss: 0.0505 - accuracy_function: 0.9060 - val_loss: 1.3062 - val_accuracy_function: 0.9062\n",
      "Epoch 144/200\n",
      "\n",
      "Epoch 00144: val_accuracy_function improved from 0.90619 to 0.90662, saving model to ./data_out/seq2seq/weights.144-0.91.h5\n",
      "16/16 - 5s - loss: 0.0476 - accuracy_function: 0.9064 - val_loss: 1.2636 - val_accuracy_function: 0.9066\n",
      "Epoch 145/200\n",
      "\n",
      "Epoch 00145: val_accuracy_function improved from 0.90662 to 0.90704, saving model to ./data_out/seq2seq/weights.145-0.91.h5\n",
      "16/16 - 5s - loss: 0.0441 - accuracy_function: 0.9068 - val_loss: 1.3027 - val_accuracy_function: 0.9070\n",
      "Epoch 146/200\n",
      "\n",
      "Epoch 00146: val_accuracy_function improved from 0.90704 to 0.90747, saving model to ./data_out/seq2seq/weights.146-0.91.h5\n",
      "16/16 - 5s - loss: 0.0442 - accuracy_function: 0.9073 - val_loss: 1.2692 - val_accuracy_function: 0.9075\n",
      "Epoch 147/200\n",
      "\n",
      "Epoch 00147: val_accuracy_function improved from 0.90747 to 0.90785, saving model to ./data_out/seq2seq/weights.147-0.91.h5\n",
      "16/16 - 5s - loss: 0.0477 - accuracy_function: 0.9077 - val_loss: 1.3043 - val_accuracy_function: 0.9079\n",
      "Epoch 148/200\n",
      "\n",
      "Epoch 00148: val_accuracy_function improved from 0.90785 to 0.90821, saving model to ./data_out/seq2seq/weights.148-0.91.h5\n",
      "16/16 - 5s - loss: 0.0611 - accuracy_function: 0.9081 - val_loss: 1.3091 - val_accuracy_function: 0.9082\n",
      "Epoch 149/200\n",
      "\n",
      "Epoch 00149: val_accuracy_function improved from 0.90821 to 0.90853, saving model to ./data_out/seq2seq/weights.149-0.91.h5\n",
      "16/16 - 5s - loss: 0.0578 - accuracy_function: 0.9084 - val_loss: 1.2713 - val_accuracy_function: 0.9085\n",
      "Epoch 150/200\n",
      "\n",
      "Epoch 00150: val_accuracy_function improved from 0.90853 to 0.90884, saving model to ./data_out/seq2seq/weights.150-0.91.h5\n",
      "16/16 - 5s - loss: 0.0891 - accuracy_function: 0.9087 - val_loss: 1.3074 - val_accuracy_function: 0.9088\n",
      "Epoch 151/200\n",
      "\n",
      "Epoch 00151: val_accuracy_function improved from 0.90884 to 0.90904, saving model to ./data_out/seq2seq/weights.151-0.91.h5\n",
      "16/16 - 5s - loss: 0.1342 - accuracy_function: 0.9090 - val_loss: 1.2158 - val_accuracy_function: 0.9090\n",
      "Epoch 152/200\n",
      "\n",
      "Epoch 00152: val_accuracy_function improved from 0.90904 to 0.90918, saving model to ./data_out/seq2seq/weights.152-0.91.h5\n",
      "16/16 - 5s - loss: 0.1787 - accuracy_function: 0.9092 - val_loss: 1.6069 - val_accuracy_function: 0.9092\n",
      "Epoch 153/200\n",
      "\n",
      "Epoch 00153: val_accuracy_function improved from 0.90918 to 0.90938, saving model to ./data_out/seq2seq/weights.153-0.91.h5\n",
      "16/16 - 5s - loss: 0.1551 - accuracy_function: 0.9093 - val_loss: 1.2048 - val_accuracy_function: 0.9094\n",
      "Epoch 154/200\n",
      "\n",
      "Epoch 00154: val_accuracy_function improved from 0.90938 to 0.90955, saving model to ./data_out/seq2seq/weights.154-0.91.h5\n",
      "16/16 - 5s - loss: 0.1324 - accuracy_function: 0.9095 - val_loss: 1.2311 - val_accuracy_function: 0.9096\n",
      "Epoch 155/200\n",
      "\n",
      "Epoch 00155: val_accuracy_function improved from 0.90955 to 0.90979, saving model to ./data_out/seq2seq/weights.155-0.91.h5\n",
      "16/16 - 5s - loss: 0.0928 - accuracy_function: 0.9097 - val_loss: 1.2133 - val_accuracy_function: 0.9098\n",
      "Epoch 156/200\n",
      "\n",
      "Epoch 00156: val_accuracy_function improved from 0.90979 to 0.91009, saving model to ./data_out/seq2seq/weights.156-0.91.h5\n",
      "16/16 - 5s - loss: 0.0645 - accuracy_function: 0.9100 - val_loss: 1.2336 - val_accuracy_function: 0.9101\n",
      "Epoch 157/200\n",
      "\n",
      "Epoch 00157: val_accuracy_function improved from 0.91009 to 0.91049, saving model to ./data_out/seq2seq/weights.157-0.91.h5\n",
      "16/16 - 5s - loss: 0.0460 - accuracy_function: 0.9103 - val_loss: 1.2124 - val_accuracy_function: 0.9105\n",
      "Epoch 158/200\n",
      "\n",
      "Epoch 00158: val_accuracy_function improved from 0.91049 to 0.91085, saving model to ./data_out/seq2seq/weights.158-0.91.h5\n",
      "16/16 - 5s - loss: 0.0421 - accuracy_function: 0.9107 - val_loss: 1.2439 - val_accuracy_function: 0.9108\n",
      "Epoch 159/200\n",
      "\n",
      "Epoch 00159: val_accuracy_function improved from 0.91085 to 0.91122, saving model to ./data_out/seq2seq/weights.159-0.91.h5\n",
      "16/16 - 5s - loss: 0.0400 - accuracy_function: 0.9111 - val_loss: 1.2765 - val_accuracy_function: 0.9112\n",
      "Epoch 160/200\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy_function` which is not available. Available metrics are: loss,accuracy_function\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_accuracy_function'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m       \u001b[0;32myield\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    768\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-40271234391e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m history = model.fit([index_inputs, index_outputs], index_targets, \n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n\u001b[0m\u001b[1;32m      6\u001b[0m                     \u001b[0;31m#validation_split=VALID_SPLIT, callbacks=[])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    395\u001b[0m                       total_epochs=1)\n\u001b[1;32m    396\u001b[0m                   cbks.make_logs(model, epoch_logs, eval_result, ModeKeys.TEST,\n\u001b[0;32m--> 397\u001b[0;31m                                  prefix='val_')\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_epoch\u001b[0;34m(self, epoch, mode)\u001b[0m\n\u001b[1;32m    769\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m         \u001b[0;31m# Epochs only apply to `fit`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    990\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m       \u001b[0;31m# For multi-worker training, back up the weights and current training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1009\u001b[0m                   int) or self.epochs_since_last_save >= self.period:\n\u001b[1;32m   1010\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs_since_last_save\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_get_file_path\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     if not self.model._in_multi_worker_mode(\n\u001b[1;32m   1054\u001b[0m     ) or multi_worker_util.should_save_checkpoint():\n\u001b[0;32m-> 1055\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0;31m# If this is multi-worker training, and this worker should not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy_function'"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy_function', patience=10)\n",
    "\n",
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCH, verbose=2,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "                    #validation_split=VALID_SPLIT, callbacks=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "!apt-get update -qq #나눔고딕 인스톨\n",
    "!apt-get install fonts-nanum* -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanumGothic Eco\n"
     ]
    }
   ],
   "source": [
    "path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'  \n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name() \n",
    "print(font_name)\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((MAX_SEQUENCE, MAX_SEQUENCE))\n",
    "    \n",
    "    index_inputs, input_seq_len = enc_processing([sentence], char2idx)    \n",
    "    \n",
    "    inputs = index_inputs\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([char2idx[STD]], 0)\n",
    "\n",
    "    for t in range(MAX_SEQUENCE):    \n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        result += idx2char[predicted_id] + ' '\n",
    "\n",
    "        if idx2char[predicted_id] == '<END>':\n",
    "            return result, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(attention, sentence, result):\n",
    "    #result = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence)) # 텍스트 처리\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 best model 이름\n",
    "SAVE_FILE_LW = 'weights.157-0.91.h5'\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_LW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['남자친구 승진 선물로 뭐가 좋을까?']\n",
      "Input: 남자친구 승진 선물로 뭐가 좋을까?\n",
      "Predicted translation: 좋아요 쫄딱 새출발 해보세요 게 가스비 게 가스비 게 가스비 게 가스비 게 가스비 게 가스비 게 가스비 게 가스비 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "query = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "\n",
    "result, attention = evaluate(query)\n",
    "translate(attention, query, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
