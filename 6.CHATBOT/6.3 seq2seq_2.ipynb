{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "PAD = \"<PAD>\"\n",
    "STD = \"<SOS>\"\n",
    "END = \"<END>\"\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "MARKER = [PAD, STD, END, UNK]\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "#PATH = 'data_in/ChatbotData.csv'\n",
    "PATH = 'data_in/ChatBotData.csv_short'\n",
    "VOCAB_PATH = 'data_in/vocabulary.txt'\n",
    "\n",
    "MAX_SEQUENCE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # 판다스를 통해서 데이터를 불러온다.\n",
    "    data_df = pd.read_csv(path, header=0)\n",
    "    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = load_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징과 어휘사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tokenizer(data):\n",
    "    # 토크나이징 해서 담을 배열 생성\n",
    "    words = []\n",
    "    for sentence in data:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 위 필터와 같은 값들을 정규화 표현식을\n",
    "        # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "        for word in sentence.split():\n",
    "            words.append(word)\n",
    "    # 토그나이징과 정규표현식을 통해 만들어진\n",
    "    # 값들을 넘겨 준다.\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def load_vocabulary(path, vocab_path):\n",
    "    # 사전을 담을 배열 준비한다.\n",
    "    vocabulary_list = []\n",
    "    # 사전을 구성한 후 파일로 저장 진행한다.\n",
    "    # 그 파일의 존재 유무를 확인한다.\n",
    "    if not os.path.exists(vocab_path):\n",
    "        # 이미 생성된 사전 파일이 존재하지 않으므로\n",
    "        # 데이터를 가지고 만들어야 한다.\n",
    "        # 그래서 데이터가 존재 하면 사전을 만들기 위해서\n",
    "        # 데이터 파일의 존재 유무를 확인한다.\n",
    "        if (os.path.exists(path)):\n",
    "            # 데이터가 존재하니 판단스를 통해서\n",
    "            # 데이터를 불러오자\n",
    "            data_df = pd.read_csv(path, encoding='utf-8')\n",
    "            # 판다스의 데이터 프레임을 통해서\n",
    "            # 질문과 답에 대한 열을 가져 온다.\n",
    "            question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "#             if DEFINES.tokenize_as_morph:  # 형태소에 따른 토크나이져 처리\n",
    "#                 question = prepro_like_morphlized(question)\n",
    "#                 answer = prepro_like_morphlized(answer)\n",
    "            data = []\n",
    "            # 질문과 답변을 extend을\n",
    "            # 통해서 구조가 없는 배열로 만든다.\n",
    "            data.extend(question)\n",
    "            data.extend(answer)\n",
    "            # 토큰나이져 처리 하는 부분이다.\n",
    "            words = data_tokenizer(data)\n",
    "            # 공통적인 단어에 대해서는 모두\n",
    "            # 필요 없으므로 한개로 만들어 주기 위해서\n",
    "            # set해주고 이것들을 리스트로 만들어 준다.\n",
    "            words = list(set(words))\n",
    "            # 데이터 없는 내용중에 MARKER를 사전에\n",
    "            # 추가 하기 위해서 아래와 같이 처리 한다.\n",
    "            # 아래는 MARKER 값이며 리스트의 첫번째 부터\n",
    "            # 순서대로 넣기 위해서 인덱스 0에 추가한다.\n",
    "            # PAD = \"<PADDING>\"\n",
    "            # STD = \"<START>\"\n",
    "            # END = \"<END>\"\n",
    "            # UNK = \"<UNKNWON>\"\n",
    "            words[:0] = MARKER\n",
    "        # 사전을 리스트로 만들었으니 이 내용을\n",
    "        # 사전 파일을 만들어 넣는다.\n",
    "        with open(vocab_path, 'w', encoding='utf-8') as vocabulary_file:\n",
    "            for word in words:\n",
    "                vocabulary_file.write(word + '\\n')\n",
    "\n",
    "    # 사전 파일이 존재하면 여기에서\n",
    "    # 그 파일을 불러서 배열에 넣어 준다.\n",
    "    with open(vocab_path, 'r', encoding='utf-8') as vocabulary_file:\n",
    "        for line in vocabulary_file:\n",
    "            vocabulary_list.append(line.strip())\n",
    "\n",
    "    # 배열에 내용을 키와 값이 있는\n",
    "    # 딕셔너리 구조로 만든다.\n",
    "    char2idx, idx2char = make_vocabulary(vocabulary_list)\n",
    "    # 두가지 형태의 키와 값이 있는 형태를 리턴한다.\n",
    "    # (예) 단어: 인덱스 , 인덱스: 단어)\n",
    "    return char2idx, idx2char, len(char2idx)\n",
    "\n",
    "\n",
    "def make_vocabulary(vocabulary_list):\n",
    "    # 리스트를 키가 단어이고 값이 인덱스인\n",
    "    # 딕셔너리를 만든다.\n",
    "    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n",
    "    # 리스트를 키가 인덱스이고 값이 단어인\n",
    "    # 딕셔너리를 만든다.\n",
    "    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n",
    "    # 두개의 딕셔너리를 넘겨 준다.\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx, idx2char, vocab_size = load_vocabulary(PATH, VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다.)\n",
    "    sequences_input_index = []\n",
    "    # 하나의 인코딩 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다.)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "\n",
    "    print(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 인코딩 할때\n",
    "        # 가지고 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 문장을 스페이스 단위로\n",
    "        # 자르고 있다.\n",
    "        for word in sequence.split():\n",
    "            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고\n",
    "            # 그 값을 가져와 sequence_index에 추가한다.\n",
    "            if dictionary.get(word) is not None:\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "            # 잘려진 단어가 딕셔너리에 존재 하지 않는\n",
    "            # 경우 이므로 UNK(2)를 넣어 준다.\n",
    "            else:\n",
    "                sequence_index.extend([dictionary[UNK]])\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_input_index에 넣어 준다.\n",
    "        sequences_input_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과\n",
    "    # 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_input_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_output_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_output_index = []\n",
    "    # 하나의 디코딩 입력 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 디코딩 할때 가지고\n",
    "        # 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 디코딩 입력의 처음에는 START가 와야 하므로\n",
    "        # 그 값을 넣어 주고 시작한다.\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서 딕셔너리의\n",
    "        # 값인 인덱스를 넣어 준다.\n",
    "        sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) >= MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE - 1] + [dictionary[END]]\n",
    "        else:\n",
    "            sequence_index += [dictionary[END]]\n",
    "            \n",
    "#         if len(sequence_index) > MAX_SEQUENCE:\n",
    "#             sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "#         # 하나의 문장에 길이를 넣어주고 있다.\n",
    "#         sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_output_index 넣어 준다.\n",
    "        sequences_output_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_output_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_target_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_target_index = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서\n",
    "        # 딕셔너리의 값인 인덱스를 넣어 준다.\n",
    "        # 디코딩 출력의 마지막에 END를 넣어 준다.\n",
    "        sequence_index = [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        # 그리고 END 토큰을 넣어 준다\n",
    "        if len(sequence_index) >= MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE - 1] + [dictionary[END]]\n",
    "        else:\n",
    "            sequence_index += [dictionary[END]]\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_target_index에 넣어 준다.\n",
    "        sequences_target_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가끔 궁금해', '가끔 뭐하는지 궁금해', '가끔은 혼자인게 좋다', '가난한 자의 설움', '가만 있어도 땀난다', '가상화폐 쫄딱 망함', '가스불 켜고 나갔어', '가스불 켜놓고 나온거 같아', '가스비 너무 많이 나왔다.', '가스비 비싼데 감기 걸리겠어', '남자친구 교회 데려가고 싶어', '남자친구 또 운동 갔어', '남자친구 생일인데 뭘 줄까', '남자친구 승진 선물로 뭐가 좋을까?', '남자친구 오늘 따라 훈훈해 보인다', '남자친구 오늘 좀 질린다.', '남자친구가 나 안 믿어줘', '남자친구가 너무 바빠', '남자친구가 너무 운동만 해', '남자친구가 너무 잘생겼어']\n"
     ]
    }
   ],
   "source": [
    "index_inputs, input_seq_len = enc_processing(inputs, char2idx)\n",
    "index_outputs, output_seq_len = dec_output_processing(outputs, char2idx)\n",
    "index_targets = dec_target_processing(outputs, char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 0 20\n"
     ]
    }
   ],
   "source": [
    "# Show length\n",
    "print(len(index_inputs), len(input_seq_len), len(index_outputs), len(output_seq_len), len(index_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,  36, 109,  21,   8,   2,   0,   0,   0,   0],\n",
       "       [  1,  36, 109,  21,   8,   2,   0,   0,   0,   0],\n",
       "       [  1,  84,  64,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,  30, 102,  45,   8,   2,   0,   0,   0,   0],\n",
       "       [  1,   4,  56,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,  12,  29,  71,  95,   2,   0,   0,   0,   0],\n",
       "       [  1,  48,  85,  18,  69,  65,   2,   0,   0,   0],\n",
       "       [  1,  48,  85,  18,  69,  65,   2,   0,   0,   0],\n",
       "       [  1,  38, 100,  19,  93,   2,   0,   0,   0,   0],\n",
       "       [  1,  51,  39,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  1,  76,  52,  35,  90,   2,   0,   0,   0,   0],\n",
       "       [  1,  43,  88, 108,   2,   0,   0,   0,   0,   0],\n",
       "       [  1,  66,  89,  24,  40,   2,   0,   0,   0,   0],\n",
       "       [  1,  66,  59,  86,  67,  24,  74,   2,   0,   0],\n",
       "       [  1, 107,  13,  81,   2,   0,   0,   0,   0,   0],\n",
       "       [  1,  55,  11,  27,   2,   0,   0,   0,   0,   0],\n",
       "       [  1, 110,  25,  95,   2,   0,   0,   0,   0,   0],\n",
       "       [  1,  42,  77,  16,   2,   0,   0,   0,   0,   0],\n",
       "       [  1,  43,  88, 108,   2,   0,   0,   0,   0,   0],\n",
       "       [  1, 107,  13,  81,   2,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALID_SPLIT = 0.2\n",
    "#BATCH_SIZE = 100\n",
    "BATCH_SIZE = 2\n",
    "units = 1024\n",
    "embedding_dim = 256\n",
    "#EPOCH = 100\n",
    "EPOCH = 100\n",
    "#EPOCH = len(index_inputs)//BATCH_SIZE\n",
    "BUFFER_SIZE = len(index_inputs)\n",
    "DATA_OUT_PATH = './data_out/'\n",
    "DATA_IN_PATH = './data_in/'\n",
    "model_name = 'seq2seq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_inputs = index_inputs[:10000]\n",
    "index_outputs = index_outputs[:10000]\n",
    "index_targets = index_targets[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20\n"
     ]
    }
   ],
   "source": [
    "print(len(index_inputs), len(index_outputs), len(index_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    #def __init__(self, **kargs):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim          \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim  \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    real = tf.dtypes.cast(real, tf.float32)\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz):    \n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz) #vocab_size, embedding_dim, enc_units, batch_sz\n",
    "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz) #vocab_size, embedding_dim, dec_units, batch_sz\n",
    "        self.final_layer = tf.keras.layers.Dense(vocab_size)\n",
    "            \n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "\n",
    "        enc_hidden = self.encoder.initialize_hidden_state()\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        #dec_input = tf.expand_dims([STD_INDEX] * BATCH_SIZE, 1)\n",
    "        predict_tokens = list()\n",
    "        \n",
    "        for t in range(0, tar.shape[1]):\n",
    "            dec_input = tf.expand_dims(tar[:, t], 1)\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))\n",
    "\n",
    "        return tf.stack(predict_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2seq(vocab_size, embedding_dim, units, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_function,\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=[accuracy_function])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_out/seq2seq -- Folder already exists \n",
      "\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.{epoch:02d}-{val_accuracy_function:.2f}.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "\n",
    "#SAVE_FILE_LW = 'weights.99-0.83.h5'\n",
    "#model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_LW))\n",
    "\n",
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_accuracy_function', verbose=2, save_best_only=True, save_weights_only=True)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : Tensor(\"seq2seq/decoder_1/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 1\n",
      "output : Tensor(\"seq2seq/decoder_1_1/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_1/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 2\n",
      "output : Tensor(\"seq2seq/decoder_1_2/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_2/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_2/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 3\n",
      "output : Tensor(\"seq2seq/decoder_1_3/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_3/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_3/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 4\n",
      "output : Tensor(\"seq2seq/decoder_1_4/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_4/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_4/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 5\n",
      "output : Tensor(\"seq2seq/decoder_1_5/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_5/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_5/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 6\n",
      "output : Tensor(\"seq2seq/decoder_1_6/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_6/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_6/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 7\n",
      "output : Tensor(\"seq2seq/decoder_1_7/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_7/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_7/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : Tensor(\"seq2seq/decoder_1_8/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_8/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_8/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 9\n",
      "output : Tensor(\"seq2seq/decoder_1_9/gru_3/Identity:0\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_9/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_9/Identity:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/Identity:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/Identity:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_9/Identity:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 10\n",
      "real : Tensor(\"output_1_target:0\", shape=(None, None, None), dtype=float32) real.shape : (None, None, None)\n",
      "pred : Tensor(\"seq2seq/Identity:0\", shape=(2, 10, 111), dtype=float32) pred.shape : (2, 10, 111)\n",
      "real : Tensor(\"output_1_target:0\", shape=(None, None, None), dtype=float32) real.shape : (None, None, None)\n",
      "Train on 16 samples, validate on 4 samples\n",
      "Epoch 1/100\n",
      "output : Tensor(\"seq2seq/decoder_1/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 1\n",
      "output : Tensor(\"seq2seq/decoder_1_1/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_1/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 2\n",
      "output : Tensor(\"seq2seq/decoder_1_2/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_2/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_2/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 3\n",
      "output : Tensor(\"seq2seq/decoder_1_3/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_3/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_3/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 4\n",
      "output : Tensor(\"seq2seq/decoder_1_4/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_4/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_4/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : Tensor(\"seq2seq/decoder_1_5/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_5/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_5/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 6\n",
      "output : Tensor(\"seq2seq/decoder_1_6/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_6/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_6/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 7\n",
      "output : Tensor(\"seq2seq/decoder_1_7/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_7/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_7/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 8\n",
      "output : Tensor(\"seq2seq/decoder_1_8/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_8/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_8/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 9\n",
      "output : Tensor(\"seq2seq/decoder_1_9/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_9/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_9/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_9/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 10\n",
      "real : Tensor(\"IteratorGetNext:2\", shape=(2, 10), dtype=int64) real.shape : (2, 10)\n",
      "pred : Tensor(\"seq2seq/stack:0\", shape=(2, 10, 111), dtype=float32) pred.shape : (2, 10, 111)\n",
      "real : Tensor(\"loss/output_1_loss/Cast:0\", shape=(2, 10), dtype=float32) real.shape : (2, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : Tensor(\"seq2seq/decoder_1/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 1\n",
      "output : Tensor(\"seq2seq/decoder_1_1/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_1/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 2\n",
      "output : Tensor(\"seq2seq/decoder_1_2/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_2/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_2/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 3\n",
      "output : Tensor(\"seq2seq/decoder_1_3/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_3/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_3/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 4\n",
      "output : Tensor(\"seq2seq/decoder_1_4/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_4/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_4/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 5\n",
      "output : Tensor(\"seq2seq/decoder_1_5/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_5/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_5/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 6\n",
      "output : Tensor(\"seq2seq/decoder_1_6/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_6/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_6/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 7\n",
      "output : Tensor(\"seq2seq/decoder_1_7/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_7/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_7/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : Tensor(\"seq2seq/decoder_1_8/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_8/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_8/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 9\n",
      "output : Tensor(\"seq2seq/decoder_1_9/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_9/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_9/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_9/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 10\n",
      "real : Tensor(\"IteratorGetNext:2\", shape=(2, 10), dtype=int64) real.shape : (2, 10)\n",
      "pred : Tensor(\"seq2seq/stack:0\", shape=(2, 10, 111), dtype=float32) pred.shape : (2, 10, 111)\n",
      "real : Tensor(\"loss/output_1_loss/Cast:0\", shape=(2, 10), dtype=float32) real.shape : (2, 10)\n",
      "14/16 [=========================>....] - ETA: 2s - loss: 2.2498 - accuracy_function: 0.5961output : Tensor(\"seq2seq/decoder_1/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 1\n",
      "output : Tensor(\"seq2seq/decoder_1_1/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_1/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_1/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 2\n",
      "output : Tensor(\"seq2seq/decoder_1_2/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_2/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_2/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 3\n",
      "output : Tensor(\"seq2seq/decoder_1_3/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_3/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_3/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 4\n",
      "output : Tensor(\"seq2seq/decoder_1_4/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_4/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_4/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output : Tensor(\"seq2seq/decoder_1_5/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_5/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_5/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 6\n",
      "output : Tensor(\"seq2seq/decoder_1_6/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_6/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_6/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 7\n",
      "output : Tensor(\"seq2seq/decoder_1_7/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_7/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_7/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 8\n",
      "output : Tensor(\"seq2seq/decoder_1_8/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_8/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_8/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 9\n",
      "output : Tensor(\"seq2seq/decoder_1_9/gru_3/StatefulPartitionedCall:1\", shape=(2, 1, 1024), dtype=float32) output.shape : (2, 1, 1024)\n",
      "reshape output : Tensor(\"seq2seq/decoder_1_9/Reshape:0\", shape=(2, 1024), dtype=float32) output.shape : (2, 1024)\n",
      "1 predictions : Tensor(\"seq2seq/decoder_1_9/dense_4/BiasAdd:0\", shape=(2, 111), dtype=float32) predictions.shape : (2, 111)\n",
      "2 predictions : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predictions.shape : (2, 111)\n",
      "predict_tokens : [<tf.Tensor 'seq2seq/decoder_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_1/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_2/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_3/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_4/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_5/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_6/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_7/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_8/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>, <tf.Tensor 'seq2seq/decoder_1_9/dense_4/BiasAdd:0' shape=(2, 111) dtype=float32>] predict_tokens.shape : 10\n",
      "real : Tensor(\"IteratorGetNext:2\", shape=(2, 10), dtype=int64) real.shape : (2, 10)\n",
      "pred : Tensor(\"seq2seq/stack:0\", shape=(2, 10, 111), dtype=float32) pred.shape : (2, 10, 111)\n",
      "real : Tensor(\"loss/output_1_loss/Cast:0\", shape=(2, 10), dtype=float32) real.shape : (2, 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_accuracy_function improved from -inf to 0.62083, saving model to ./data_out/seq2seq/weights.01-0.62.h5\n",
      "16/16 [==============================] - 20s 1s/sample - loss: 2.2029 - accuracy_function: 0.5974 - val_loss: 1.8723 - val_accuracy_function: 0.6208\n",
      "Epoch 2/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 2.0953 - accuracy_function: 0.6310\n",
      "Epoch 00002: val_accuracy_function improved from 0.62083 to 0.63329, saving model to ./data_out/seq2seq/weights.02-0.63.h5\n",
      "16/16 [==============================] - 2s 114ms/sample - loss: 2.1822 - accuracy_function: 0.6306 - val_loss: 1.8530 - val_accuracy_function: 0.6333\n",
      "Epoch 3/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 2.0916 - accuracy_function: 0.6409\n",
      "Epoch 00003: val_accuracy_function improved from 0.63329 to 0.63727, saving model to ./data_out/seq2seq/weights.03-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 2.1367 - accuracy_function: 0.6400 - val_loss: 1.7901 - val_accuracy_function: 0.6373\n",
      "Epoch 4/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.9014 - accuracy_function: 0.6418\n",
      "Epoch 00004: val_accuracy_function improved from 0.63727 to 0.63923, saving model to ./data_out/seq2seq/weights.04-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.9815 - accuracy_function: 0.6412 - val_loss: 1.6773 - val_accuracy_function: 0.6392\n",
      "Epoch 5/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.8474 - accuracy_function: 0.6406\n",
      "Epoch 00005: val_accuracy_function improved from 0.63923 to 0.64040, saving model to ./data_out/seq2seq/weights.05-0.64.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.8711 - accuracy_function: 0.6404 - val_loss: 1.6524 - val_accuracy_function: 0.6404\n",
      "Epoch 6/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.8809 - accuracy_function: 0.6388\n",
      "Epoch 00006: val_accuracy_function improved from 0.64040 to 0.64117, saving model to ./data_out/seq2seq/weights.06-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.8429 - accuracy_function: 0.6389 - val_loss: 1.6581 - val_accuracy_function: 0.6412\n",
      "Epoch 7/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.8387 - accuracy_function: 0.6412\n",
      "Epoch 00007: val_accuracy_function improved from 0.64117 to 0.64172, saving model to ./data_out/seq2seq/weights.07-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.7729 - accuracy_function: 0.6411 - val_loss: 1.7158 - val_accuracy_function: 0.6417\n",
      "Epoch 8/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.6710 - accuracy_function: 0.6432\n",
      "Epoch 00008: val_accuracy_function improved from 0.64172 to 0.64214, saving model to ./data_out/seq2seq/weights.08-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.7181 - accuracy_function: 0.6429 - val_loss: 1.7260 - val_accuracy_function: 0.6421\n",
      "Epoch 9/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.6781 - accuracy_function: 0.6418\n",
      "Epoch 00009: val_accuracy_function improved from 0.64214 to 0.64246, saving model to ./data_out/seq2seq/weights.09-0.64.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 1.6776 - accuracy_function: 0.6418 - val_loss: 1.8008 - val_accuracy_function: 0.6425\n",
      "Epoch 10/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.6734 - accuracy_function: 0.6422\n",
      "Epoch 00010: val_accuracy_function improved from 0.64246 to 0.64271, saving model to ./data_out/seq2seq/weights.10-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.6468 - accuracy_function: 0.6421 - val_loss: 1.8630 - val_accuracy_function: 0.6427\n",
      "Epoch 11/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.6433 - accuracy_function: 0.6425\n",
      "Epoch 00011: val_accuracy_function improved from 0.64271 to 0.64292, saving model to ./data_out/seq2seq/weights.11-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.6514 - accuracy_function: 0.6425 - val_loss: 1.9282 - val_accuracy_function: 0.6429\n",
      "Epoch 12/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.6785 - accuracy_function: 0.6424\n",
      "Epoch 00012: val_accuracy_function improved from 0.64292 to 0.64310, saving model to ./data_out/seq2seq/weights.12-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.6275 - accuracy_function: 0.6424 - val_loss: 1.9134 - val_accuracy_function: 0.6431\n",
      "Epoch 13/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.6899 - accuracy_function: 0.6425\n",
      "Epoch 00013: val_accuracy_function improved from 0.64310 to 0.64324, saving model to ./data_out/seq2seq/weights.13-0.64.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.6045 - accuracy_function: 0.6425 - val_loss: 1.9443 - val_accuracy_function: 0.6432\n",
      "Epoch 14/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.6271 - accuracy_function: 0.6435\n",
      "Epoch 00014: val_accuracy_function improved from 0.64324 to 0.64337, saving model to ./data_out/seq2seq/weights.14-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.5947 - accuracy_function: 0.6434 - val_loss: 1.9485 - val_accuracy_function: 0.6434\n",
      "Epoch 15/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.5054 - accuracy_function: 0.6427\n",
      "Epoch 00015: val_accuracy_function improved from 0.64337 to 0.64348, saving model to ./data_out/seq2seq/weights.15-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.5790 - accuracy_function: 0.6427 - val_loss: 2.0409 - val_accuracy_function: 0.6435\n",
      "Epoch 16/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.5693 - accuracy_function: 0.6437\n",
      "Epoch 00016: val_accuracy_function improved from 0.64348 to 0.64357, saving model to ./data_out/seq2seq/weights.16-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.5672 - accuracy_function: 0.6436 - val_loss: 2.0048 - val_accuracy_function: 0.6436\n",
      "Epoch 17/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.5755 - accuracy_function: 0.6429\n",
      "Epoch 00017: val_accuracy_function improved from 0.64357 to 0.64366, saving model to ./data_out/seq2seq/weights.17-0.64.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 1.5449 - accuracy_function: 0.6430 - val_loss: 2.0149 - val_accuracy_function: 0.6437\n",
      "Epoch 18/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.5443 - accuracy_function: 0.6432\n",
      "Epoch 00018: val_accuracy_function improved from 0.64366 to 0.64373, saving model to ./data_out/seq2seq/weights.18-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.5193 - accuracy_function: 0.6432 - val_loss: 2.0817 - val_accuracy_function: 0.6437\n",
      "Epoch 19/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.4789 - accuracy_function: 0.6439\n",
      "Epoch 00019: val_accuracy_function improved from 0.64373 to 0.64380, saving model to ./data_out/seq2seq/weights.19-0.64.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 1.5040 - accuracy_function: 0.6438 - val_loss: 2.1234 - val_accuracy_function: 0.6438\n",
      "Epoch 20/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.4911 - accuracy_function: 0.6436\n",
      "Epoch 00020: val_accuracy_function improved from 0.64380 to 0.64436, saving model to ./data_out/seq2seq/weights.20-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.4656 - accuracy_function: 0.6436 - val_loss: 2.0856 - val_accuracy_function: 0.6444\n",
      "Epoch 21/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.5308 - accuracy_function: 0.6437\n",
      "Epoch 00021: val_accuracy_function improved from 0.64436 to 0.64439, saving model to ./data_out/seq2seq/weights.21-0.64.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 1.4551 - accuracy_function: 0.6438 - val_loss: 2.1997 - val_accuracy_function: 0.6444\n",
      "Epoch 22/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.4171 - accuracy_function: 0.6442\n",
      "Epoch 00022: val_accuracy_function improved from 0.64439 to 0.64442, saving model to ./data_out/seq2seq/weights.22-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.4225 - accuracy_function: 0.6442 - val_loss: 2.2267 - val_accuracy_function: 0.6444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.3741 - accuracy_function: 0.6445\n",
      "Epoch 00023: val_accuracy_function improved from 0.64442 to 0.64488, saving model to ./data_out/seq2seq/weights.23-0.64.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.3954 - accuracy_function: 0.6445 - val_loss: 2.2116 - val_accuracy_function: 0.6449\n",
      "Epoch 24/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.3520 - accuracy_function: 0.6451\n",
      "Epoch 00024: val_accuracy_function improved from 0.64488 to 0.64509, saving model to ./data_out/seq2seq/weights.24-0.65.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.3811 - accuracy_function: 0.6450 - val_loss: 2.2291 - val_accuracy_function: 0.6451\n",
      "Epoch 25/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.3844 - accuracy_function: 0.6451\n",
      "Epoch 00025: val_accuracy_function did not improve from 0.64509\n",
      "16/16 [==============================] - 2s 106ms/sample - loss: 1.3582 - accuracy_function: 0.6450 - val_loss: 2.2768 - val_accuracy_function: 0.6451\n",
      "Epoch 26/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.3580 - accuracy_function: 0.6453\n",
      "Epoch 00026: val_accuracy_function improved from 0.64509 to 0.64547, saving model to ./data_out/seq2seq/weights.26-0.65.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 1.3469 - accuracy_function: 0.6453 - val_loss: 2.3463 - val_accuracy_function: 0.6455\n",
      "Epoch 27/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.3174 - accuracy_function: 0.6453\n",
      "Epoch 00027: val_accuracy_function improved from 0.64547 to 0.64657, saving model to ./data_out/seq2seq/weights.27-0.65.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.3105 - accuracy_function: 0.6454 - val_loss: 2.3557 - val_accuracy_function: 0.6466\n",
      "Epoch 28/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.2844 - accuracy_function: 0.6470\n",
      "Epoch 00028: val_accuracy_function improved from 0.64657 to 0.64705, saving model to ./data_out/seq2seq/weights.28-0.65.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 1.3088 - accuracy_function: 0.6470 - val_loss: 2.2360 - val_accuracy_function: 0.6470\n",
      "Epoch 29/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.3228 - accuracy_function: 0.6470\n",
      "Epoch 00029: val_accuracy_function improved from 0.64705 to 0.64784, saving model to ./data_out/seq2seq/weights.29-0.65.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.2845 - accuracy_function: 0.6470 - val_loss: 2.3525 - val_accuracy_function: 0.6478\n",
      "Epoch 30/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.2944 - accuracy_function: 0.6480\n",
      "Epoch 00030: val_accuracy_function improved from 0.64784 to 0.64808, saving model to ./data_out/seq2seq/weights.30-0.65.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.2568 - accuracy_function: 0.6480 - val_loss: 2.3779 - val_accuracy_function: 0.6481\n",
      "Epoch 31/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.2622 - accuracy_function: 0.6487\n",
      "Epoch 00031: val_accuracy_function improved from 0.64808 to 0.64927, saving model to ./data_out/seq2seq/weights.31-0.65.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 1.2299 - accuracy_function: 0.6488 - val_loss: 2.3919 - val_accuracy_function: 0.6493\n",
      "Epoch 32/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.2204 - accuracy_function: 0.6500\n",
      "Epoch 00032: val_accuracy_function improved from 0.64927 to 0.65039, saving model to ./data_out/seq2seq/weights.32-0.65.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.2143 - accuracy_function: 0.6500 - val_loss: 2.3894 - val_accuracy_function: 0.6504\n",
      "Epoch 33/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.1915 - accuracy_function: 0.6511\n",
      "Epoch 00033: val_accuracy_function improved from 0.65039 to 0.65129, saving model to ./data_out/seq2seq/weights.33-0.65.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.1918 - accuracy_function: 0.6511 - val_loss: 2.4231 - val_accuracy_function: 0.6513\n",
      "Epoch 34/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.1058 - accuracy_function: 0.6525\n",
      "Epoch 00034: val_accuracy_function improved from 0.65129 to 0.65287, saving model to ./data_out/seq2seq/weights.34-0.65.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.1649 - accuracy_function: 0.6525 - val_loss: 2.4065 - val_accuracy_function: 0.6529\n",
      "Epoch 35/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.1677 - accuracy_function: 0.6530\n",
      "Epoch 00035: val_accuracy_function improved from 0.65287 to 0.65436, saving model to ./data_out/seq2seq/weights.35-0.65.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.1596 - accuracy_function: 0.6532 - val_loss: 2.5160 - val_accuracy_function: 0.6544\n",
      "Epoch 36/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.0726 - accuracy_function: 0.6555\n",
      "Epoch 00036: val_accuracy_function improved from 0.65436 to 0.65619, saving model to ./data_out/seq2seq/weights.36-0.66.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 1.1137 - accuracy_function: 0.6556 - val_loss: 2.4124 - val_accuracy_function: 0.6562\n",
      "Epoch 37/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.0558 - accuracy_function: 0.6570\n",
      "Epoch 00037: val_accuracy_function improved from 0.65619 to 0.65792, saving model to ./data_out/seq2seq/weights.37-0.66.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.0854 - accuracy_function: 0.6571 - val_loss: 2.6104 - val_accuracy_function: 0.6579\n",
      "Epoch 38/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.0371 - accuracy_function: 0.6594\n",
      "Epoch 00038: val_accuracy_function improved from 0.65792 to 0.66021, saving model to ./data_out/seq2seq/weights.38-0.66.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.0570 - accuracy_function: 0.6595 - val_loss: 2.4956 - val_accuracy_function: 0.6602\n",
      "Epoch 39/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.9941 - accuracy_function: 0.6615\n",
      "Epoch 00039: val_accuracy_function improved from 0.66021 to 0.66252, saving model to ./data_out/seq2seq/weights.39-0.66.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 1.0261 - accuracy_function: 0.6616 - val_loss: 2.5652 - val_accuracy_function: 0.6625\n",
      "Epoch 40/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 1.0065 - accuracy_function: 0.6633\n",
      "Epoch 00040: val_accuracy_function improved from 0.66252 to 0.66458, saving model to ./data_out/seq2seq/weights.40-0.66.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.0111 - accuracy_function: 0.6635 - val_loss: 2.6055 - val_accuracy_function: 0.6646\n",
      "Epoch 41/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.9706 - accuracy_function: 0.6657\n",
      "Epoch 00041: val_accuracy_function improved from 0.66458 to 0.66654, saving model to ./data_out/seq2seq/weights.41-0.67.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 1.0000 - accuracy_function: 0.6658 - val_loss: 2.6577 - val_accuracy_function: 0.6665\n",
      "Epoch 42/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.9063 - accuracy_function: 0.6678\n",
      "Epoch 00042: val_accuracy_function improved from 0.66654 to 0.66865, saving model to ./data_out/seq2seq/weights.42-0.67.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.9524 - accuracy_function: 0.6679 - val_loss: 2.7649 - val_accuracy_function: 0.6687\n",
      "Epoch 43/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.9293 - accuracy_function: 0.6694\n",
      "Epoch 00043: val_accuracy_function improved from 0.66865 to 0.67043, saving model to ./data_out/seq2seq/weights.43-0.67.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.9183 - accuracy_function: 0.6695 - val_loss: 2.6169 - val_accuracy_function: 0.6704\n",
      "Epoch 44/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.8833 - accuracy_function: 0.6717\n",
      "Epoch 00044: val_accuracy_function improved from 0.67043 to 0.67235, saving model to ./data_out/seq2seq/weights.44-0.67.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.8893 - accuracy_function: 0.6718 - val_loss: 2.7321 - val_accuracy_function: 0.6724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.8764 - accuracy_function: 0.6731\n",
      "Epoch 00045: val_accuracy_function improved from 0.67235 to 0.67419, saving model to ./data_out/seq2seq/weights.45-0.67.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.8658 - accuracy_function: 0.6732 - val_loss: 2.6738 - val_accuracy_function: 0.6742\n",
      "Epoch 46/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.8179 - accuracy_function: 0.6750\n",
      "Epoch 00046: val_accuracy_function improved from 0.67419 to 0.67606, saving model to ./data_out/seq2seq/weights.46-0.68.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.8406 - accuracy_function: 0.6751 - val_loss: 2.7200 - val_accuracy_function: 0.6761\n",
      "Epoch 47/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.8735 - accuracy_function: 0.6768\n",
      "Epoch 00047: val_accuracy_function improved from 0.67606 to 0.67753, saving model to ./data_out/seq2seq/weights.47-0.68.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 0.8321 - accuracy_function: 0.6769 - val_loss: 2.9009 - val_accuracy_function: 0.6775\n",
      "Epoch 48/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.7817 - accuracy_function: 0.6787\n",
      "Epoch 00048: val_accuracy_function improved from 0.67753 to 0.67956, saving model to ./data_out/seq2seq/weights.48-0.68.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.8066 - accuracy_function: 0.6788 - val_loss: 2.5354 - val_accuracy_function: 0.6796\n",
      "Epoch 49/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.8296 - accuracy_function: 0.6803\n",
      "Epoch 00049: val_accuracy_function improved from 0.67956 to 0.68121, saving model to ./data_out/seq2seq/weights.49-0.68.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.8131 - accuracy_function: 0.6804 - val_loss: 2.9027 - val_accuracy_function: 0.6812\n",
      "Epoch 50/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.7735 - accuracy_function: 0.6819\n",
      "Epoch 00050: val_accuracy_function improved from 0.68121 to 0.68258, saving model to ./data_out/seq2seq/weights.50-0.68.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.7736 - accuracy_function: 0.6819 - val_loss: 2.5385 - val_accuracy_function: 0.6826\n",
      "Epoch 51/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.7439 - accuracy_function: 0.6834\n",
      "Epoch 00051: val_accuracy_function improved from 0.68258 to 0.68400, saving model to ./data_out/seq2seq/weights.51-0.68.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.7797 - accuracy_function: 0.6835 - val_loss: 2.8348 - val_accuracy_function: 0.6840\n",
      "Epoch 52/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.7194 - accuracy_function: 0.6851\n",
      "Epoch 00052: val_accuracy_function improved from 0.68400 to 0.68633, saving model to ./data_out/seq2seq/weights.52-0.69.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.7395 - accuracy_function: 0.6853 - val_loss: 2.6914 - val_accuracy_function: 0.6863\n",
      "Epoch 53/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.7334 - accuracy_function: 0.6877\n",
      "Epoch 00053: val_accuracy_function improved from 0.68633 to 0.68886, saving model to ./data_out/seq2seq/weights.53-0.69.h5\n",
      "16/16 [==============================] - 2s 113ms/sample - loss: 0.6954 - accuracy_function: 0.6879 - val_loss: 2.6583 - val_accuracy_function: 0.6889\n",
      "Epoch 54/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.7094 - accuracy_function: 0.6897\n",
      "Epoch 00054: val_accuracy_function improved from 0.68886 to 0.69092, saving model to ./data_out/seq2seq/weights.54-0.69.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.6824 - accuracy_function: 0.6899 - val_loss: 2.7567 - val_accuracy_function: 0.6909\n",
      "Epoch 55/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.6542 - accuracy_function: 0.6925\n",
      "Epoch 00055: val_accuracy_function improved from 0.69092 to 0.69390, saving model to ./data_out/seq2seq/weights.55-0.69.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.6610 - accuracy_function: 0.6927 - val_loss: 2.7230 - val_accuracy_function: 0.6939\n",
      "Epoch 56/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.6563 - accuracy_function: 0.6954\n",
      "Epoch 00056: val_accuracy_function improved from 0.69390 to 0.69634, saving model to ./data_out/seq2seq/weights.56-0.70.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.6435 - accuracy_function: 0.6955 - val_loss: 2.7906 - val_accuracy_function: 0.6963\n",
      "Epoch 57/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.6075 - accuracy_function: 0.6977\n",
      "Epoch 00057: val_accuracy_function improved from 0.69634 to 0.69921, saving model to ./data_out/seq2seq/weights.57-0.70.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.6229 - accuracy_function: 0.6979 - val_loss: 2.7578 - val_accuracy_function: 0.6992\n",
      "Epoch 58/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.6128 - accuracy_function: 0.7008\n",
      "Epoch 00058: val_accuracy_function improved from 0.69921 to 0.70242, saving model to ./data_out/seq2seq/weights.58-0.70.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.5979 - accuracy_function: 0.7010 - val_loss: 2.8486 - val_accuracy_function: 0.7024\n",
      "Epoch 59/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5627 - accuracy_function: 0.7038\n",
      "Epoch 00059: val_accuracy_function improved from 0.70242 to 0.70500, saving model to ./data_out/seq2seq/weights.59-0.71.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 0.5814 - accuracy_function: 0.7040 - val_loss: 2.8191 - val_accuracy_function: 0.7050\n",
      "Epoch 60/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.6086 - accuracy_function: 0.7065\n",
      "Epoch 00060: val_accuracy_function improved from 0.70500 to 0.70734, saving model to ./data_out/seq2seq/weights.60-0.71.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.5778 - accuracy_function: 0.7066 - val_loss: 2.8002 - val_accuracy_function: 0.7073\n",
      "Epoch 61/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5339 - accuracy_function: 0.7089\n",
      "Epoch 00061: val_accuracy_function improved from 0.70734 to 0.71009, saving model to ./data_out/seq2seq/weights.61-0.71.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.5626 - accuracy_function: 0.7090 - val_loss: 2.9222 - val_accuracy_function: 0.7101\n",
      "Epoch 62/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5434 - accuracy_function: 0.7117\n",
      "Epoch 00062: val_accuracy_function improved from 0.71009 to 0.71267, saving model to ./data_out/seq2seq/weights.62-0.71.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.5597 - accuracy_function: 0.7118 - val_loss: 2.8753 - val_accuracy_function: 0.7127\n",
      "Epoch 63/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5782 - accuracy_function: 0.7137\n",
      "Epoch 00063: val_accuracy_function improved from 0.71267 to 0.71446, saving model to ./data_out/seq2seq/weights.63-0.71.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.5665 - accuracy_function: 0.7138 - val_loss: 2.7137 - val_accuracy_function: 0.7145\n",
      "Epoch 64/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.6182 - accuracy_function: 0.7155\n",
      "Epoch 00064: val_accuracy_function improved from 0.71446 to 0.71650, saving model to ./data_out/seq2seq/weights.64-0.72.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 0.5770 - accuracy_function: 0.7156 - val_loss: 2.8907 - val_accuracy_function: 0.7165\n",
      "Epoch 65/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5391 - accuracy_function: 0.7173\n",
      "Epoch 00065: val_accuracy_function improved from 0.71650 to 0.71832, saving model to ./data_out/seq2seq/weights.65-0.72.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.5504 - accuracy_function: 0.7175 - val_loss: 2.8316 - val_accuracy_function: 0.7183\n",
      "Epoch 66/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4760 - accuracy_function: 0.7197\n",
      "Epoch 00066: val_accuracy_function improved from 0.71832 to 0.72062, saving model to ./data_out/seq2seq/weights.66-0.72.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.5153 - accuracy_function: 0.7198 - val_loss: 2.8225 - val_accuracy_function: 0.7206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4809 - accuracy_function: 0.7220\n",
      "Epoch 00067: val_accuracy_function improved from 0.72062 to 0.72308, saving model to ./data_out/seq2seq/weights.67-0.72.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.4956 - accuracy_function: 0.7221 - val_loss: 2.7824 - val_accuracy_function: 0.7231\n",
      "Epoch 68/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4526 - accuracy_function: 0.7244\n",
      "Epoch 00068: val_accuracy_function improved from 0.72308 to 0.72546, saving model to ./data_out/seq2seq/weights.68-0.73.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 0.4828 - accuracy_function: 0.7245 - val_loss: 2.9281 - val_accuracy_function: 0.7255\n",
      "Epoch 69/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4862 - accuracy_function: 0.7267\n",
      "Epoch 00069: val_accuracy_function improved from 0.72546 to 0.72763, saving model to ./data_out/seq2seq/weights.69-0.73.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 0.4759 - accuracy_function: 0.7269 - val_loss: 2.7685 - val_accuracy_function: 0.7276\n",
      "Epoch 70/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4844 - accuracy_function: 0.7288\n",
      "Epoch 00070: val_accuracy_function improved from 0.72763 to 0.72988, saving model to ./data_out/seq2seq/weights.70-0.73.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.4668 - accuracy_function: 0.7290 - val_loss: 2.8497 - val_accuracy_function: 0.7299\n",
      "Epoch 71/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4147 - accuracy_function: 0.7312\n",
      "Epoch 00071: val_accuracy_function improved from 0.72988 to 0.73199, saving model to ./data_out/seq2seq/weights.71-0.73.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 0.4661 - accuracy_function: 0.7313 - val_loss: 2.9609 - val_accuracy_function: 0.7320\n",
      "Epoch 72/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4906 - accuracy_function: 0.7328\n",
      "Epoch 00072: val_accuracy_function improved from 0.73199 to 0.73363, saving model to ./data_out/seq2seq/weights.72-0.73.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.4741 - accuracy_function: 0.7329 - val_loss: 2.7674 - val_accuracy_function: 0.7336\n",
      "Epoch 73/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4858 - accuracy_function: 0.7346\n",
      "Epoch 00073: val_accuracy_function improved from 0.73363 to 0.73537, saving model to ./data_out/seq2seq/weights.73-0.74.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.4831 - accuracy_function: 0.7347 - val_loss: 2.9142 - val_accuracy_function: 0.7354\n",
      "Epoch 74/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5587 - accuracy_function: 0.7360\n",
      "Epoch 00074: val_accuracy_function improved from 0.73537 to 0.73644, saving model to ./data_out/seq2seq/weights.74-0.74.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.5454 - accuracy_function: 0.7360 - val_loss: 2.7389 - val_accuracy_function: 0.7364\n",
      "Epoch 75/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4790 - accuracy_function: 0.7375\n",
      "Epoch 00075: val_accuracy_function improved from 0.73644 to 0.73843, saving model to ./data_out/seq2seq/weights.75-0.74.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.4792 - accuracy_function: 0.7377 - val_loss: 2.9133 - val_accuracy_function: 0.7384\n",
      "Epoch 76/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5235 - accuracy_function: 0.7389\n",
      "Epoch 00076: val_accuracy_function improved from 0.73843 to 0.73910, saving model to ./data_out/seq2seq/weights.76-0.74.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.5702 - accuracy_function: 0.7390 - val_loss: 3.0096 - val_accuracy_function: 0.7391\n",
      "Epoch 77/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5272 - accuracy_function: 0.7399\n",
      "Epoch 00077: val_accuracy_function improved from 0.73910 to 0.74006, saving model to ./data_out/seq2seq/weights.77-0.74.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.5647 - accuracy_function: 0.7399 - val_loss: 2.7704 - val_accuracy_function: 0.7401\n",
      "Epoch 78/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5237 - accuracy_function: 0.7409\n",
      "Epoch 00078: val_accuracy_function improved from 0.74006 to 0.74108, saving model to ./data_out/seq2seq/weights.78-0.74.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 0.5589 - accuracy_function: 0.7410 - val_loss: 3.2172 - val_accuracy_function: 0.7411\n",
      "Epoch 79/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4303 - accuracy_function: 0.7420\n",
      "Epoch 00079: val_accuracy_function improved from 0.74108 to 0.74256, saving model to ./data_out/seq2seq/weights.79-0.74.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.4580 - accuracy_function: 0.7421 - val_loss: 2.9893 - val_accuracy_function: 0.7426\n",
      "Epoch 80/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.4328 - accuracy_function: 0.7434\n",
      "Epoch 00080: val_accuracy_function improved from 0.74256 to 0.74434, saving model to ./data_out/seq2seq/weights.80-0.74.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.4317 - accuracy_function: 0.7436 - val_loss: 2.9235 - val_accuracy_function: 0.7443\n",
      "Epoch 81/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3727 - accuracy_function: 0.7454\n",
      "Epoch 00081: val_accuracy_function improved from 0.74434 to 0.74626, saving model to ./data_out/seq2seq/weights.81-0.75.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.3890 - accuracy_function: 0.7455 - val_loss: 2.7846 - val_accuracy_function: 0.7463\n",
      "Epoch 82/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3702 - accuracy_function: 0.7472\n",
      "Epoch 00082: val_accuracy_function improved from 0.74626 to 0.74790, saving model to ./data_out/seq2seq/weights.82-0.75.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.3694 - accuracy_function: 0.7473 - val_loss: 2.8437 - val_accuracy_function: 0.7479\n",
      "Epoch 83/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3520 - accuracy_function: 0.7488\n",
      "Epoch 00083: val_accuracy_function improved from 0.74790 to 0.74973, saving model to ./data_out/seq2seq/weights.83-0.75.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.3547 - accuracy_function: 0.7489 - val_loss: 2.8802 - val_accuracy_function: 0.7497\n",
      "Epoch 84/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3490 - accuracy_function: 0.7507\n",
      "Epoch 00084: val_accuracy_function improved from 0.74973 to 0.75146, saving model to ./data_out/seq2seq/weights.84-0.75.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 0.3451 - accuracy_function: 0.7508 - val_loss: 2.9381 - val_accuracy_function: 0.7515\n",
      "Epoch 85/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3444 - accuracy_function: 0.7524\n",
      "Epoch 00085: val_accuracy_function improved from 0.75146 to 0.75321, saving model to ./data_out/seq2seq/weights.85-0.75.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.3320 - accuracy_function: 0.7525 - val_loss: 2.9122 - val_accuracy_function: 0.7532\n",
      "Epoch 86/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3164 - accuracy_function: 0.7541\n",
      "Epoch 00086: val_accuracy_function improved from 0.75321 to 0.75486, saving model to ./data_out/seq2seq/weights.86-0.75.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.3135 - accuracy_function: 0.7542 - val_loss: 2.8627 - val_accuracy_function: 0.7549\n",
      "Epoch 87/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3254 - accuracy_function: 0.7558\n",
      "Epoch 00087: val_accuracy_function improved from 0.75486 to 0.75653, saving model to ./data_out/seq2seq/weights.87-0.76.h5\n",
      "16/16 [==============================] - 2s 115ms/sample - loss: 0.3057 - accuracy_function: 0.7559 - val_loss: 2.8877 - val_accuracy_function: 0.7565\n",
      "Epoch 88/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.3135 - accuracy_function: 0.7574\n",
      "Epoch 00088: val_accuracy_function improved from 0.75653 to 0.75821, saving model to ./data_out/seq2seq/weights.88-0.76.h5\n",
      "16/16 [==============================] - 2s 114ms/sample - loss: 0.2967 - accuracy_function: 0.7576 - val_loss: 2.9110 - val_accuracy_function: 0.7582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2652 - accuracy_function: 0.7591\n",
      "Epoch 00089: val_accuracy_function improved from 0.75821 to 0.75987, saving model to ./data_out/seq2seq/weights.89-0.76.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.2860 - accuracy_function: 0.7592 - val_loss: 2.9046 - val_accuracy_function: 0.7599\n",
      "Epoch 90/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2692 - accuracy_function: 0.7607\n",
      "Epoch 00090: val_accuracy_function improved from 0.75987 to 0.76142, saving model to ./data_out/seq2seq/weights.90-0.76.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.2756 - accuracy_function: 0.7608 - val_loss: 2.9047 - val_accuracy_function: 0.7614\n",
      "Epoch 91/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2800 - accuracy_function: 0.7624\n",
      "Epoch 00091: val_accuracy_function improved from 0.76142 to 0.76306, saving model to ./data_out/seq2seq/weights.91-0.76.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.2749 - accuracy_function: 0.7625 - val_loss: 2.9542 - val_accuracy_function: 0.7631\n",
      "Epoch 92/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2568 - accuracy_function: 0.7640\n",
      "Epoch 00092: val_accuracy_function improved from 0.76306 to 0.76465, saving model to ./data_out/seq2seq/weights.92-0.76.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.2630 - accuracy_function: 0.7641 - val_loss: 2.9552 - val_accuracy_function: 0.7647\n",
      "Epoch 93/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2639 - accuracy_function: 0.7655\n",
      "Epoch 00093: val_accuracy_function improved from 0.76465 to 0.76622, saving model to ./data_out/seq2seq/weights.93-0.77.h5\n",
      "16/16 [==============================] - 2s 110ms/sample - loss: 0.2547 - accuracy_function: 0.7656 - val_loss: 2.9186 - val_accuracy_function: 0.7662\n",
      "Epoch 94/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2412 - accuracy_function: 0.7671\n",
      "Epoch 00094: val_accuracy_function improved from 0.76622 to 0.76775, saving model to ./data_out/seq2seq/weights.94-0.77.h5\n",
      "16/16 [==============================] - 2s 109ms/sample - loss: 0.2537 - accuracy_function: 0.7672 - val_loss: 2.9568 - val_accuracy_function: 0.7677\n",
      "Epoch 95/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2175 - accuracy_function: 0.7686\n",
      "Epoch 00095: val_accuracy_function improved from 0.76775 to 0.76925, saving model to ./data_out/seq2seq/weights.95-0.77.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.2447 - accuracy_function: 0.7687 - val_loss: 2.9582 - val_accuracy_function: 0.7692\n",
      "Epoch 96/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2388 - accuracy_function: 0.7701\n",
      "Epoch 00096: val_accuracy_function improved from 0.76925 to 0.77066, saving model to ./data_out/seq2seq/weights.96-0.77.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.2383 - accuracy_function: 0.7702 - val_loss: 2.9678 - val_accuracy_function: 0.7707\n",
      "Epoch 97/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2419 - accuracy_function: 0.7715\n",
      "Epoch 00097: val_accuracy_function improved from 0.77066 to 0.77215, saving model to ./data_out/seq2seq/weights.97-0.77.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.2301 - accuracy_function: 0.7716 - val_loss: 2.9495 - val_accuracy_function: 0.7722\n",
      "Epoch 98/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2172 - accuracy_function: 0.7730\n",
      "Epoch 00098: val_accuracy_function improved from 0.77215 to 0.77361, saving model to ./data_out/seq2seq/weights.98-0.77.h5\n",
      "16/16 [==============================] - 2s 112ms/sample - loss: 0.2325 - accuracy_function: 0.7731 - val_loss: 3.0061 - val_accuracy_function: 0.7736\n",
      "Epoch 99/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2073 - accuracy_function: 0.7744\n",
      "Epoch 00099: val_accuracy_function improved from 0.77361 to 0.77494, saving model to ./data_out/seq2seq/weights.99-0.77.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.2279 - accuracy_function: 0.7744 - val_loss: 2.9668 - val_accuracy_function: 0.7749\n",
      "Epoch 100/100\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.2283 - accuracy_function: 0.7757\n",
      "Epoch 00100: val_accuracy_function improved from 0.77494 to 0.77634, saving model to ./data_out/seq2seq/weights.100-0.78.h5\n",
      "16/16 [==============================] - 2s 111ms/sample - loss: 0.2202 - accuracy_function: 0.7758 - val_loss: 2.9794 - val_accuracy_function: 0.7763\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy_function', patience=10)\n",
    "\n",
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCH, verbose=1,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[cp_callback])\n",
    "                    #validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])\n",
    "                    #validation_split=VALID_SPLIT, callbacks=[cp_callback]) epochs=EPOCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "!apt-get update -qq #나눔고딕 인스톨\n",
    "!apt-get install fonts-nanum* -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanumGothic Eco\n"
     ]
    }
   ],
   "source": [
    "path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'  \n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name() \n",
    "print(font_name)\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((MAX_SEQUENCE, MAX_SEQUENCE))\n",
    "    \n",
    "    index_inputs, input_seq_len = enc_processing([sentence], char2idx)    \n",
    "    \n",
    "    inputs = index_inputs\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([char2idx[STD]], 0)\n",
    "\n",
    "    for t in range(MAX_SEQUENCE):    \n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        result += idx2char[predicted_id] + ' '\n",
    "\n",
    "        if idx2char[predicted_id] == '<END>':\n",
    "            return result, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(attention, sentence, result):\n",
    "    #result = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence)) # 텍스트 처리\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 best model 이름\n",
    "SAVE_FILE_LW = 'weights.100-0.78.h5'\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_LW))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['남자친구 승진 선물로 뭐가 좋을까?']\n",
      "output : [[[-0.00667446 -0.00555728  0.00307565 ...  0.00600052  0.00358629\n",
      "    0.00229351]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-0.00667446 -0.00555728  0.00307565 ...  0.00600052  0.00358629\n",
      "   0.00229351]] output.shape : (1, 1024)\n",
      "output : [[[-4.7686164e-05 -1.0308087e-03  1.8760696e-03 ...  9.4362773e-04\n",
      "    2.8640220e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7686164e-05 -1.0308087e-03  1.8760696e-03 ...  9.4362773e-04\n",
      "   2.8640220e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "output : [[[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "    2.8640225e-03  9.4531290e-04]]] output.shape : (1, 1, 1024)\n",
      "reshape output : [[-4.7687554e-05 -1.0308096e-03  1.8760687e-03 ...  9.4362680e-04\n",
      "   2.8640225e-03  9.4531290e-04]] output.shape : (1, 1024)\n",
      "Input: 남자친구 승진 선물로 뭐가 좋을까?\n",
      "Predicted translation: 망함 망함 망함 망함 망함 망함 망함 망함 망함 망함 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "query = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "\n",
    "result, attention = evaluate(query)\n",
    "translate(attention, query, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
