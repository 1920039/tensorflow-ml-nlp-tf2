{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "PAD = \"<PAD>\"\n",
    "STD = \"<SOS>\"\n",
    "END = \"<END>\"\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "MARKER = [PAD, STD, END, UNK]\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "PATH = 'data_in/ChatBotData.csv_short'\n",
    "VOCAB_PATH = 'data_in/vocabulary.txt'\n",
    "\n",
    "MAX_SEQUENCE = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # 판다스를 통해서 데이터를 불러온다.\n",
    "    data_df = pd.read_csv(path, header=0)\n",
    "    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = load_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징과 어휘사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tokenizer(data):\n",
    "    # 토크나이징 해서 담을 배열 생성\n",
    "    words = []\n",
    "    for sentence in data:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 위 필터와 같은 값들을 정규화 표현식을\n",
    "        # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "        for word in sentence.split():\n",
    "            words.append(word)\n",
    "    # 토그나이징과 정규표현식을 통해 만들어진\n",
    "    # 값들을 넘겨 준다.\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def load_vocabulary(path, vocab_path):\n",
    "    # 사전을 담을 배열 준비한다.\n",
    "    vocabulary_list = []\n",
    "    # 사전을 구성한 후 파일로 저장 진행한다.\n",
    "    # 그 파일의 존재 유무를 확인한다.\n",
    "    if not os.path.exists(vocab_path):\n",
    "        # 이미 생성된 사전 파일이 존재하지 않으므로\n",
    "        # 데이터를 가지고 만들어야 한다.\n",
    "        # 그래서 데이터가 존재 하면 사전을 만들기 위해서\n",
    "        # 데이터 파일의 존재 유무를 확인한다.\n",
    "        if (os.path.exists(path)):\n",
    "            # 데이터가 존재하니 판단스를 통해서\n",
    "            # 데이터를 불러오자\n",
    "            data_df = pd.read_csv(path, encoding='utf-8')\n",
    "            # 판다스의 데이터 프레임을 통해서\n",
    "            # 질문과 답에 대한 열을 가져 온다.\n",
    "            question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "#             if DEFINES.tokenize_as_morph:  # 형태소에 따른 토크나이져 처리\n",
    "#                 question = prepro_like_morphlized(question)\n",
    "#                 answer = prepro_like_morphlized(answer)\n",
    "            data = []\n",
    "            # 질문과 답변을 extend을\n",
    "            # 통해서 구조가 없는 배열로 만든다.\n",
    "            data.extend(question)\n",
    "            data.extend(answer)\n",
    "            # 토큰나이져 처리 하는 부분이다.\n",
    "            words = data_tokenizer(data)\n",
    "            # 공통적인 단어에 대해서는 모두\n",
    "            # 필요 없으므로 한개로 만들어 주기 위해서\n",
    "            # set해주고 이것들을 리스트로 만들어 준다.\n",
    "            words = list(set(words))\n",
    "            # 데이터 없는 내용중에 MARKER를 사전에\n",
    "            # 추가 하기 위해서 아래와 같이 처리 한다.\n",
    "            # 아래는 MARKER 값이며 리스트의 첫번째 부터\n",
    "            # 순서대로 넣기 위해서 인덱스 0에 추가한다.\n",
    "            # PAD = \"<PADDING>\"\n",
    "            # STD = \"<START>\"\n",
    "            # END = \"<END>\"\n",
    "            # UNK = \"<UNKNWON>\"\n",
    "            words[:0] = MARKER\n",
    "        # 사전을 리스트로 만들었으니 이 내용을\n",
    "        # 사전 파일을 만들어 넣는다.\n",
    "        with open(vocab_path, 'w', encoding='utf-8') as vocabulary_file:\n",
    "            for word in words:\n",
    "                vocabulary_file.write(word + '\\n')\n",
    "\n",
    "    # 사전 파일이 존재하면 여기에서\n",
    "    # 그 파일을 불러서 배열에 넣어 준다.\n",
    "    with open(vocab_path, 'r', encoding='utf-8') as vocabulary_file:\n",
    "        for line in vocabulary_file:\n",
    "            vocabulary_list.append(line.strip())\n",
    "\n",
    "    # 배열에 내용을 키와 값이 있는\n",
    "    # 딕셔너리 구조로 만든다.\n",
    "    char2idx, idx2char = make_vocabulary(vocabulary_list)\n",
    "    # 두가지 형태의 키와 값이 있는 형태를 리턴한다.\n",
    "    # (예) 단어: 인덱스 , 인덱스: 단어)\n",
    "    return char2idx, idx2char, len(char2idx)\n",
    "\n",
    "\n",
    "def make_vocabulary(vocabulary_list):\n",
    "    # 리스트를 키가 단어이고 값이 인덱스인\n",
    "    # 딕셔너리를 만든다.\n",
    "    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n",
    "    # 리스트를 키가 인덱스이고 값이 단어인\n",
    "    # 딕셔너리를 만든다.\n",
    "    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n",
    "    # 두개의 딕셔너리를 넘겨 준다.\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx, idx2char, vocab_size = load_vocabulary(PATH, VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다.)\n",
    "    sequences_input_index = []\n",
    "    # 하나의 인코딩 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다.)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "\n",
    "    print(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 인코딩 할때\n",
    "        # 가지고 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 문장을 스페이스 단위로\n",
    "        # 자르고 있다.\n",
    "        for word in sequence.split():\n",
    "            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고\n",
    "            # 그 값을 가져와 sequence_index에 추가한다.\n",
    "            if dictionary.get(word) is not None:\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "            # 잘려진 단어가 딕셔너리에 존재 하지 않는\n",
    "            # 경우 이므로 UNK(2)를 넣어 준다.\n",
    "            else:\n",
    "                sequence_index.extend([dictionary[UNK]])\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_input_index에 넣어 준다.\n",
    "        sequences_input_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과\n",
    "    # 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_input_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_output_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_output_index = []\n",
    "    # 하나의 디코딩 입력 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 디코딩 할때 가지고\n",
    "        # 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 디코딩 입력의 처음에는 START가 와야 하므로\n",
    "        # 그 값을 넣어 주고 시작한다.\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서 딕셔너리의\n",
    "        # 값인 인덱스를 넣어 준다.\n",
    "        sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_output_index 넣어 준다.\n",
    "        sequences_output_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_output_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_target_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_target_index = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서\n",
    "        # 딕셔너리의 값인 인덱스를 넣어 준다.\n",
    "        # 디코딩 출력의 마지막에 END를 넣어 준다.\n",
    "        sequence_index = [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        # 그리고 END 토큰을 넣어 준다\n",
    "        if len(sequence_index) >= MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE - 1] + [dictionary[END]]\n",
    "        else:\n",
    "            sequence_index += [dictionary[END]]\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_target_index에 넣어 준다.\n",
    "        sequences_target_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['가끔 궁금해', '가끔 뭐하는지 궁금해', '가끔은 혼자인게 좋다', '가난한 자의 설움', '가만 있어도 땀난다', '가상화폐 쫄딱 망함', '가스불 켜고 나갔어', '가스불 켜놓고 나온거 같아', '가스비 너무 많이 나왔다.', '가스비 비싼데 감기 걸리겠어', '남자친구 교회 데려가고 싶어', '남자친구 또 운동 갔어', '남자친구 생일인데 뭘 줄까', '남자친구 승진 선물로 뭐가 좋을까?', '남자친구 오늘 따라 훈훈해 보인다', '남자친구 오늘 좀 질린다.', '남자친구가 나 안 믿어줘', '남자친구가 너무 바빠', '남자친구가 너무 운동만 해', '남자친구가 너무 잘생겼어']\n"
     ]
    }
   ],
   "source": [
    "index_inputs, input_seq_len = enc_processing(inputs, char2idx)\n",
    "index_outputs, output_seq_len = dec_output_processing(outputs, char2idx)\n",
    "index_targets = dec_target_processing(outputs, char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 33,  56,  10,  72,   2,   0,   0,   0,   0,   0],\n",
       "       [ 33,  56,  10,  72,   2,   0,   0,   0,   0,   0],\n",
       "       [ 47,  74,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 93,  42,   5,  72,   2,   0,   0,   0,   0,   0],\n",
       "       [ 63,  36,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 32,  46,  25,  34,   2,   0,   0,   0,   0,   0],\n",
       "       [ 27,  13,  62,  84,  26,   2,   0,   0,   0,   0],\n",
       "       [ 27,  13,  62,  84,  26,   2,   0,   0,   0,   0],\n",
       "       [ 94,  24,  39,  78,   2,   0,   0,   0,   0,   0],\n",
       "       [ 57,  95,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [ 77, 103,  30,  65,   2,   0,   0,   0,   0,   0],\n",
       "       [  6,  97,  70,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [105,  96,  14,  51,   2,   0,   0,   0,   0,   0],\n",
       "       [105,  61,  55,  71,  14,   7,   2,   0,   0,   0],\n",
       "       [ 37,  49,  58,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [ 15,  64,  12,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [ 23,  67,  34,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [ 52,  80, 106,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [  6,  97,  70,   2,   0,   0,   0,   0,   0,   0],\n",
       "       [ 37,  49,  58,   2,   0,   0,   0,   0,   0,   0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 20 20 20 20\n"
     ]
    }
   ],
   "source": [
    "# Show length\n",
    "print(len(index_inputs), len(input_seq_len), len(index_outputs), len(output_seq_len), len(index_targets))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a tf.data dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1\n",
    "units = 1024\n",
    "embedding_dim = 256\n",
    "steps_per_epoch = len(index_inputs)//BATCH_SIZE\n",
    "BUFFER_SIZE = len(index_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    #def __init__(self, **kargs):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim          \n",
    "#         self.batch_sz = kargs['batch_size']\n",
    "#         self.enc_units = kargs['enc_units']\n",
    "#         self.vocab_size = kargs['vocab_size'] \n",
    "#         self.embedding_dim = kargs['embedding_dim'] \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, query, values):\n",
    "        hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        score = self.V(tf.nn.tanh(\n",
    "            self.W1(values) + self.W2(hidden_with_time_axis)))\n",
    "\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.vocab_size = vocab_size \n",
    "        self.embedding_dim = embedding_dim  \n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
    "                                       return_sequences=True,\n",
    "                                       return_state=True,\n",
    "                                       recurrent_initializer='glorot_uniform')\n",
    "        self.fc = tf.keras.layers.Dense(self.vocab_size)\n",
    "\n",
    "        # used for attention\n",
    "        self.attention = BahdanauAttention(self.dec_units)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
    "\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        output, state = self.gru(x)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "            \n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(vocab_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2seq(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, dec_units, batch_sz):    \n",
    "        super(Seq2seq, self).__init__()\n",
    "        self.encoder = Encoder(vocab_size, embedding_dim, enc_units, batch_sz) #vocab_size, embedding_dim, enc_units, batch_sz\n",
    "        self.decoder = Decoder(vocab_size, embedding_dim, dec_units, batch_sz) #vocab_size, embedding_dim, dec_units, batch_sz\n",
    "\n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "\n",
    "        enc_hidden = self.encoder.initialize_hidden_state()\n",
    "        enc_output, enc_hidden = self.encoder(inp, enc_hidden)\n",
    "\n",
    "        dec_hidden = enc_hidden\n",
    "\n",
    "        dec_input = tf.expand_dims([STD_INDEX] * BATCH_SIZE, 1)\n",
    "        predict_tokens = list()\n",
    "        for t in range(0, tar.shape[1]):\n",
    "            predictions, dec_hidden, _ = self.decoder(dec_input, dec_hidden, enc_output)\n",
    "            predict_tokens.append(tf.dtypes.cast(predictions, tf.float32))\n",
    "            # using teacher forcing\n",
    "            dec_input = tf.dtypes.cast(tf.expand_dims(tar[:, t], 1), tf.float32)      \n",
    "        return tf.stack(predict_tokens, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kargs = {\n",
    "#          'enc_units' : units,\n",
    "#          'dec_units' : units,\n",
    "#          'embedding_dim': embedding_dim,\n",
    "#          'vocab_size': vocab_size,\n",
    "#          'batch_size' : BATCH_SIZE\n",
    "#         }\n",
    "\n",
    "model = Seq2seq(vocab_size, embedding_dim, units, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=loss_function,\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=[accuracy_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 2 samples\n",
      "Epoch 1/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 2.0959 - accuracy_function: 0.6536WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 21s 1s/sample - loss: 2.1617 - accuracy_function: 0.6522 - val_loss: 1.8517 - val_accuracy_function: 0.6333\n",
      "Epoch 2/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 2.0425 - accuracy_function: 0.6458WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 149ms/sample - loss: 2.0465 - accuracy_function: 0.6453 - val_loss: 1.6090 - val_accuracy_function: 0.6392\n",
      "Epoch 3/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.8659 - accuracy_function: 0.6398WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 150ms/sample - loss: 1.8505 - accuracy_function: 0.6398 - val_loss: 1.5756 - val_accuracy_function: 0.6412\n",
      "Epoch 4/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.7635 - accuracy_function: 0.6406WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 152ms/sample - loss: 1.7725 - accuracy_function: 0.6406 - val_loss: 1.5663 - val_accuracy_function: 0.6421\n",
      "Epoch 5/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.7155 - accuracy_function: 0.6436WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 153ms/sample - loss: 1.7097 - accuracy_function: 0.6435 - val_loss: 1.5665 - val_accuracy_function: 0.6427\n",
      "Epoch 6/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.7057 - accuracy_function: 0.6444WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 152ms/sample - loss: 1.6727 - accuracy_function: 0.6443 - val_loss: 1.5447 - val_accuracy_function: 0.6431\n",
      "Epoch 7/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.6552 - accuracy_function: 0.6415WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 148ms/sample - loss: 1.6475 - accuracy_function: 0.6416 - val_loss: 1.5046 - val_accuracy_function: 0.6434\n",
      "Epoch 8/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.6372 - accuracy_function: 0.6431WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 148ms/sample - loss: 1.6286 - accuracy_function: 0.6431 - val_loss: 1.4912 - val_accuracy_function: 0.6436\n",
      "Epoch 9/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.5946 - accuracy_function: 0.6442WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 147ms/sample - loss: 1.6172 - accuracy_function: 0.6441 - val_loss: 1.4804 - val_accuracy_function: 0.6437\n",
      "Epoch 10/10\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 1.5826 - accuracy_function: 0.6438WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 3s 149ms/sample - loss: 1.5948 - accuracy_function: 0.6438 - val_loss: 1.4779 - val_accuracy_function: 0.6439\n"
     ]
    }
   ],
   "source": [
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=1)\n",
    "\n",
    "history = model.fit([index_inputs, index_targets], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=10,\n",
    "                    validation_split=0.1, callbacks=[earlystop_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Could not open lock file /var/lib/apt/lists/lock - open (13: Permission denied)\n",
      "E: Unable to lock directory /var/lib/apt/lists/\n",
      "W: Problem unlinking the file /var/cache/apt/pkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "W: Problem unlinking the file /var/cache/apt/srcpkgcache.bin - RemoveCaches (13: Permission denied)\n",
      "E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\n",
      "E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\n"
     ]
    }
   ],
   "source": [
    "!apt-get update -qq #나눔고딕 인스톨\n",
    "!apt-get install fonts-nanum* -qq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NanumGothic Eco\n"
     ]
    }
   ],
   "source": [
    "path = '/usr/share/fonts/truetype/nanum/NanumGothicEco.ttf'  \n",
    "font_name = fm.FontProperties(fname=path, size=10).get_name() \n",
    "print(font_name)\n",
    "plt.rc('font', family=font_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    attention_plot = np.zeros((MAX_SEQUENCE, MAX_SEQUENCE))\n",
    "    \n",
    "    index_inputs, input_seq_len = enc_processing([sentence], char2idx)    \n",
    "    \n",
    "    inputs = index_inputs\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([char2idx[STD]], 0)\n",
    "\n",
    "    for t in range(MAX_SEQUENCE):    \n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
    "                                                         dec_hidden,\n",
    "                                                         enc_out)\n",
    "\n",
    "        # storing the attention weights to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "        \n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "        \n",
    "        result += idx2char[predicted_id] + ' '\n",
    "\n",
    "        if idx2char[predicted_id] == '<END>':\n",
    "            return result, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(attention, sentence, result):\n",
    "    #result = evaluate(sentence)\n",
    "    print('Input: %s' % (sentence)) # 텍스트 처리\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    attention_plot = attention[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore the latest checkpoint and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['남자친구 승진 선물로 뭐가 좋을까?']\n",
      "Input: 남자친구 승진 선물로 뭐가 좋을까?\n",
      "Predicted translation: 거예요 빨리 사세요 나온거 따라 해보세요 <END> \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "query = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "\n",
    "result, attention = evaluate(query)\n",
    "translate(attention, query, result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
