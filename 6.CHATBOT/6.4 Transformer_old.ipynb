{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 데이터 경로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = './data_in/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 래"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 만들기에 필요한 값 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "PAD = \"<PAD>\"\n",
    "STD = \"<SOS>\"\n",
    "END = \"<END>\"\n",
    "UNK = \"<UNK>\"\n",
    "\n",
    "PAD_INDEX = 0\n",
    "STD_INDEX = 1\n",
    "END_INDEX = 2\n",
    "UNK_INDEX = 3\n",
    "\n",
    "MARKER = [PAD, STD, END, UNK]\n",
    "CHANGE_FILTER = re.compile(FILTERS)\n",
    "\n",
    "PATH = 'data_in/ChatBotData.csv_short'\n",
    "VOCAB_PATH = 'data_in/vocabulary.txt'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "MAX_SEQUENCE = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    # 판다스를 통해서 데이터를 불러온다.\n",
    "    data_df = pd.read_csv(path, header=0)\n",
    "    # 질문과 답변 열을 가져와 question과 answer에 넣는다.\n",
    "    question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "\n",
    "    return question, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, outputs = load_data(PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 토크나이징과 어휘사전 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_tokenizer(data):\n",
    "    # 토크나이징 해서 담을 배열 생성\n",
    "    words = []\n",
    "    for sentence in data:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 위 필터와 같은 값들을 정규화 표현식을\n",
    "        # 통해서 모두 \"\" 으로 변환 해주는 부분이다.\n",
    "        sentence = re.sub(CHANGE_FILTER, \"\", sentence)\n",
    "        for word in sentence.split():\n",
    "            words.append(word)\n",
    "    # 토그나이징과 정규표현식을 통해 만들어진\n",
    "    # 값들을 넘겨 준다.\n",
    "    return [word for word in words if word]\n",
    "\n",
    "def load_vocabulary(path, vocab_path):\n",
    "    # 사전을 담을 배열 준비한다.\n",
    "    vocabulary_list = []\n",
    "    # 사전을 구성한 후 파일로 저장 진행한다.\n",
    "    # 그 파일의 존재 유무를 확인한다.\n",
    "    if not os.path.exists(vocab_path):\n",
    "        # 이미 생성된 사전 파일이 존재하지 않으므로\n",
    "        # 데이터를 가지고 만들어야 한다.\n",
    "        # 그래서 데이터가 존재 하면 사전을 만들기 위해서\n",
    "        # 데이터 파일의 존재 유무를 확인한다.\n",
    "        if (os.path.exists(path)):\n",
    "            # 데이터가 존재하니 판단스를 통해서\n",
    "            # 데이터를 불러오자\n",
    "            data_df = pd.read_csv(path, encoding='utf-8')\n",
    "            # 판다스의 데이터 프레임을 통해서\n",
    "            # 질문과 답에 대한 열을 가져 온다.\n",
    "            question, answer = list(data_df['Q']), list(data_df['A'])\n",
    "#             if DEFINES.tokenize_as_morph:  # 형태소에 따른 토크나이져 처리\n",
    "#                 question = prepro_like_morphlized(question)\n",
    "#                 answer = prepro_like_morphlized(answer)\n",
    "            data = []\n",
    "            # 질문과 답변을 extend을\n",
    "            # 통해서 구조가 없는 배열로 만든다.\n",
    "            data.extend(question)\n",
    "            data.extend(answer)\n",
    "            # 토큰나이져 처리 하는 부분이다.\n",
    "            words = data_tokenizer(data)\n",
    "            # 공통적인 단어에 대해서는 모두\n",
    "            # 필요 없으므로 한개로 만들어 주기 위해서\n",
    "            # set해주고 이것들을 리스트로 만들어 준다.\n",
    "            words = list(set(words))\n",
    "            # 데이터 없는 내용중에 MARKER를 사전에\n",
    "            # 추가 하기 위해서 아래와 같이 처리 한다.\n",
    "            # 아래는 MARKER 값이며 리스트의 첫번째 부터\n",
    "            # 순서대로 넣기 위해서 인덱스 0에 추가한다.\n",
    "            # PAD = \"<PADDING>\"\n",
    "            # STD = \"<START>\"\n",
    "            # END = \"<END>\"\n",
    "            # UNK = \"<UNKNWON>\"\n",
    "            words[:0] = MARKER\n",
    "        # 사전을 리스트로 만들었으니 이 내용을\n",
    "        # 사전 파일을 만들어 넣는다.\n",
    "        with open(vocab_path, 'w', encoding='utf-8') as vocabulary_file:\n",
    "            for word in words:\n",
    "                vocabulary_file.write(word + '\\n')\n",
    "\n",
    "    # 사전 파일이 존재하면 여기에서\n",
    "    # 그 파일을 불러서 배열에 넣어 준다.\n",
    "    with open(vocab_path, 'r', encoding='utf-8') as vocabulary_file:\n",
    "        for line in vocabulary_file:\n",
    "            vocabulary_list.append(line.strip())\n",
    "\n",
    "    # 배열에 내용을 키와 값이 있는\n",
    "    # 딕셔너리 구조로 만든다.\n",
    "    char2idx, idx2char = make_vocabulary(vocabulary_list)\n",
    "    # 두가지 형태의 키와 값이 있는 형태를 리턴한다.\n",
    "    # (예) 단어: 인덱스 , 인덱스: 단어)\n",
    "    return char2idx, idx2char, len(char2idx)\n",
    "\n",
    "\n",
    "def make_vocabulary(vocabulary_list):\n",
    "    # 리스트를 키가 단어이고 값이 인덱스인\n",
    "    # 딕셔너리를 만든다.\n",
    "    char2idx = {char: idx for idx, char in enumerate(vocabulary_list)}\n",
    "    # 리스트를 키가 인덱스이고 값이 단어인\n",
    "    # 딕셔너리를 만든다.\n",
    "    idx2char = {idx: char for idx, char in enumerate(vocabulary_list)}\n",
    "    # 두개의 딕셔너리를 넘겨 준다.\n",
    "    return char2idx, idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx, idx2char, vocab_size = load_vocabulary(PATH, VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다.)\n",
    "    sequences_input_index = []\n",
    "    # 하나의 인코딩 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다.)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 인코딩 할때\n",
    "        # 가지고 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 문장을 스페이스 단위로\n",
    "        # 자르고 있다.\n",
    "        for word in sequence.split():\n",
    "            # 잘려진 단어들이 딕셔너리에 존재 하는지 보고\n",
    "            # 그 값을 가져와 sequence_index에 추가한다.\n",
    "            if dictionary.get(word) is not None:\n",
    "                sequence_index.extend([dictionary[word]])\n",
    "            # 잘려진 단어가 딕셔너리에 존재 하지 않는\n",
    "            # 경우 이므로 UNK(2)를 넣어 준다.\n",
    "            else:\n",
    "                sequence_index.extend([dictionary[UNK]])\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_input_index에 넣어 준다.\n",
    "        sequences_input_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과\n",
    "    # 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_input_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_output_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_output_index = []\n",
    "    # 하나의 디코딩 입력 되는 문장의\n",
    "    # 길이를 가지고 있다.(누적된다)\n",
    "    sequences_length = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 하나의 문장을 디코딩 할때 가지고\n",
    "        # 있기 위한 배열이다.\n",
    "        sequence_index = []\n",
    "        # 디코딩 입력의 처음에는 START가 와야 하므로\n",
    "        # 그 값을 넣어 주고 시작한다.\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서 딕셔너리의\n",
    "        # 값인 인덱스를 넣어 준다.\n",
    "        sequence_index = [dictionary[STD]] + [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        if len(sequence_index) > MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE]\n",
    "        # 하나의 문장에 길이를 넣어주고 있다.\n",
    "        sequences_length.append(len(sequence_index))\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_output_index 넣어 준다.\n",
    "        sequences_output_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한\n",
    "    # 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_output_index), sequences_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dec_target_processing(value, dictionary):\n",
    "    # 인덱스 값들을 가지고 있는\n",
    "    # 배열이다.(누적된다)\n",
    "    sequences_target_index = []\n",
    "    # 형태소 토크나이징 사용 유무\n",
    "#     if DEFINES.tokenize_as_morph:\n",
    "#         value = prepro_like_morphlized(value)\n",
    "    # 한줄씩 불어온다.\n",
    "    for sequence in value:\n",
    "        # FILTERS = \"([~.,!?\\\"':;)(])\"\n",
    "        # 정규화를 사용하여 필터에 들어 있는\n",
    "        # 값들을 \"\" 으로 치환 한다.\n",
    "        sequence = re.sub(CHANGE_FILTER, \"\", sequence)\n",
    "        # 문장에서 스페이스 단위별로 단어를 가져와서\n",
    "        # 딕셔너리의 값인 인덱스를 넣어 준다.\n",
    "        # 디코딩 출력의 마지막에 END를 넣어 준다.\n",
    "        sequence_index = [dictionary[word] for word in sequence.split()]\n",
    "        # 문장 제한 길이보다 길어질 경우 뒤에 토큰을 자르고 있다.\n",
    "        # 그리고 END 토큰을 넣어 준다\n",
    "        if len(sequence_index) >= MAX_SEQUENCE:\n",
    "            sequence_index = sequence_index[:MAX_SEQUENCE - 1] + [dictionary[END]]\n",
    "        else:\n",
    "            sequence_index += [dictionary[END]]\n",
    "        # max_sequence_length보다 문장 길이가\n",
    "        # 작다면 빈 부분에 PAD(0)를 넣어준다.\n",
    "        sequence_index += (MAX_SEQUENCE - len(sequence_index)) * [dictionary[PAD]]\n",
    "        # 인덱스화 되어 있는 값을\n",
    "        # sequences_target_index에 넣어 준다.\n",
    "        sequences_target_index.append(sequence_index)\n",
    "    # 인덱스화된 일반 배열을 넘파이 배열로 변경한다.\n",
    "    # 이유는 텐서플로우 dataset에 넣어 주기 위한 사전 작업이다.\n",
    "    # 넘파이 배열에 인덱스화된 배열과 그 길이를 넘겨준다.\n",
    "    return np.asarray(sequences_target_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_inputs, input_seq_len = enc_processing(inputs, char2idx)\n",
    "index_outputs, output_seq_len = dec_output_processing(outputs, char2idx)\n",
    "index_targets = dec_target_processing(outputs, char2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 마스크 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * i//2) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model']\n",
    "\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(kargs['d_model'])  # (batch_size, seq_len, d_model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(**kargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, mask)\n",
    "\n",
    "        return x  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(**kargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.decoder = Decoder(**kargs)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "\n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, _ = self.decoder(\n",
    "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output\n",
    "    \n",
    "    def inference(self, x):\n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX], 0)\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)        \n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, -1).numpy()\n",
    "            pred_token = outputs[0][-1]\n",
    "            if pred_token == self.end_token_idx:\n",
    "                break\n",
    "            predict_tokens.append(pred_token)\n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "            \n",
    "        return predict_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 실행 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kargs = {'num_layers': 2,\n",
    "         'd_model': 512,\n",
    "         'num_heads': 8,\n",
    "         'dff': 2048,\n",
    "         'input_vocab_size': vocab_size,\n",
    "         'target_vocab_size': vocab_size,\n",
    "         'maximum_position_encoding': MAX_SEQUENCE,\n",
    "         'end_token_idx': END_INDEX,\n",
    "         'rate': 0.1\n",
    "        }\n",
    "\n",
    "model = Transformer(**kargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=loss_function,\n",
    "              metrics=[accuracy_function])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18 samples, validate on 2 samples\n",
      "Epoch 1/20\n",
      "16/18 [=========================>....] - ETA: 1s - loss: 0.9229 - accuracy_function: 0.8429WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 11s 591ms/sample - loss: 0.9334 - accuracy_function: 0.8428 - val_loss: 0.6233 - val_accuracy_function: 0.8460\n",
      "Epoch 2/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.6429 - accuracy_function: 0.8513WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 42ms/sample - loss: 0.6539 - accuracy_function: 0.8512 - val_loss: 0.5680 - val_accuracy_function: 0.8520\n",
      "Epoch 3/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.5551 - accuracy_function: 0.8541WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 43ms/sample - loss: 0.5430 - accuracy_function: 0.8546 - val_loss: 0.6156 - val_accuracy_function: 0.8573\n",
      "Epoch 4/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.4086 - accuracy_function: 0.8618WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 43ms/sample - loss: 0.4426 - accuracy_function: 0.8620 - val_loss: 0.5118 - val_accuracy_function: 0.8635\n",
      "Epoch 5/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.3384 - accuracy_function: 0.8685WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 44ms/sample - loss: 0.3389 - accuracy_function: 0.8690 - val_loss: 0.5437 - val_accuracy_function: 0.8716\n",
      "Epoch 6/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.2288 - accuracy_function: 0.8764WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 41ms/sample - loss: 0.2290 - accuracy_function: 0.8772 - val_loss: 0.4300 - val_accuracy_function: 0.8800\n",
      "Epoch 7/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1693 - accuracy_function: 0.8852WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 42ms/sample - loss: 0.1667 - accuracy_function: 0.8858 - val_loss: 0.4522 - val_accuracy_function: 0.8883\n",
      "Epoch 8/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.1346 - accuracy_function: 0.8933WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 42ms/sample - loss: 0.1307 - accuracy_function: 0.8941 - val_loss: 0.5058 - val_accuracy_function: 0.8970\n",
      "Epoch 9/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0920 - accuracy_function: 0.9014WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 42ms/sample - loss: 0.0909 - accuracy_function: 0.9020 - val_loss: 0.5198 - val_accuracy_function: 0.9044\n",
      "Epoch 10/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0826 - accuracy_function: 0.9079WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 51ms/sample - loss: 0.0806 - accuracy_function: 0.9086 - val_loss: 0.3562 - val_accuracy_function: 0.9112\n",
      "Epoch 11/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0863 - accuracy_function: 0.9146WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 58ms/sample - loss: 0.0786 - accuracy_function: 0.9151 - val_loss: 0.4367 - val_accuracy_function: 0.9167\n",
      "Epoch 12/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0363 - accuracy_function: 0.9198WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 52ms/sample - loss: 0.0447 - accuracy_function: 0.9203 - val_loss: 0.2914 - val_accuracy_function: 0.9223\n",
      "Epoch 13/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0305 - accuracy_function: 0.9253WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 56ms/sample - loss: 0.0311 - accuracy_function: 0.9257 - val_loss: 0.2559 - val_accuracy_function: 0.9274\n",
      "Epoch 14/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0182 - accuracy_function: 0.9301WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 42ms/sample - loss: 0.0181 - accuracy_function: 0.9305 - val_loss: 0.2720 - val_accuracy_function: 0.9320\n",
      "Epoch 15/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0121 - accuracy_function: 0.9343WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 44ms/sample - loss: 0.0145 - accuracy_function: 0.9347 - val_loss: 0.2671 - val_accuracy_function: 0.9359\n",
      "Epoch 16/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0127 - accuracy_function: 0.9379WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 49ms/sample - loss: 0.0116 - accuracy_function: 0.9382 - val_loss: 0.2552 - val_accuracy_function: 0.9394\n",
      "Epoch 17/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0092 - accuracy_function: 0.9412WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 45ms/sample - loss: 0.0087 - accuracy_function: 0.9415 - val_loss: 0.2644 - val_accuracy_function: 0.9426\n",
      "Epoch 18/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0074 - accuracy_function: 0.9442WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 51ms/sample - loss: 0.0071 - accuracy_function: 0.9445 - val_loss: 0.2651 - val_accuracy_function: 0.9454\n",
      "Epoch 19/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0062 - accuracy_function: 0.9469WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 48ms/sample - loss: 0.0064 - accuracy_function: 0.9471 - val_loss: 0.2528 - val_accuracy_function: 0.9480\n",
      "Epoch 20/20\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 0.0050 - accuracy_function: 0.9493WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy_function,val_loss,val_accuracy_function\n",
      "18/18 [==============================] - 1s 55ms/sample - loss: 0.0049 - accuracy_function: 0.9495 - val_loss: 0.2345 - val_accuracy_function: 0.9503\n"
     ]
    }
   ],
   "source": [
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001,patience=1)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.{epoch:02d}-{val_accuracy:.2f}.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=False, save_weights_only=True)\n",
    "\n",
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=4, epochs=20,\n",
    "                    validation_split=0.1, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 출력값 보이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[o] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'평소에 필요했던 게 좋을 것 같아요'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.inference(test_index_inputs)\n",
    "' '.join([idx2char[o] for o in outputs])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
